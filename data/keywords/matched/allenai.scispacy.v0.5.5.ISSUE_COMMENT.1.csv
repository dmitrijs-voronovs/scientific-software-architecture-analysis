id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/allenai/scispacy/issues/150:1860,integrability,state,state,1860,"re generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <a",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:2890,integrability,Sub,Subject,2890,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:3264,integrability,pipelin,pipeline,3264,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:2143,modifiability,LAYER,LAYERS,2143,"t(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:627,performance,load,load,627,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:232,reliability,doe,does,232,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:405,reliability,doe,doesn,405,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:177,safety,test,test,177,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:364,safety,Test,Test,364,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:3190,safety,detect,detector,3190,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:2854,security,Auth,Author,2854,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:2862,security,auth,author,2862,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:3190,security,detect,detector,3190,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:3401,security,auth,authored,3401,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:3757,security,auth,auth,3757,"s that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS, IPS Cell, Cells, IPS. CUI: C0872076, Name: Pluripotent Stem Cells. Definition: Cells that can give rise to cells of the three different GERM LAYERS. TUI(s): T025. Aliases (abbreviated, total: 12):. Pluripotent Stem Cells, pluripotent stem cells, pluripotent stem cell, pluripotent stem cell, pluripotent stem cell, Pluripotent Stem Cell, Pluripotent Stem Cell, Stem Cell, Pluripotent, Pluripotent stem cell, Pluripotent stem cell. (scispacy) ELSSLCM-4176012:scispacy danielr$. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Tuesday, August 13, 2019 at 2:08 PM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Hi! Good news - we have that functionality already! https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. if you set resolve_abbreviations : bool = True and add the abbreviation detector<https://github.com/allenai/scispacy#abbreviationdetector> to the pipeline before the linker, the linker will use the long forms of any abbreviations that it finds. —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXYFGH7E6R2NZ4ZPOO3QEMPEHA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4G7VGA#issuecomment-521009816>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX76EQRNL4XQF3OZ47DQEMPEHANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:177,testability,test,test,177,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:364,testability,Test,Test,364,"Hi Mark,. Thanks for your prompt reply. My apologies for taking a few days to reply. I think I am already using resolve_abbreviations=True in the proper manner. Here’s a bit of test code and output. Note that the abbreviations code does find ‘Human induced pluripotent stem cells’ as the long form for hiPSC, but the UMLS codes for hiPSC don’t include that one. # Test of scispacy to see problem where it doesn't find. # CUI C3658289 for Human Induced Pluripotent stem cells. import spacy. import scispacy. from scispacy.abbreviation import AbbreviationDetector. from scispacy.umls_linking import UmlsEntityLinker. nlp = spacy.load(""en_core_sci_sm""). abbreviation_pipe = AbbreviationDetector(nlp). nlp.add_pipe(abbreviation_pipe). linker = UmlsEntityLinker(resolve_abbreviations=True). nlp.add_pipe(linker). text1 = ""Human induced pluripotent stem cells (hiPSC) are generated from ""\. ""reprogrammed fibroblasts by overexpression of pluripotency factors.\n"". # Process the text w/ full SciSpacy pipeline. print(""Pipeline: "", nlp.pipe_names). doc1 = nlp(text1). print(""Abbreviations:""). for a in doc1._.abbreviations:. print(a, a._.long_form). print(""\nEntities: "", doc1.ents). # Comment out next block and uncomment loop below it to see all UMLS entities. entity = doc1.ents[3] # for the hiPSC case. print(""Entity Name: "", entity). for umls_ent in entity._.umls_ents:. print(""\t"", linker.umls.cui_to_entity[umls_ent[0]]). $ python test_abbrv.py. Pipeline: ['tagger', 'parser', 'ner', 'AbbreviationDetector', 'UmlsEntityLinker']. Abbreviations:. hiPSC Human induced pluripotent stem cells. Entities: (Human, induced, pluripotent stem cells, hiPSC, fibroblasts, overexpression, pluripotency factors). Entity Name: hiPSC. CUI: C2717959, Name: Induced Pluripotent Stem Cells. Definition: Cells from adult organisms that have been reprogrammed into a pluripotential state similar to that of EMBRYONIC STEM CELLS. TUI(s): T025. Aliases: (total: 6):. Induced Pluripotent Stem Cell, iPSC, IPS Cells, Cell, IPS",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:642,availability,error,error,642,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:95,integrability,filter,filter,95,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:272,integrability,filter,filter,272,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:642,performance,error,error,642,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:398,safety,detect,detector,398,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:522,safety,detect,detector,522,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:642,safety,error,error,642,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:398,security,detect,detector,398,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:522,security,detect,detector,522,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:206,usability,prefer,prefer,206,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:642,usability,error,error,642,"Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152 . Thanks for the useful error cases!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1410,availability,error,error,1410,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:566,integrability,Sub,Subject,566,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:769,integrability,filter,filter,769,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:946,integrability,filter,filter,946,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1410,performance,error,error,1410,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1118,safety,detect,detector,1118,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1242,safety,detect,detector,1242,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1410,safety,error,error,1410,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:530,security,Auth,Author,530,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:538,security,auth,author,538,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1118,security,detect,detector,1118,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1242,security,detect,detector,1242,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1461,security,auth,authored,1461,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1817,security,auth,auth,1817,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:880,usability,prefer,prefer,880,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/issues/150:1410,usability,error,error,1410,"Hi Mark,. Thank *you* for the super-fast debugging of that issue, and the quick fix when there is a known long form. Looking forward to the other fix too. Best regards,. Ron Daniel, Ph.D. Director, Elsevier Labs | ELSEVIER. +1 619 208 3064 | r.daniel@elsevier.com<mailto:r.daniel@elsevier.com>. From: Mark Neumann <notifications@github.com>. Reply-To: allenai/scispacy <reply@reply.github.com>. Date: Friday, August 16, 2019 at 11:13 AM. To: allenai/scispacy <scispacy@noreply.github.com>. Cc: Ron Daniel <R.Daniel@elsevier.com>, Author <author@noreply.github.com>. Subject: Re: [allenai/scispacy] Abbreviations and UMLS linking (#150). *** External email: use caution ***. Thanks for the snippet! We actually figured out this was a combination of two problems:. 1. We filter for entities which have definitions in the KnowledgeBase, because over 80% of mentions typically should prefer an entity with a definition. However, it was a bit dumb to filter these out when there is an exact string match, so I fixed this part in #153<https://github.com/allenai/scispacy/pull/153>. 2. The second part is that if the mention detector goes a bit wrong and splits up a long entity into several separate ones, we should be able to use the abbreviation detector to fix those cases. We haven't done this yet, but we opened an issue for it here: #152<https://github.com/allenai/scispacy/issues/152> . Thanks for the useful error cases! —. You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/allenai/scispacy/issues/150?email_source=notifications&email_token=AAGVMXZHKNHDNBNN2EABFL3QE3U6DA5CNFSM4ILM75Q2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD4PKPFA#issuecomment-522102676>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AAGVMX2SGSAHUPYFELK46ELQE3U6DANCNFSM4ILM75QQ>.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/150
https://github.com/allenai/scispacy/pull/162:9,safety,test,test,9,Close to test removing teamcity,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:23,security,team,teamcity,23,Close to test removing teamcity,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:9,testability,test,test,9,Close to test removing teamcity,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/162:0,usability,Close,Close,0,Close to test removing teamcity,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/162
https://github.com/allenai/scispacy/pull/164:9,security,team,teamcity,9,"Alright, teamcity is fully off now",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/164
https://github.com/allenai/scispacy/issues/165:171,deployability,upgrad,upgrading,171,"Hmm sorry about that! Unfortunately to use the entity linker you do actually need nmslib. It looks like it's some system level problem with cython - perhaps you could try upgrading cython? Alternatively, you can look at the steps in our Dockerfile (which we use on a linux server to run our tests:. https://github.com/allenai/scispacy/blob/master/Dockerfile#L4. These lines might help you? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:171,modifiability,upgrad,upgrading,171,"Hmm sorry about that! Unfortunately to use the entity linker you do actually need nmslib. It looks like it's some system level problem with cython - perhaps you could try upgrading cython? Alternatively, you can look at the steps in our Dockerfile (which we use on a linux server to run our tests:. https://github.com/allenai/scispacy/blob/master/Dockerfile#L4. These lines might help you? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:291,safety,test,tests,291,"Hmm sorry about that! Unfortunately to use the entity linker you do actually need nmslib. It looks like it's some system level problem with cython - perhaps you could try upgrading cython? Alternatively, you can look at the steps in our Dockerfile (which we use on a linux server to run our tests:. https://github.com/allenai/scispacy/blob/master/Dockerfile#L4. These lines might help you? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:291,testability,test,tests,291,"Hmm sorry about that! Unfortunately to use the entity linker you do actually need nmslib. It looks like it's some system level problem with cython - perhaps you could try upgrading cython? Alternatively, you can look at the steps in our Dockerfile (which we use on a linux server to run our tests:. https://github.com/allenai/scispacy/blob/master/Dockerfile#L4. These lines might help you? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/165:380,usability,help,help,380,"Hmm sorry about that! Unfortunately to use the entity linker you do actually need nmslib. It looks like it's some system level problem with cython - perhaps you could try upgrading cython? Alternatively, you can look at the steps in our Dockerfile (which we use on a linux server to run our tests:. https://github.com/allenai/scispacy/blob/master/Dockerfile#L4. These lines might help you? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/165
https://github.com/allenai/scispacy/issues/166:142,deployability,instal,installed,142,"Hi! Normally this means that you have run out of memory. Perhaps checking that might help? Additionally, it's worth checking that `nmslib` is installed correctly. It is a c++ library and so might have segfaulted etc. can you use `nmslib` directly in a python shell?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:49,performance,memor,memory,49,"Hi! Normally this means that you have run out of memory. Perhaps checking that might help? Additionally, it's worth checking that `nmslib` is installed correctly. It is a c++ library and so might have segfaulted etc. can you use `nmslib` directly in a python shell?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:49,usability,memor,memory,49,"Hi! Normally this means that you have run out of memory. Perhaps checking that might help? Additionally, it's worth checking that `nmslib` is installed correctly. It is a c++ library and so might have segfaulted etc. can you use `nmslib` directly in a python shell?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:85,usability,help,help,85,"Hi! Normally this means that you have run out of memory. Perhaps checking that might help? Additionally, it's worth checking that `nmslib` is installed correctly. It is a c++ library and so might have segfaulted etc. can you use `nmslib` directly in a python shell?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:106,deployability,instal,installed,106,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:164,deployability,instal,installed,164,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:80,performance,memor,memory,80,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:36,reliability,doe,doesn,36,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:144,reliability,Doe,Does,144,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:80,usability,memor,memory,80,"I just did what the demo did but it doesn't work, and I can't figure out why my memory run out. I do have installed nmslib and I can import it. Does it mean I have installed it correctly?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:44,availability,down,downgrading,44,@fireholder was this issue also resolved by downgrading spacy version (similar to #167) or are you still facing this issue as well?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:62,deployability,version,version,62,@fireholder was this issue also resolved by downgrading spacy version (similar to #167) or are you still facing this issue as well?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:62,integrability,version,version,62,@fireholder was this issue also resolved by downgrading spacy version (similar to #167) or are you still facing this issue as well?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:62,modifiability,version,version,62,@fireholder was this issue also resolved by downgrading spacy version (similar to #167) or are you still facing this issue as well?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:84,deployability,fail,failing,84,Could you provide the output of `pip list` along with the full code snippet that is failing?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:84,reliability,fail,failing,84,Could you provide the output of `pip list` along with the full code snippet that is failing?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2379,availability,servic,service,2379, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2379,deployability,servic,service,2379, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2727,deployability,upgrad,upgrades,2727, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:497,energy efficiency,core,core-sci-lg,497,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:521,energy efficiency,core,core-sci-md,521,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:545,energy efficiency,core,core-sci-sm,545,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:971,energy efficiency,core,core,971,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2470,energy efficiency,estimat,estimator,2470, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2501,energy efficiency,gpu,gpu,2501, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:3134,energy efficiency,load,load,3134, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2379,integrability,servic,service,2379, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2917,integrability,wrap,wrapt,2917, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2952,integrability,interfac,interface,2952, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2952,interoperability,interfac,interface,2952, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:386,modifiability,deco,decorator,386,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2379,modifiability,servic,service,2379, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2727,modifiability,upgrad,upgrades,2727, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2952,modifiability,interfac,interface,2952, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2501,performance,gpu,gpu,2501, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:3134,performance,load,load,3134, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2553,safety,test,testpath,2553, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:63,security,apt,apturl,63,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:235,security,certif,certifi,235,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:330,security,cryptograph,cryptography,330,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:1889,security,apt,apt,1889,0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). wi,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2098,security,rsa,rsa,2098,.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsE,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:3253,security,sign,signal,3253, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2284,testability,simpl,simplegeneric,2284, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2307,testability,simpl,simplejson,2307, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2553,testability,test,testpath,2553, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:291,usability,command,command-not-found,291,@danielkingai2 . my pip list is as follows:. `absl-py (0.8.0). apturl (0.5.2). asn1crypto (0.24.0). astor (0.8.0). attrs (19.1.0). awscli (1.16.248). backcall (0.1.0). bleach (3.1.0). blis (0.4.1). botocore (1.12.238). Brlapi (0.6.6). certifi (2019.9.11). chardet (3.0.4). colorama (0.3.9). command-not-found (0.3). conllu (2.0). cryptography (2.1.4). cupshelpers (1.0). cymem (2.0.2). decorator (4.4.0). defer (1.0.6). defusedxml (0.6.0). distro-info (0.18ubuntu0.18.04.1). docutils (0.15.2). en-core-sci-lg (0.2.3). en-core-sci-md (0.2.3). en-core-sci-sm (0.2.3). en-ner-bionlp13cg-md (0.2.3). entrypoints (0.3). gast (0.3.2). google-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzm,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:1626,usability,tool,toolkit,1626,oogle-pasta (0.1.7). grpcio (1.24.0). Guake (3.0.5). h5py (2.10.0). httplib2 (0.9.2). idna (2.8). ipykernel (5.1.2). ipython (7.8.0). ipython-genutils (0.2.0). ipywidgets (7.5.1). jedi (0.15.1). Jinja2 (2.10.1). jmespath (0.9.4). joblib (0.13.2). jsonschema (3.0.2). jupyter (1.0.0). jupyter-client (5.3.3). jupyter-console (6.0.0). jupyter-core (4.5.0). Keras-Applications (1.0.8). Keras-Preprocessing (1.1.0). keyring (10.6.0). keyrings.alt (3.0). language-selector (0.1). launchpadlib (1.10.6). lazr.restfulclient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado ,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2138,usability,learn,learn,2138,lient (0.13.5). lazr.uri (1.0.3). louis (3.5.0). macaroonbakery (1.1.3). Mako (1.0.7). Markdown (3.1.1). MarkupSafe (1.1.1). mistune (0.8.4). murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('e,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2284,usability,simpl,simplegeneric,2284, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2307,usability,simpl,simplejson,2307, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:2889,usability,widget,widgetsnbextension,2889, murmurhash (1.0.2). nbconvert (5.6.0). nbformat (4.4.0). netifaces (0.10.4). nmslib (1.8.1). notebook (6.0.1). numpy (1.17.2). oauth (1.0.1). olefile (0.45.1). pandocfilters (1.4.2). parso (0.5.1). pbr (3.1.1). pexpect (4.7.0). pickleshare (0.7.5). Pillow (6.1.0). pip (9.0.1). plac (0.9.6). preshed (3.0.2). prometheus-client (0.7.1). prompt-toolkit (2.0.9). protobuf (3.9.2). ptyprocess (0.6.0). pyasn1 (0.4.7). pybind11 (2.4.2). pycairo (1.16.2). pycrypto (2.6.1). pycups (1.9.73). Pygments (2.4.2). pygobject (3.26.1). pymacaroons (0.13.0). PyNaCl (1.1.2). pyRFC3339 (1.0). pyrsistent (0.15.4). python-apt (1.6.4). python-dateutil (2.8.0). python-debian (0.1.32). pytz (2018.3). pyxdg (0.25). PyYAML (5.1.2). pyzmq (18.1.0). qtconsole (4.5.5). reportlab (3.4.0). requests (2.22.0). requests-unixsocket (0.1.5). rsa (3.4.2). s3transfer (0.2.1). scikit-learn (0.21.3). scipy (1.3.1). scispacy (0.2.3). screen-resolution-extra (0.0.0). SecretStorage (2.3.1). Send2Trash (1.5.0). setuptools (41.2.0). simplegeneric (0.8.1). simplejson (3.13.2). six (1.12.0). spacy (2.1.8). srsly (0.1.0). system-service (0.3). systemd-python (234). tensorboard (1.14.0). tensorflow (1.14.0). tensorflow-estimator (1.14.0). tensorflow-gpu (1.14.0). termcolor (1.1.0). terminado (0.8.2). testpath (0.4.2). thinc (7.1.1). torch (1.2.0). torchvision (0.4.0). tornado (6.0.3). tqdm (4.36.1). traitlets (4.3.2). ubuntu-drivers-common (0.0.0). ufw (0.36). unattended-upgrades (0.1). urllib3 (1.25.6). usb-creator (0.3.3). wadllib (1.3.2). wasabi (0.2.2). wcwidth (0.1.7). webencodings (0.5.1). Werkzeug (0.16.0). wheel (0.33.6). widgetsnbextension (3.5.1). wrapt (1.11.2). xkit (0.0.0). zope.interface (4.3.2)`. and my full code snippet is :. `In [1]: import spacy . In [2]: import scispacy . In [3]: from scispacy.umls_linking import UmlsEntityLinker . In [4]: nlp = spacy.load('en_core_sci_sm') . In [5]: linker = UmlsEntityLinker(resolve_abbreviations=True) . fish: “ipython” terminated by signal SIGKILL (Forced quit)`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:38,availability,error,error,38,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:31,performance,memor,memory,31,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:38,performance,error,error,38,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:61,performance,memor,memory,61,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:114,performance,memor,memory,114,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:121,reliability,doe,does,121,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:38,safety,error,error,38,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:31,usability,memor,memory,31,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:38,usability,error,error,38,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:61,usability,memor,memory,61,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:85,usability,command,command,85,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:114,usability,memor,memory,114,This is quite likely an out of memory error. Could you check memory usage while that command is run? And how much memory does the machine you are running it on have?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:26,performance,memor,memory,26,"I have a machine of of 8G memory, and I only used firefox when the command was run. @danielkingai2",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:26,usability,memor,memory,26,"I have a machine of of 8G memory, and I only used firefox when the command was run. @danielkingai2",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:67,usability,command,command,67,"I have a machine of of 8G memory, and I only used firefox when the command was run. @danielkingai2",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,availability,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:92,deployability,manag,manager,92,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,deployability,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:92,energy efficiency,manag,manager,92,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,energy efficiency,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:45,performance,memor,memory,45,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:189,performance,memor,memory,189,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,reliability,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:92,safety,manag,manager,92,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,safety,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:118,testability,monitor,monitor,118,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:18,usability,help,helpful,18,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:45,usability,memor,memory,45,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:145,usability,command,command,145,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:169,usability,confirm,confirm,169,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:189,usability,memor,memory,189,"It would still be helpful if you could check memory usage (on linux: htop, on windows: task manager, on mac: activity monitor) while running the command, just so we can confirm that out of memory is the issue versus something else.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:20,performance,memor,memory,20,It used at least 4G memory. @danielkingai2,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:20,usability,memor,memory,20,It used at least 4G memory. @danielkingai2,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:86,deployability,updat,updates,86,Could you try this again in a clean conda environment? I'd like to know if the latest updates to `nmslib` resolved your issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:86,safety,updat,updates,86,Could you try this again in a clean conda environment? I'd like to know if the latest updates to `nmslib` resolved your issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:86,security,updat,updates,86,Could you try this again in a clean conda environment? I'd like to know if the latest updates to `nmslib` resolved your issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:61,performance,memor,memory,61,Unfortunately I think this is just a straightforward lack of memory - please re-open if you find it actually is something more severe. Thanks!,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/166:61,usability,memor,memory,61,Unfortunately I think this is just a straightforward lack of memory - please re-open if you find it actually is something more severe. Thanks!,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/166
https://github.com/allenai/scispacy/issues/167:80,deployability,version,version,80,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:101,deployability,version,version,101,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:74,energy efficiency,model,model,74,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:80,integrability,version,version,80,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:101,integrability,version,version,101,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:80,modifiability,version,version,80,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:101,modifiability,version,version,101,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:74,security,model,model,74,Could you please provide the output of running `pip list`? I suspect your model version and scispacy version are out of sync.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:238,availability,Down,Downgrading,238,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:122,deployability,releas,release,122,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:166,deployability,releas,releases,166,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:60,energy efficiency,core,core-sci-sm,60,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:230,energy efficiency,model,models,230,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:210,interoperability,compatib,compatible,210,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:230,security,model,models,230,"I have a similar issue with spacy=2.2.1, scispacy=0.2.3, en-core-sci-sm=0.2.3. I believe this stems from the [spacy 2.2.0 release](https://github.com/explosion/spaCy/releases/tag/v2.2.0), which is not backward compatible with old models. Downgrading to spacy 2.1.8 seems to fix it in my case.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:109,availability,down,downgrading,109,"Ah, that is probably correct, thanks! We will have to retrain the models. @fireholder for now, please see if downgrading spacy to 2.1.8 solves your problems",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:66,energy efficiency,model,models,66,"Ah, that is probably correct, thanks! We will have to retrain the models. @fireholder for now, please see if downgrading spacy to 2.1.8 solves your problems",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:66,security,model,models,66,"Ah, that is probably correct, thanks! We will have to retrain the models. @fireholder for now, please see if downgrading spacy to 2.1.8 solves your problems",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:5,availability,down,downgrading,5,"Yes, downgrading does work. Thanks~",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:17,reliability,doe,does,17,"Yes, downgrading does work. Thanks~",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:15,deployability,updat,update,15,Can you please update scispacy to work with the current spacy?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:48,energy efficiency,current,current,48,Can you please update scispacy to work with the current spacy?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:15,safety,updat,update,15,Can you please update scispacy to work with the current spacy?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:15,security,updat,update,15,Can you please update scispacy to work with the current spacy?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:19,deployability,updat,update,19,"@epurdy No, when I update to spacy 2.2.1, it still doesn't work.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:51,reliability,doe,doesn,51,"@epurdy No, when I update to spacy 2.2.1, it still doesn't work.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:19,safety,updat,update,19,"@epurdy No, when I update to spacy 2.2.1, it still doesn't work.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:19,security,updat,update,19,"@epurdy No, when I update to spacy 2.2.1, it still doesn't work.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:18,deployability,updat,updating,18,"We are working on updating it, not sure of an ETA, there are a few issues we have to work through.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:18,safety,updat,updating,18,"We are working on updating it, not sure of an ETA, there are a few issues we have to work through.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:18,security,updat,updating,18,"We are working on updating it, not sure of an ETA, there are a few issues we have to work through.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:91,deployability,releas,release,91,"One issue we are facing is a bug with the latest spacy, so we will have to wait on them to release the fix for that, at a minimum.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:122,usability,minim,minimum,122,"One issue we are facing is a bug with the latest spacy, so we will have to wait on them to release the fix for that, at a minimum.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:123,availability,down,downgrade,123,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:178,availability,error,error,178,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:95,interoperability,incompatib,incompatible,95,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:178,performance,error,error,178,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:178,safety,error,error,178,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:178,usability,error,error,178,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:192,usability,help,help,192,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:236,usability,user,user-images,236,"**scispacy 0.2.3-unreleased has requirement spacy>=2.2.1, but you'll have spacy 2.1.8 which is incompatible.**. I tried to downgrade my spacy from 2.2.1 to 2.1.8 but I got above error .Kindly help me resolve . ![Screenshot (3)](https://user-images.githubusercontent.com/27534184/67003511-bd9ab100-f0fb-11e9-951e-b2cb14392148.png).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:252,availability,error,error,252,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:20,deployability,updat,updating,20,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:100,deployability,instal,installed,100,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:148,deployability,instal,installing,148,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:163,deployability,releas,released,163,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:172,deployability,version,version,172,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:211,deployability,instal,install,211,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:295,deployability,stack,stackoverflow,295,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:342,deployability,instal,install-packages-due-to-an-environmenterror-winerror-,342,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:172,integrability,version,version,172,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:44,interoperability,compatib,compatible,44,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:172,modifiability,version,version,172,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:350,modifiability,pac,packages-due-to-an-environmenterror-winerror-,350,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:252,performance,error,error,252,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:20,safety,updat,updating,20,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:241,safety,permiss,permission,241,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:252,safety,error,error,252,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:20,security,updat,updating,20,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:397,security,access,access-is-de,397,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:252,usability,error,error,252,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:425,usability,help,help,425,"We haven't finished updating scispacy to be compatible with spacy 2.2.1 yet. It seems that you have installed scispacy from source. I would suggest installing the released version with `pip` from pypi with `pip install scispacy`. As for the permission error, likely the solutions [here](https://stackoverflow.com/questions/51912999/could-not-install-packages-due-to-an-environmenterror-winerror-5-access-is-de/57132010) will help you out",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:45,availability,error,error,45,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:56,energy efficiency,core,core-sci-lg,56,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:148,energy efficiency,model,models,148,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:45,performance,error,error,45,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:45,safety,error,error,45,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:148,security,model,models,148,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:45,usability,error,error,45,"Just to chime in, I'm also getting this same error . en-core-sci-lg 0.2.3 . scispacy 0.2.3. spacy 2.2.1. looking forward to trying out the scispacy models :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:15,availability,down,downgrade,15,"you'll need to downgrade spacy to 2.1.8 for now, we're working on it though :)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:46,interoperability,compatib,compatible,46,Closing as `scispacy == 0.2.4` is live and is compatible with `spacy == 2.2.1`,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:4,deployability,updat,updates,4,Any updates on this. spacy == 2.2.1 with scispacy==0.2.4 also has issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:4,safety,updat,updates,4,Any updates on this. spacy == 2.2.1 with scispacy==0.2.4 also has issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/issues/167:4,security,updat,updates,4,Any updates on this. spacy == 2.2.1 with scispacy==0.2.4 also has issue.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/167
https://github.com/allenai/scispacy/pull/171:0,energy efficiency,Current,Current,0,"Current status is that all tests pass without the fall backs on the normal sentence splitter. Leaving them in for now (without merging), hoping that @isabelcachola can rerun her job and see if there are any more edge cases that output warnings, or if we can remove the fall backs.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:27,safety,test,tests,27,"Current status is that all tests pass without the fall backs on the normal sentence splitter. Leaving them in for now (without merging), hoping that @isabelcachola can rerun her job and see if there are any more edge cases that output warnings, or if we can remove the fall backs.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:27,testability,test,tests,27,"Current status is that all tests pass without the fall backs on the normal sentence splitter. Leaving them in for now (without merging), hoping that @isabelcachola can rerun her job and see if there are any more edge cases that output warnings, or if we can remove the fall backs.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:8,usability,statu,status,8,"Current status is that all tests pass without the fall backs on the normal sentence splitter. Leaving them in for now (without merging), hoping that @isabelcachola can rerun her job and see if there are any more edge cases that output warnings, or if we can remove the fall backs.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:128,availability,state,state,128,@DeNeutoy all the hacky fallbacks have been removed because all the known pysbd bugs were fixed. I'll merge it in this (better) state once CI passes unless you object to something,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:128,integrability,state,state,128,@DeNeutoy all the hacky fallbacks have been removed because all the known pysbd bugs were fixed. I'll merge it in this (better) state once CI passes unless you object to something,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/171:18,security,hack,hacky,18,@DeNeutoy all the hacky fallbacks have been removed because all the known pysbd bugs were fixed. I'll merge it in this (better) state once CI passes unless you object to something,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/171
https://github.com/allenai/scispacy/pull/178:47,safety,test,tests,47,"@danielkingai2 , @DeNeutoy Able to pass rest 3 tests. 1 test related to list items is pending. Let me know what you think",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:56,safety,test,test,56,"@danielkingai2 , @DeNeutoy Able to pass rest 3 tests. 1 test related to list items is pending. Let me know what you think",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:47,testability,test,tests,47,"@danielkingai2 , @DeNeutoy Able to pass rest 3 tests. 1 test related to list items is pending. Let me know what you think",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:56,testability,test,test,56,"@danielkingai2 , @DeNeutoy Able to pass rest 3 tests. 1 test related to list items is pending. Let me know what you think",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:146,deployability,version,version,146,"@nipunsadvilkar are you addressing these fixes upstream in https://github.com/nipunsadvilkar/pySBD/pull/42 ? We'd love to be able to use a stable version of pySBD, it's a great project and has solved a lot of problems for a team internally :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:146,integrability,version,version,146,"@nipunsadvilkar are you addressing these fixes upstream in https://github.com/nipunsadvilkar/pySBD/pull/42 ? We'd love to be able to use a stable version of pySBD, it's a great project and has solved a lot of problems for a team internally :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:146,modifiability,version,version,146,"@nipunsadvilkar are you addressing these fixes upstream in https://github.com/nipunsadvilkar/pySBD/pull/42 ? We'd love to be able to use a stable version of pySBD, it's a great project and has solved a lot of problems for a team internally :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:224,security,team,team,224,"@nipunsadvilkar are you addressing these fixes upstream in https://github.com/nipunsadvilkar/pySBD/pull/42 ? We'd love to be able to use a stable version of pySBD, it's a great project and has solved a lot of problems for a team internally :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:74,deployability,fail,failing,74,https://github.com/nipunsadvilkar/pySBD/issues/49 opened an issue for the failing test,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:74,reliability,fail,failing,74,https://github.com/nipunsadvilkar/pySBD/issues/49 opened an issue for the failing test,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:82,safety,test,test,82,https://github.com/nipunsadvilkar/pySBD/issues/49 opened an issue for the failing test,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/pull/178:82,testability,test,test,82,https://github.com/nipunsadvilkar/pySBD/issues/49 opened an issue for the failing test,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/178
https://github.com/allenai/scispacy/issues/179:109,deployability,version,version,109,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:186,energy efficiency,model,models,186,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2,integrability,coupl,couple,2,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:109,integrability,version,version,109,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:171,interoperability,standard,standard,171,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2,modifiability,coupl,couple,2,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:109,modifiability,version,version,109,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:186,security,model,models,186,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2,testability,coupl,couple,2,A couple of questions:. (1) Could you provide the output of `pip list` in your environment so I can see what version of everything you have? (2) Are you able to train the standard spacy models with your data?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:131,deployability,Version,Version,131,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:60,energy efficiency,model,model,60,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:712,energy efficiency,cloud,cloudpickle,712,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1003,energy efficiency,core,core-sci-lg,1003," able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1026,energy efficiency,core,core-web-sm,1026,"dard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-ff",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1245,energy efficiency,green,greenlet,1245,aconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . n,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1686,energy efficiency,core,core,1686,det 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolk,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3913,energy efficiency,gpu,gpu-ops,3913,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:131,integrability,Version,Version,131,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:4140,integrability,wrap,wrapt,4140,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:28,interoperability,standard,standard,28,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:963,interoperability,distribut,distributed,963,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1069,interoperability,xml,xmlfile,1069," data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertoo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1848,interoperability,prox,proxy,1848,m 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycry,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2608,interoperability,plug,pluggy,2608,0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:123,modifiability,Pac,Package,123,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:131,modifiability,Version,Version,131,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:926,modifiability,deco,decorator,926,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2373,modifiability,pac,packaging,2373,ib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 ,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:631,performance,Bottleneck,Bottleneck,631,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1912,performance,lock,locket,1912,pe 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . ,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2194,performance,network,networkx,2194,glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyY,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3913,performance,gpu,gpu-ops,3913,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3876,safety,test,testpath,3876,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:60,security,model,model,60,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:650,security,certif,certifi,650,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:797,security,cryptograph,cryptography,797,"Yes, i am able to train the standard spacy ""en_core_web_sm"" model with my data. . The output of ""pip list"" is as follows:. Package Version . ---------------------------------- ----------. absl-py 0.7.1 . alabaster 0.7.12 . anaconda-client 1.7.2 . anaconda-project 0.8.2 . asn1crypto 0.24.0 . astor 0.8.0 . astroid 2.1.0 . astropy 3.1 . atomicwrites 1.2.1 . attrs 18.2.0 . awscli 1.16.261 . Babel 2.6.0 . backcall 0.1.0 . backports.os 0.1.1 . backports.shutil-get-terminal-size 1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccab",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1474,security,iso,isort,1474,1.0.0 . beautifulsoup4 4.6.3 . bitarray 0.8.3 . bkcharts 0.2 . blaze 0.11.3 . bleach 3.0.2 . blis 0.4.1 . bokeh 1.0.2 . boto 2.49.0 . botocore 1.12.251 . Bottleneck 1.2.1 . certifi 2018.11.29. cffi 1.11.5 . chardet 3.0.4 . Click 7.0 . cloudpickle 0.6.1 . clyent 1.2.2 . colorama 0.4.1 . conllu 2.2 . contextlib2 0.5.5 . cryptography 2.4.2 . cupy 6.4.0 . cycler 0.10.0 . cymem 2.0.2 . Cython 0.29.2 . cytoolz 0.9.0.1 . dask 1.0.0 . datashape 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . path,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:1912,security,lock,locket,1912,pe 0.5.4 . decorator 4.3.0 . defusedxml 0.5.0 . distributed 1.25.1 . docutils 0.14 . en-core-sci-lg 0.2.3 . en-core-web-sm 2.2.0 . entrypoints 0.2.3 . et-xmlfile 1.0.1 . fastcache 1.0.2 . fastrlock 0.4 . filelock 3.0.10 . Flask 1.0.2 . Flask-Cors 3.0.7 . gast 0.2.2 . gevent 1.3.7 . glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . ,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2194,security,network,networkx,2194,glob2 0.6 . gmpy2 2.0.8 . google-pasta 0.1.7 . greenlet 0.4.15 . grpcio 1.23.0 . h5py 2.8.0 . heapdict 1.0.0 . html5lib 1.0.1 . idna 2.8 . imageio 2.4.1 . imagesize 1.1.0 . importlib-metadata 0.6 . ipykernel 5.1.0 . ipython 7.2.0 . ipython-genutils 0.2.0 . ipywidgets 7.4.2 . isort 4.3.4 . itsdangerous 1.1.0 . jdcal 1.4 . jedi 0.13.2 . jeepney 0.4 . Jinja2 2.10 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . jupyter 1.0.0 . jupyter-client 5.2.4 . jupyter-console 6.0.0 . jupyter-core 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyY,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3305,security,rsa,rsa,3305,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3510,testability,simpl,simplegeneric,3510,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3707,testability,spy,spyder,3707,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3722,testability,spy,spyder-kernels,3722,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3876,testability,test,testpath,3876,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:2683,usability,tool,toolkit,2683,ore 4.4.0 . jupyterlab 0.35.3 . jupyterlab-server 0.2.0 . Keras-Applications 1.0.8 . Keras-Preprocessing 1.1.0 . keyring 17.0.0 . kiwisolver 1.0.1 . lazy-object-proxy 1.3.1 . libarchive-c 2.8 . lief 0.9.0 . llvmlite 0.26.0 . locket 0.2.0 . lxml 4.2.5 . Markdown 3.1.1 . MarkupSafe 1.1.0 . matplotlib 3.0.2 . mccabe 0.6.1 . mistune 0.8.4 . mkl-fft 1.0.6 . mkl-random 1.0.2 . more-itertools 4.3.0 . mpmath 1.1.0 . msgpack 0.5.6 . multipledispatch 0.6.0 . murmurhash 1.0.2 . nbconvert 5.4.0 . nbformat 4.4.0 . networkx 2.2 . nltk 3.4 . nmslib 1.8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3387,usability,learn,learn,3387,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3510,usability,simpl,simplegeneric,3510,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:3929,usability,tool,toolz,3929,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:4113,usability,widget,widgetsnbextension,4113,8.1 . nose 1.3.7 . notebook 5.7.4 . numba 0.41.0 . numexpr 2.6.8 . numpy 1.15.4 . numpydoc 0.8.0 . odo 0.5.1 . olefile 0.46 . openpyxl 2.5.12 . packaging 18.0 . pandas 0.23.4 . pandocfilters 1.4.2 . parso 0.3.1 . partd 0.3.9 . path.py 11.5.0 . pathlib2 2.3.3 . patsy 0.5.1 . pep8 1.7.1 . pexpect 4.6.0 . pickleshare 0.7.5 . Pillow 5.3.0 . pip 18.1 . pkginfo 1.4.2 . plac 0.9.6 . pluggy 0.8.0 . ply 3.11 . preshed 3.0.2 . prometheus-client 0.5.0 . prompt-toolkit 2.0.7 . protobuf 3.9.1 . psutil 5.4.8 . ptyprocess 0.6.0 . py 1.7.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.4.0 . pycosat 0.6.3 . pycparser 2.19 . pycrypto 2.6.1 . pycurl 7.43.0.2 . pyflakes 2.0.0 . Pygments 2.3.1 . pylint 2.2.2 . pyodbc 4.0.25 . pyOpenSSL 18.0.0 . pyparsing 2.3.0 . PySocks 1.6.8 . pytest 4.0.2 . pytest-arraydiff 0.3 . pytest-astropy 0.5.0 . pytest-doctestplus 0.2.0 . pytest-openfiles 0.3.1 . pytest-remotedata 0.3.1 . python-dateutil 2.7.5 . pytz 2018.7 . PyWavelets 1.0.1 . PyYAML 3.13 . pyzmq 17.1.2 . QtAwesome 0.5.3 . qtconsole 4.4.3 . QtPy 1.5.2 . requests 2.21.0 . rope 0.11.0 . rsa 3.4.2 . ruamel-yaml 0.15.46 . s3transfer 0.2.1 . scikit-image 0.14.1 . scikit-learn 0.21.3 . scipy 1.1.0 . scispacy 0.2.3 . seaborn 0.9.0 . SecretStorage 3.1.0 . Send2Trash 1.5.0 . setuptools 40.6.3 . simplegeneric 0.8.1 . singledispatch 3.4.0.3 . six 1.12.0 . snowballstemmer 1.2.1 . sortedcollections 1.0.1 . sortedcontainers 2.1.0 . spacy 2.2.1 . Sphinx 1.8.2 . sphinxcontrib-websupport 1.1.0 . spyder 3.3.2 . spyder-kernels 0.3.0 . SQLAlchemy 1.2.15 . srsly 0.1.0 . statsmodels 0.9.0 . sympy 1.3 . tables 3.4.4 . tblib 1.3.2 . termcolor 1.1.0 . terminado 0.8.1 . testpath 0.4.2 . thinc 7.1.1 . thinc-gpu-ops 0.0.4 . toolz 0.9.0 . tornado 5.1.1 . tqdm 4.28.1 . traitlets 4.3.2 . unicodecsv 0.14.1 . urllib3 1.24.1 . wasabi 0.2.2 . wcwidth 0.1.7 . webencodings 0.5.1 . Werkzeug 0.14.1 . wheel 0.32.3 . widgetsnbextension 3.4.2 . wrapt 1.11.2 . wurlitzer 1.0.2 . xlrd 1.2.0 . XlsxWriter 1.1.2 . xlwt 1.3.0 . zict 0.1.3.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:11,deployability,upgrad,upgrade,11,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:117,deployability,releas,release,117,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:127,deployability,Version,Version,127,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:66,energy efficiency,model,models,66,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:127,integrability,Version,Version,127,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:148,interoperability,compatib,compatible,148,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:11,modifiability,upgrad,upgrade,11,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:127,modifiability,Version,Version,127,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:66,security,model,models,66,"Ah, please upgrade to scispacy==0.2.4 and redownload the scispacy models (making sure you get the ones for the 0.2.4 release). Version 0.2.3 is not compatible with spacy==2.2.1",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:28,deployability,fail,failing,28,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:40,deployability,upgrad,upgrading,40,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:199,deployability,continu,continues,199,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:449,deployability,resourc,resources,449,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:176,energy efficiency,model,model,176,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:270,energy efficiency,core,core,270,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:275,energy efficiency,CPU,CPU,275,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:292,energy efficiency,GPU,GPU,292,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:410,energy efficiency,model,model,410,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:449,energy efficiency,resourc,resources,449,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:226,integrability,event,eventually,226,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:40,modifiability,upgrad,upgrading,40,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:220,performance,time,time,220,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:275,performance,CPU,CPU,275,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:292,performance,GPU,GPU,292,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:449,performance,resourc,resources,449,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:28,reliability,fail,failing,28,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:376,reliability,Doe,Does,376,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:449,safety,resourc,resources,449,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:176,security,model,model,176,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:410,security,model,model,410,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:449,testability,resourc,resources,449,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:91,usability,help,help,91,"The training process is not failing, so upgrading to scispacy 0.2.4 worked. Thanks for the help. But while training it, i am facing another issue. The training of the scispacy model ""en_core_sci_lg"" continues for a long time, eventually consumes all RAM (on a 64GB , 32 core CPU machine with GPU) and finally crashes after running for around one and a half day in background. Does the further training of this model requires even larger machine and resources ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,availability,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,deployability,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:66,energy efficiency,model,model,66,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:118,energy efficiency,CPU,CPUs,118,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,energy efficiency,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:514,integrability,coupl,couple,514,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:514,modifiability,coupl,couple,514,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:118,performance,CPU,CPUs,118,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:190,performance,time,time,190,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,reliability,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,safety,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:66,security,model,model,66,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:147,testability,monitor,monitor,147,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:514,testability,coupl,couple,514,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:311,usability,command,command,311,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/179:731,usability,help,help,731,"hm, this is unexpected to me. When I trained the `en_core_sci_lg` model, it was on a machine with 64 GB of RAM, and 8 CPUs (and although I did not monitor RAM, I was training it at the same time as `en_core_sci_sm` and `en_core_sci_md` without any issues). Using these scripts (as opposed to the built in spacy command): https://github.com/allenai/scispacy/blob/master/scripts/train_parser_and_tagger.py (for parser and tagger) and https://github.com/allenai/scispacy/blob/master/scripts/train_ner.py (for ner). A couple of questions, what part of the training process did `en_core_sci_lg` make it to (i.e. what output did you see before it crashed)? and, are you able to train `en_core_web_lg` (if not, I would suggest asking for help on the spacy repo)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/179
https://github.com/allenai/scispacy/issues/181:130,deployability,releas,releases,130,"You should be able to use the same links from the readme (which look like this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz or this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_craft_md-0.2.4.tar.gz), but with each `0.2.4` replaced with `0.2.3`. So that would be https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_core_sci_sm-0.2.3.tar.gz or https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_ner_craft_md-0.2.3.tar.gz for example.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:233,deployability,releas,releases,233,"You should be able to use the same links from the readme (which look like this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz or this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_craft_md-0.2.4.tar.gz), but with each `0.2.4` replaced with `0.2.3`. So that would be https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_core_sci_sm-0.2.3.tar.gz or https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_ner_craft_md-0.2.3.tar.gz for example.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:393,deployability,releas,releases,393,"You should be able to use the same links from the readme (which look like this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz or this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_craft_md-0.2.4.tar.gz), but with each `0.2.4` replaced with `0.2.3`. So that would be https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_core_sci_sm-0.2.3.tar.gz or https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_ner_craft_md-0.2.3.tar.gz for example.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:491,deployability,releas,releases,491,"You should be able to use the same links from the readme (which look like this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz or this https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_ner_craft_md-0.2.4.tar.gz), but with each `0.2.4` replaced with `0.2.3`. So that would be https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_core_sci_sm-0.2.3.tar.gz or https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.3/en_ner_craft_md-0.2.3.tar.gz for example.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:165,deployability,pipelin,pipeline,165,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:113,energy efficiency,load,loading,113,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:129,energy efficiency,model,models,129,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:146,energy efficiency,model,model,146,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:165,integrability,pipelin,pipeline,165,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:67,performance,time,time,67,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:113,performance,load,loading,113,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:129,security,model,models,129,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:146,security,model,model,146,"Excellent that indeed works! I must have flubbed the url the first time around - sorry about that. . In terms of loading the NER models, do I add model to the SpaCY pipeline, . e.g. `nlp.add_pipe('en-ner-craft-md')`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:8,energy efficiency,model,models,8,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:38,energy efficiency,model,models,38,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:167,energy efficiency,load,load,167,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:245,energy efficiency,model,models,245,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:263,energy efficiency,current,currently,263,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:344,energy efficiency,model,models,344,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:167,performance,load,load,167,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:8,security,model,models,8,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:38,security,model,models,38,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:245,security,model,models,245,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/181:344,security,model,models,344,"The NER models are their own separate models (they are just the NER pipe trained on top of `en_core_sci_md`), so you would use them the same as the others, `nlp=spacy.load('en_ner_craft_md')`. If you need to combine the output from multiple NER models , we don't currently have a good way to do that, and the suggested way would be to run both models separately and then combine the output however you choose to.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/181
https://github.com/allenai/scispacy/issues/182:53,availability,avail,available,53,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:79,deployability,instal,install,79,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:89,deployability,upgrad,upgrade,89,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:89,modifiability,upgrad,upgrade,89,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:53,reliability,availab,available,53,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:53,safety,avail,available,53,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/182:53,security,availab,available,53,"Fixed upstream, we don't pin pysbd so this should be available by running `pip install --upgrade pysbd`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/182
https://github.com/allenai/scispacy/issues/183:135,deployability,depend,dependency,135,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:253,deployability,api,api,253,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:478,deployability,depend,depending,478,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:135,integrability,depend,dependency,135,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:253,integrability,api,api,253,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:478,integrability,depend,depending,478,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:253,interoperability,api,api,253,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:135,modifiability,depend,dependency,135,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:478,modifiability,depend,depending,478,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:135,safety,depend,dependency,135,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:478,safety,depend,depending,478,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:135,testability,depend,dependency,135,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:478,testability,depend,depending,478,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:58,usability,support,supported,58,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:227,usability,command,command,227,"Hi, relation extraction is not something that is natively supported with spacy or scispacy. You could try to use NER combined with the dependency parser to extract some relations perhaps. You could check out the spacy pretrain command (https://spacy.io/api/cli#pretrain) perhaps for combining pretrained weights with spacy. Your questions might be better suited for the spacy folks (https://github.com/explosion/spaCy) or the biobert folks (https://github.com/dmis-lab/biobert) depending on your goals.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:182,usability,efficien,efficiency,182,"Hello @danielkingai2 , I've read recently that there's a library called kindred which is related to spacy and the main goal of it is to extract biomedical relation, any ideas on its efficiency?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/183:33,modifiability,pac,package,33,"I don't know anything about this package, sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/183
https://github.com/allenai/scispacy/issues/184:67,deployability,pipelin,pipeline,67,"There isn't currently a way to use multiple ner models in the same pipeline. You can definitely run them each independently and then combine results however you like. Also, see this issue (https://github.com/explosion/spaCy/issues/2920) about the same thing.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/184
https://github.com/allenai/scispacy/issues/184:12,energy efficiency,current,currently,12,"There isn't currently a way to use multiple ner models in the same pipeline. You can definitely run them each independently and then combine results however you like. Also, see this issue (https://github.com/explosion/spaCy/issues/2920) about the same thing.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/184
https://github.com/allenai/scispacy/issues/184:48,energy efficiency,model,models,48,"There isn't currently a way to use multiple ner models in the same pipeline. You can definitely run them each independently and then combine results however you like. Also, see this issue (https://github.com/explosion/spaCy/issues/2920) about the same thing.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/184
https://github.com/allenai/scispacy/issues/184:67,integrability,pipelin,pipeline,67,"There isn't currently a way to use multiple ner models in the same pipeline. You can definitely run them each independently and then combine results however you like. Also, see this issue (https://github.com/explosion/spaCy/issues/2920) about the same thing.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/184
https://github.com/allenai/scispacy/issues/184:48,security,model,models,48,"There isn't currently a way to use multiple ner models in the same pipeline. You can definitely run them each independently and then combine results however you like. Also, see this issue (https://github.com/explosion/spaCy/issues/2920) about the same thing.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/184
https://github.com/allenai/scispacy/issues/185:13,usability,document,documentation,13,Where in the documentation do you see that `en_core_sci_sm` should have those entity types? Those look like the entity types for `en_ner_craft_md`.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/185
https://github.com/allenai/scispacy/issues/186:45,deployability,pipelin,pipeline,45,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:61,deployability,contain,contains,61,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:233,energy efficiency,model,model,233,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:12,integrability,discover,discovered,12,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:45,integrability,pipelin,pipeline,45,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:12,interoperability,discover,discovered,12,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:160,safety,test,tested,160,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:233,security,model,model,233,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:160,testability,test,tested,160,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:12,usability,discov,discovered,12,"As you have discovered, `cust_ner` is a full pipeline, which contains an NER pipe. You might be ablet to just add the NER pipe to the `en_core_sci_md`, haven't tested that. However, this shouldn't be necessary. The `en_ner_craft_md` model only retrains the NER pipe from `en_core_sci_md`, the parser and tagger should be equivalent. Are you seeing dramatic differences between the parser/tagger in `en_ner_craft_md` and the parser/tagger in `en_core_sci_md`?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:727,availability,error,error,727,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:793,availability,Error,Error,793,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:87,deployability,modul,modules,87,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:134,deployability,pipelin,pipeline,134,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:168,deployability,pipelin,pipeline,168,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:584,deployability,pipelin,pipeline,584,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:535,energy efficiency,load,load,535,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:612,energy efficiency,load,load,612,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:134,integrability,pipelin,pipeline,134,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:168,integrability,pipelin,pipeline,168,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:584,integrability,pipelin,pipeline,584,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:432,interoperability,specif,specifically,432,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:87,modifiability,modul,modules,87,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:535,performance,load,load,535,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:612,performance,load,load,612,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:727,performance,error,error,727,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:793,performance,Error,Error,793,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:87,safety,modul,modules,87,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:727,safety,error,error,727,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:793,safety,Error,Error,793,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:326,usability,user,user-images,326,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:727,usability,error,error,727,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:793,usability,Error,Error,793,"Thanks for your speedy reply! The parser/tagger do not appear to be included the `ner` modules - neither in the directory nor in the `pipeline`. . when I run `cust_ner.pipeline` I only see `(ner, EntityRecognizer)`. In the actual directory, I see a vocab folder (with vectors files?) and ner folder. . ![en_craft_ner](https://user-images.githubusercontent.com/36715397/70349696-e0f3f980-182a-11ea-8637-57fc228830d7.png). I tried to specifically add the `ner` pipe from craft corpus with the following:. ```python. cust_ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = cust_ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```. but receive an error regarding the `StringStore`:. ```python. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,energy efficiency,model,models,56,"hm, it is possible I made a mistake when training these models. I'll look into this.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,security,model,models,56,"hm, it is possible I made a mistake when training these models. I'll look into this.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:729,deployability,resourc,resources,729,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:274,energy efficiency,core,core-sci-lg,274,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:297,energy efficiency,core,core-sci-md,297,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:320,energy efficiency,core,core-sci-sm,320,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:343,energy efficiency,core,core-web-md,343,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:366,energy efficiency,core,core-web-sm,366,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:729,energy efficiency,resourc,resources,729,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:760,interoperability,plug,pluggy,760,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:679,modifiability,pac,packaging,679,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:729,performance,resourc,resources,729,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:729,safety,resourc,resources,729,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:157,security,certif,certifi,157,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:996,security,rsa,rsa,996,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:729,testability,resourc,resources,729,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1034,usability,learn,learn,1034,"Sorry, it is a bit long. ```python . atomicwrites 1.3.0 . attrs 19.3.0 . autopep8 1.4.4 . awscli 1.16.260 . blis 0.2.4 . boto3 1.9.249 . botocore 1.12.250 . certifi 2019.9.11. chardet 3.0.4 . colorama 0.4.1 . conllu 2.2 . cymem 2.0.2 . Cython 0.29.13 . docutils 0.15.2 . en-core-sci-lg 0.2.3 . en-core-sci-md 0.2.3 . en-core-sci-sm 0.2.4 . en-core-web-md 2.1.0 . en-core-web-sm 2.1.0 . en-ner-craft-md 0.2.3 . en-ner-jnlpba-md 0.2.3 . entrypoints 0.3 . ez-setup 0.9 . flake8 3.7.9 . idna 2.8 . importlib-metadata 0.23 . jmespath 0.9.4 . joblib 0.14.0 . jsonschema 2.6.0 . mccabe 0.6.1 . more-itertools 7.2.0 . murmurhash 1.0.2 . neuralcoref 4.0 . nmslib 1.7.3.6 . numpy 1.17.3 . packaging 19.2 . pandas 0.25.3 . pip 19.3.1 . pkg-resources 0.0.0 . plac 0.9.6 . pluggy 0.13.0 . preshed 2.0.1 . py 1.8.0 . pyasn1 0.4.7 . pybind11 2.4.3 . pycodestyle 2.5.0 . pyflakes 2.1.1 . pyparsing 2.4.2 . pyrsistent 0.15.5 . pytest 5.2.1 . python-dateutil 2.8.0 . pytz 2019.3 . PyYAML 5.1.2 . requests 2.22.0 . rsa 3.4.2 . s3transfer 0.2.1 . scikit-learn 0.21.3 . scipy 1.3.1 . scispacy 0.2.3 . setuptools 39.0.1 . six 1.12.0 . spacy 2.1.3 . srsly 0.1.0 . thinc 7.0.8 . tqdm 4.36.1 . urllib3 1.25.6 . wasabi 0.4.0 . wcwidth 0.1.7 . XlsxWriter 1.2.6 . zipp 0.6.0 . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:3,deployability,upgrad,upgrading,3,"Is upgrading to `scispacy==0.2.4` an option for you? I'm not sure what happened with `0.2.3`, but I just checked `en_ner_craft_md` in `0.2.4` and it has the full pipeline.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:162,deployability,pipelin,pipeline,162,"Is upgrading to `scispacy==0.2.4` an option for you? I'm not sure what happened with `0.2.3`, but I just checked `en_ner_craft_md` in `0.2.4` and it has the full pipeline.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:162,integrability,pipelin,pipeline,162,"Is upgrading to `scispacy==0.2.4` an option for you? I'm not sure what happened with `0.2.3`, but I just checked `en_ner_craft_md` in `0.2.4` and it has the full pipeline.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:3,modifiability,upgrad,upgrading,3,"Is upgrading to `scispacy==0.2.4` an option for you? I'm not sure what happened with `0.2.3`, but I just checked `en_ner_craft_md` in `0.2.4` and it has the full pipeline.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:55,deployability,upgrad,upgrade,55,"Note, you'll to reinstall the models as well if you do upgrade.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:30,energy efficiency,model,models,30,"Note, you'll to reinstall the models as well if you do upgrade.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:55,modifiability,upgrad,upgrade,55,"Note, you'll to reinstall the models as well if you do upgrade.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:30,security,model,models,30,"Note, you'll to reinstall the models as well if you do upgrade.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:80,usability,support,supports,80,"Unfortunately, `0.2.3` is the newest I can go as the `neuralcoref` library only supports `spacy <=2.2.0`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:96,deployability,releas,release,96,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:113,deployability,version,version,113,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:265,deployability,version,versions,265,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:464,deployability,pipelin,pipeline,464,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:579,deployability,version,version,579,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:628,deployability,version,version,628,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:683,deployability,pipelin,pipeline,683,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:156,energy efficiency,core,core,156,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:161,energy efficiency,model,model,161,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:336,energy efficiency,load,load,336,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:383,energy efficiency,load,load,383,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:113,integrability,version,version,113,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:265,integrability,version,versions,265,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:464,integrability,pipelin,pipeline,464,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:579,integrability,version,version,579,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:628,integrability,version,version,628,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:683,integrability,pipelin,pipeline,683,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:113,modifiability,version,version,113,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:265,modifiability,version,versions,265,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:579,modifiability,version,version,579,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:628,modifiability,version,version,628,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:336,performance,load,load,336,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:383,performance,load,load,383,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:161,security,model,model,161,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:854,security,token,token,854,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:869,security,token,token,869,"Well, I'm still not sure what happened with `0.2.3` (@DeNeutoy do you know? I think you did the release for that version), but adding the craft pipe to the core model seems to work for me. Could you try again in a clean environment and make sure you have the right versions of everything? ```. In [1]: import spacy . In [2]: md = spacy.load('en_core_sci_md') . In [3]: craft = spacy.load('en_ner_craft_md') . In [4]: md.remove_pipe('ner') . Out[4]: ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f21b83be8e8>). In [5]: spacy.__version__ . Out[5]: '2.1.3'. In [6]: md.meta['version'] . Out[6]: '0.2.3'. In [7]: craft.meta['version'] . Out[7]: '0.2.3'. In [8]: md.add_pipe(craft.pipeline[0][1], name='ner', last=True) . In [9]: md(""This text has DNA."") . Out[9]: This text has DNA. In [10]: md(""This text has DNA."").ents . Out[10]: (DNA,). In [11]: [token.dep_ for token in md(""This text has DNA."")] . Out[11]: ['det', 'nsubj', 'ROOT', 'dobj', 'punct']. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,availability,error,error,194,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:239,availability,error,error,239,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1380,availability,sli,slightly,1380,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1809,availability,Error,Error,1809,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:44,deployability,version,version,44,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:863,deployability,depend,dependent,863,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1653,deployability,modul,module,1653,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:44,integrability,version,version,44,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:379,integrability,pub,published,379,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:863,integrability,depend,dependent,863,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:44,modifiability,version,version,44,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:863,modifiability,depend,dependent,863,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1653,modifiability,modul,module,1653,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,performance,error,error,194,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:239,performance,error,error,239,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1809,performance,Error,Error,1809,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:91,reliability,doe,does,91,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1203,reliability,stabil,stabilizing,1203,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1380,reliability,sli,slightly,1380,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:65,safety,input,input,65,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,safety,error,error,194,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:239,safety,error,error,239,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:863,safety,depend,dependent,863,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1653,safety,modul,module,1653,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1809,safety,Error,Error,1809,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:112,security,access,access,112,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1697,security,token,tokens,1697,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1762,security,token,tokens,1762,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:27,testability,verif,verified,27,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:678,testability,understand,understand,678,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:863,testability,depend,dependent,863,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1589,testability,Trace,Traceback,1589,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:65,usability,input,input,65,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,usability,error,error,194,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:239,usability,error,error,239,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1107,usability,indicat,indicate,1107,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:1809,usability,Error,Error,1809,"I created a clean venv and verified correct version and the text input `This text has DNA` does not fuss when I access the `ents` attribute but other text examples still yield the `StringStore` error. . Here is the code that generates the error:. ```python . >>> ab = md(""""""Regulation of c-jun mRNA expression by hydroxyurea in human K562 cells during erythroid differentiation [published erratum appears in Biochim Biophys Acta 1995 Dec 27;1264(3):409] . ... ... Hydroxyurea (HU) is an antitumor agent which also induces hemoglobinization during erythroid differentiation. In addition, HU stimulates the synthesis of fetal hemoglobin in sickle cell anemia patients. To further understand its mechanism of action, we investigated the effects of HU on regulation of c-jun expression prior to the onset of erythroid differentiation of K562 cells. HU induced a dose-dependent stimulation of c-jun synthesis. The levels of c-jun mRNA was elevated 4 to 7.5-fold by HU within 2 h. This was followed by a gradual decline to the basal level by 24 h. Both nuclear run-on and actinomycin D pulse experiments strongly indicate that HU regulates c-jun mRNA expression by increasing the rate of synthesis as well as stabilizing the c-jun mRNA. In addition, the level of jun protein was elevated by 2 to 5-fold within 4 h in HU treated cells. Furthermore, concentrations of HU below 250 microM slightly increased the 5X AP-1/CAT activity. These results strongly suggest that HU induces both transcriptional and post-transcription regulation of c-jun during erythroid differentiation. """"""). >>> ab.ents. Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""doc.pyx"", line 496, in spacy.tokens.doc.Doc.ents.__get__. File ""span.pyx"", line 114, in spacy.tokens.span.Span.__cinit__. ValueError: [E084] Error assigning label ID 15990443803332177159 to span: not in StringStore. >>> . ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:14,availability,down,down,14,"Well i got it down to this text that causes the crash `""""""expression hydroxyurea in"""""" `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:54,security,token,tokenization,54,It looks like maybe something weird is happening with tokenization and the added pipe,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:64,energy efficiency,model,model,64,Hm. I think I got it to work! If I use the vocab from the `ner` model within `sci_md` it works.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:64,security,model,model,64,Hm. I think I got it to work! If I use the vocab from the `ner` model within `sci_md` it works.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:66,deployability,releas,release,66,"oh nice! Sorry about that, we got something wrong for the `0.2.3` release there.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:10,interoperability,share,share,10,Could you share the code that works?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:275,deployability,depend,depend,275,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:377,deployability,log,logic,377,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:639,deployability,pipelin,pipeline,639,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:524,energy efficiency,model,model,524,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:545,energy efficiency,model,model,545,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:595,energy efficiency,load,load,595,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:667,energy efficiency,load,load,667,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:275,integrability,depend,depend,275,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:639,integrability,pipelin,pipeline,639,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:275,modifiability,depend,depend,275,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:595,performance,load,load,595,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:667,performance,load,load,667,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:275,safety,depend,depend,275,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:377,safety,log,logic,377,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:290,security,token,tokenizer,290,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:377,security,log,logic,377,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:524,security,model,model,524,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:545,security,model,model,545,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:275,testability,depend,depend,275,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:377,testability,log,logic,377,"So unfortunately the best I could do was to manually replace the `vocab` dir in the `core_sci_md` folder with the `vocab` found in the `ner_craft_md` folder. I tried various ways to not have to manually copy the `vocab` folder, but none worked. It seems the `tagger, parser` depend on the `tokenizer` in the `sci_md` and the `ner` relies on the `vocab`. I tried to follow this logic and create a `Language` object from class but it did not work for me. . After moving the `vocab` dir, replace the `ner` pipe in the `sci_md` model with the `ner` model as shown below:. ```python. ner_mod = spacy.load('en_ner_craft_md'). ner_pipe = ner_mod.pipeline[0][1]. nlp = spacy.load('en_core_sci_md'). nlp.remove_pipe('ner'). nlp.add_pipe(ner_pipe, name=""ner"", last=True). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:393,availability,error,error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model,393,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:80,deployability,contain,contained,80,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:99,deployability,pipelin,pipeline,99,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:244,deployability,contain,contains,244,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:474,deployability,depend,dependency-parsing-model,474,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:73,energy efficiency,model,models,73,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:184,energy efficiency,model,model,184,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:444,energy efficiency,model,model-from-prodigy-with-spacy-dependency-parsing-model,444,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:757,energy efficiency,model,model,757,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:5,integrability,coupl,couple,5,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:99,integrability,pipelin,pipeline,99,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:474,integrability,depend,dependency-parsing-model,474,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:5,modifiability,coupl,couple,5,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:474,modifiability,depend,dependency-parsing-model,474,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:393,performance,error,error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model,393,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:393,safety,error,error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model,393,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:73,security,model,models,73,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:184,security,model,model,184,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:444,security,model,model-from-prodigy-with-spacy-dependency-parsing-model,444,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:757,security,model,model,757,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:5,testability,coupl,couple,5,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:474,testability,depend,dependency-parsing-model,474,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:374,usability,support,support,374,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:393,usability,error,error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model,393,"hmm, couple of issues here:. 1. Until 0.2.4, none of the specialised NER models contained the full pipeline. I didn't add it in because it fits with spacy's naming convention `{lang}_{model}_{data}_{size}`. It's not really a problem that 0.2.4 contains them (just a miscommunication between Daniel and I), and maybe it's actually a good thing given this problem. 2. https://support.prodi.gy/t/error-assigning-label-id-when-combining-custom-ner-model-from-prodigy-with-spacy-dependency-parsing-model/1444/2 This seems to be a similar problem. Basically what I think is happening is that spacy assumes that all NER labels are in the vocabulary - here they are not, because the vocabs are different. You might find that just adding the literal strings the NER model needs for its labels to the vocabulary of the one for the parser/tagger works.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:504,availability,error,error,504,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,deployability,pipelin,pipeline,56,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:169,deployability,contain,contains,169,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:415,deployability,pipelin,pipeline,415,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:461,deployability,pipelin,pipeline,461,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:101,energy efficiency,model,models,101,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,integrability,pipelin,pipeline,56,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:415,integrability,pipelin,pipeline,415,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:461,integrability,pipelin,pipeline,461,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:504,performance,error,error,504,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:504,safety,error,error,504,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:101,security,model,models,101,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:279,security,token,tokens,279,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:504,usability,error,error,504,"Also, I should have used the base vocab from the medium pipeline when training these specialised NER models, meaning that the NER vocab should be strictly larger (as it contains only the additional labels), although I am not confident that is the case - it's possible spacy adds tokens it sees during training on the fly to the vocab or something that I don't know about. If you try just setting the vocab from the pipeline equal to the vocab from the ner-only pipeline, do you get that same stringstore error when trying to use the parser? That would at least make sense...",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,availability,error,error,56,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:158,energy efficiency,load,load,158,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:206,energy efficiency,load,load,206,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,performance,error,error,56,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:158,performance,load,load,158,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:206,performance,load,load,206,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,safety,error,error,56,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:56,usability,error,error,56,I did try just setting the vocab equal and got the same error. Looks like your hope about the relative size of them isn't the case:. ```. In [96]: md = spacy.load('en_core_sci_md') . In [97]: craft = spacy.load('en_ner_craft_md') . In [98]: len(md.vocab) . Out[98]: 386148. In [99]: len(craft.vocab) . Out[99]: 363532. ```,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:25,energy efficiency,model,model,25,I'm confused how the ner model ended up with a smaller vocab...,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:25,security,model,model,25,I'm confused how the ner model ended up with a smaller vocab...,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:28,deployability,build,building,28,"@masonedmison you could try building spacy and neuralcoref from source as suggested here (https://github.com/huggingface/neuralcoref/issues/197). don't really know if this would work with scispacy or not, but maybe worth a shot unless the vocab copying thing is working alright for you.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:131,deployability,modul,module,131,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,deployability,pipelin,pipeline,194,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:83,energy efficiency,model,model,83,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:194,integrability,pipelin,pipeline,194,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:131,modifiability,modul,module,131,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:342,performance,time,time,342,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:131,safety,modul,module,131,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:83,security,model,model,83,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:351,usability,help,help,351,"@danielkingai2 I just ended up manually moving over the vocab file to the `sci_md` model, then adding the `ner` pipe for the `ner` module, then use the `spacy.Language.to_disk` to save the full pipeline with the specialized `ner`. Not the most pretty process, but only needs done once and it seems to work as expected. Thanks for all of your time and help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:7,deployability,build,build,7,"We now build the specialised NER models with the parser and tagger inside them, so I think we can close this issue. Please reopen if not!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:33,energy efficiency,model,models,33,"We now build the specialised NER models with the parser and tagger inside them, so I think we can close this issue. Please reopen if not!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:33,security,model,models,33,"We now build the specialised NER models with the parser and tagger inside them, so I think we can close this issue. Please reopen if not!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/issues/186:98,usability,close,close,98,"We now build the specialised NER models with the parser and tagger inside them, so I think we can close this issue. Please reopen if not!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/186
https://github.com/allenai/scispacy/pull/188:18,deployability,fail,failed,18,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:18,reliability,fail,failed,18,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:160,reliability,doe,doesn,160,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:276,reliability,doe,doesn,276,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:29,safety,test,test,29,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:29,testability,test,test,29,"After checking, I failed the test case due to the broken sentence splitter. It splits the sentence ""1-Methyl-4-phenylpyridinium (MPP+) is an abbreviation which doesn't exist in the baby index."" into 2 pieces: ""1-Methyl-4-phenylpyridinium"" and ""(MPP+) is an abbreviation which doesn't exist in the baby index."". This is weird and I don't know what I should do for this case. Please let me know your idea. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:140,deployability,fail,failing,140,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:140,reliability,fail,failing,140,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:93,safety,test,test,93,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:100,safety,Test,TestAbbreviationDetector,100,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:93,testability,test,test,93,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/pull/188:100,testability,Test,TestAbbreviationDetector,100,"@dnanhkhoa thanks for the PR! It looks like there is some bug in your implementation as this test (`TestAbbreviationDetector.test_find`) is failing: https://github.com/allenai/scispacy/runs/364816000#step:3:625 . . I don't think this is due to the sentence splitting, but I could be wrong. Maybe if you fix this one, the other one will also resolve?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/188
https://github.com/allenai/scispacy/issues/189:73,reliability,doe,does,73,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:21,safety,detect,detector,21,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:30,safety,detect,detects,30,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:258,safety,detect,detector,258,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:21,security,detect,detector,21,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:30,security,detect,detects,30,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:258,security,detect,detector,258,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:135,usability,document,document,135,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:327,usability,document,document,327,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:354,usability,clear,clearer,354,"Ah! The Abbreviation detector detects abbreviations defined in text, but does not try to disambiguate arbitrary abbreviations. So in a document, you had `blah blah... computed tomography angiography (CTA) was used ... After, CTA was done.`, the abbreviation detector would find the definition and connect it to its uses in the document. Hopefully that's clearer?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:158,availability,state,statement,158,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:15,energy efficiency,current,current,15,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:158,integrability,state,statement,158,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:137,safety,detect,detector,137,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:137,security,detect,detector,137,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:95,testability,plan,plan,95,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:51,usability,behavi,behavior,51,"Understood the current implementation and expected behavior. However, just curious, is there a plan to implement ""arbitrary abbreviation detector"" on a given statement ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/189:30,interoperability,specif,specific,30,"No, sorry. That's very domain specific, and wouldn't be useful generally. It should be easy to implement (just a dictionary lookup) for any given abbreviations you have though!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/189
https://github.com/allenai/scispacy/issues/190:192,availability,error,errors,192,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:271,deployability,updat,updating,271,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:43,energy efficiency,model,models,43,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:92,energy efficiency,model,model,92,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:177,energy efficiency,model,models,177,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:284,energy efficiency,model,model,284,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:377,integrability,abstract,abstracts,377,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:377,modifiability,abstract,abstracts,377,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:127,performance,perform,performance,127,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:192,performance,error,errors,192,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:192,safety,error,errors,192,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:271,safety,updat,updating,271,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:43,security,model,models,43,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:92,security,model,model,92,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:177,security,model,models,177,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:271,security,updat,updating,271,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:284,security,model,model,284,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:127,usability,perform,performance,127,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:192,usability,error,errors,192,"Hi,. This seems to be a side effect of the models with vectors, sorry! If you try the small model, it is correct. Broadly, the performance is within ~1% of the medium and large models and the errors are often a bit more ""sensible"". The other thing you could try doing is updating the model a bit on your data, as the syntax of search queries is a bit different from biomedical abstracts.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:24,energy efficiency,model,models,24,FYI you can try out the models here:. https://scispacy.apps.allenai.org/.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:24,security,model,models,24,FYI you can try out the models here:. https://scispacy.apps.allenai.org/.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:101,energy efficiency,model,model,101,"@nikolamilosevic86 just tagging you so you saw this - I think you might be better off with the small model? Closing, as this is just a difficulty with statistical models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:163,energy efficiency,model,models,163,"@nikolamilosevic86 just tagging you so you saw this - I think you might be better off with the small model? Closing, as this is just a difficulty with statistical models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:101,security,model,model,101,"@nikolamilosevic86 just tagging you so you saw this - I think you might be better off with the small model? Closing, as this is just a difficulty with statistical models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/190:163,security,model,models,163,"@nikolamilosevic86 just tagging you so you saw this - I think you might be better off with the small model? Closing, as this is just a difficulty with statistical models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/190
https://github.com/allenai/scispacy/issues/191:475,availability,sli,slightly,475,"Hi @izuna385, sorry this is a little complicated: . The concept_aliases list is created here. It is all of the possible alias names for all entities. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L314. Later on, when it is used, we do ann lookup in ""alias space"", and then return all canonical entities that have this alias. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L253. The reason we do it in this slightly backward way (matching aliases, and then finding entities which have them as an alias) is explained in this comment here:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L94. Hopefully that helps! Let me know if you have any questions. Certainly I think the alias list is inefficient in some way, but it works for now :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:475,reliability,sli,slightly,475,"Hi @izuna385, sorry this is a little complicated: . The concept_aliases list is created here. It is all of the possible alias names for all entities. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L314. Later on, when it is used, we do ann lookup in ""alias space"", and then return all canonical entities that have this alias. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L253. The reason we do it in this slightly backward way (matching aliases, and then finding entities which have them as an alias) is explained in this comment here:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L94. Hopefully that helps! Let me know if you have any questions. Certainly I think the alias list is inefficient in some way, but it works for now :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:37,safety,compl,complicated,37,"Hi @izuna385, sorry this is a little complicated: . The concept_aliases list is created here. It is all of the possible alias names for all entities. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L314. Later on, when it is used, we do ann lookup in ""alias space"", and then return all canonical entities that have this alias. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L253. The reason we do it in this slightly backward way (matching aliases, and then finding entities which have them as an alias) is explained in this comment here:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L94. Hopefully that helps! Let me know if you have any questions. Certainly I think the alias list is inefficient in some way, but it works for now :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:37,security,compl,complicated,37,"Hi @izuna385, sorry this is a little complicated: . The concept_aliases list is created here. It is all of the possible alias names for all entities. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L314. Later on, when it is used, we do ann lookup in ""alias space"", and then return all canonical entities that have this alias. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L253. The reason we do it in this slightly backward way (matching aliases, and then finding entities which have them as an alias) is explained in this comment here:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L94. Hopefully that helps! Let me know if you have any questions. Certainly I think the alias list is inefficient in some way, but it works for now :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:708,usability,help,helps,708,"Hi @izuna385, sorry this is a little complicated: . The concept_aliases list is created here. It is all of the possible alias names for all entities. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L314. Later on, when it is used, we do ann lookup in ""alias space"", and then return all canonical entities that have this alias. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L253. The reason we do it in this slightly backward way (matching aliases, and then finding entities which have them as an alias) is explained in this comment here:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L94. Hopefully that helps! Let me know if you have any questions. Certainly I think the alias list is inefficient in some way, but it works for now :).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:45,safety,avoid,avoiding,45,"Thanks for detailed descriptions. seems like avoiding fixed candidates for mentions which might have same alias. (For top1 candidates per mentions which may have many entities in alias table, we have to choose randomly from them, because only clues we have are string and alias table.)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:330,interoperability,share,share,330,"Basically, the problem is that if you have some canonical entities like:. ```. ""Ford County, Texas"": [""Ford County"", ""Ford County, Texas""]. ""Ford County, Alabama"": [""Ford County"", ""Ford County, Alabama""]. etc. ```. And you encounter the string ""Ford County"" in some text, there is no way to know which canonical entity (which all share the same alias which is an exact match) you should link to. So we default to returning all of them. Obviously this is the point at which Entity Linking becomes difficult and actually interesting, but the good thing is that this doesn't happen hugely often 😄 .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:564,reliability,doe,doesn,564,"Basically, the problem is that if you have some canonical entities like:. ```. ""Ford County, Texas"": [""Ford County"", ""Ford County, Texas""]. ""Ford County, Alabama"": [""Ford County"", ""Ford County, Alabama""]. etc. ```. And you encounter the string ""Ford County"" in some text, there is no way to know which canonical entity (which all share the same alias which is an exact match) you should link to. So we default to returning all of them. Obviously this is the point at which Entity Linking becomes difficult and actually interesting, but the good thing is that this doesn't happen hugely often 😄 .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:206,energy efficiency,Current,Currently,206,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:358,energy efficiency,model,model,358,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:85,performance,perform,performance,85,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:164,safety,test,test,164,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:301,safety,detect,detection,301,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:301,security,detect,detection,301,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:358,security,model,model,358,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:164,testability,test,test,164,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:85,usability,perform,performance,85,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:387,usability,document,document,387,"Actually why I ask this question is, to check the surface-based candidate generation performance. Is there any report for top-K recall of MedMentions or st21pv dev/test when only mention's span are given? (Currently, my interesting is only candidate generation when mention-span is given, and mention detection is not included. Also, I'm interested in local model, in which sentences in document are separately considered.). This [link](https://github.com/allenai/scispacy/issues/134#issuecomment-510358152)'s ""Soft Matching"" meets this situation?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:123,deployability,continu,continuous,123,"I personally used candidate_generator.py and checked recall with MedMentions dev sets, under local model. Apologies for my continuous comments, and this issue can be closed. ```. baseline: top1 string is gold acc 49.393338058114814 %. baseline: top1 string is gold acc normalized 61.25329583406574 %. dev data crosswiki top 10 recall 69.579 %. dev data crosswiki top 25 recall 72.439 %. dev data crosswiki top 50 recall 74.102 %. dev data crosswiki top 75 recall 74.846 %. dev data crosswiki top 100 recall 75.433 %. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:99,energy efficiency,model,model,99,"I personally used candidate_generator.py and checked recall with MedMentions dev sets, under local model. Apologies for my continuous comments, and this issue can be closed. ```. baseline: top1 string is gold acc 49.393338058114814 %. baseline: top1 string is gold acc normalized 61.25329583406574 %. dev data crosswiki top 10 recall 69.579 %. dev data crosswiki top 25 recall 72.439 %. dev data crosswiki top 50 recall 74.102 %. dev data crosswiki top 75 recall 74.846 %. dev data crosswiki top 100 recall 75.433 %. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:99,security,model,model,99,"I personally used candidate_generator.py and checked recall with MedMentions dev sets, under local model. Apologies for my continuous comments, and this issue can be closed. ```. baseline: top1 string is gold acc 49.393338058114814 %. baseline: top1 string is gold acc normalized 61.25329583406574 %. dev data crosswiki top 10 recall 69.579 %. dev data crosswiki top 25 recall 72.439 %. dev data crosswiki top 50 recall 74.102 %. dev data crosswiki top 75 recall 74.846 %. dev data crosswiki top 100 recall 75.433 %. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:2,usability,person,personally,2,"I personally used candidate_generator.py and checked recall with MedMentions dev sets, under local model. Apologies for my continuous comments, and this issue can be closed. ```. baseline: top1 string is gold acc 49.393338058114814 %. baseline: top1 string is gold acc normalized 61.25329583406574 %. dev data crosswiki top 10 recall 69.579 %. dev data crosswiki top 25 recall 72.439 %. dev data crosswiki top 50 recall 74.102 %. dev data crosswiki top 75 recall 74.846 %. dev data crosswiki top 100 recall 75.433 %. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:166,usability,close,closed,166,"I personally used candidate_generator.py and checked recall with MedMentions dev sets, under local model. Apologies for my continuous comments, and this issue can be closed. ```. baseline: top1 string is gold acc 49.393338058114814 %. baseline: top1 string is gold acc normalized 61.25329583406574 %. dev data crosswiki top 10 recall 69.579 %. dev data crosswiki top 25 recall 72.439 %. dev data crosswiki top 50 recall 74.102 %. dev data crosswiki top 75 recall 74.846 %. dev data crosswiki top 100 recall 75.433 %. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:61,deployability,depend,depends,61,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:61,integrability,depend,depends,61,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:61,modifiability,depend,depends,61,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:344,modifiability,paramet,parameter,344,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:266,performance,perform,performance,266,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:61,safety,depend,depends,61,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:61,testability,depend,depends,61,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:266,usability,perform,performance,266,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:623,usability,user,user-images,623,"Yes, this is similar to what we found. However, note that it depends a lot on the quality of the knowledge base - UMLS is quite noisy, which means that very often, a reasonable alternative entity is suggested, even though it is not ""correct"". Also, when focusing on performance for the entity linker, you might want to consider increasing this parameter: https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L47. Here is a picture of our results for candidate generation using Gold Mentions on the med mentions dev data:. <img width=""405"" alt=""Screen Shot 2020-02-10 at 8 08 07 AM"" src=""https://user-images.githubusercontent.com/16001974/74167115-9c932a00-4bdc-11ea-91bf-b3f0a30a2dda.png"">.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:341,deployability,version,version,341,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:162,energy efficiency,model,model,162,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:341,integrability,version,version,341,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:51,modifiability,paramet,parameters,51,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:341,modifiability,version,version,341,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:125,performance,perform,performance,125,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:162,security,model,model,162,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/191:125,usability,perform,performance,125,"Thanks for detailed reports. I'll try and re-check parameters of candidate_generator in my own. Because candidate generation performance is crucial to my linking model, if I have another question, I might ask you again. Thank you in advance. . p.s. I now rechecked paper and found that section 5 (candidate generation) was added to previous version. I didn't notice that. Sorry for inconvenience... Based on your comments I try to reproduce candidate recall (Figure 3. in paper, or table you give in the above). Again thanks for the details.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/191
https://github.com/allenai/scispacy/issues/192:124,integrability,sub,submit,124,"Hi @fj-morales, it seems quite reasonable to assume that short form abbreviations will be a single token. Would you like to submit a PR with the change (and a small test demonstrating that single token short form abbreviations can be extracted?).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/192
https://github.com/allenai/scispacy/issues/192:165,safety,test,test,165,"Hi @fj-morales, it seems quite reasonable to assume that short form abbreviations will be a single token. Would you like to submit a PR with the change (and a small test demonstrating that single token short form abbreviations can be extracted?).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/192
https://github.com/allenai/scispacy/issues/192:99,security,token,token,99,"Hi @fj-morales, it seems quite reasonable to assume that short form abbreviations will be a single token. Would you like to submit a PR with the change (and a small test demonstrating that single token short form abbreviations can be extracted?).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/192
https://github.com/allenai/scispacy/issues/192:196,security,token,token,196,"Hi @fj-morales, it seems quite reasonable to assume that short form abbreviations will be a single token. Would you like to submit a PR with the change (and a small test demonstrating that single token short form abbreviations can be extracted?).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/192
https://github.com/allenai/scispacy/issues/192:165,testability,test,test,165,"Hi @fj-morales, it seems quite reasonable to assume that short form abbreviations will be a single token. Would you like to submit a PR with the change (and a small test demonstrating that single token short form abbreviations can be extracted?).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/192
https://github.com/allenai/scispacy/issues/193:170,deployability,Continu,ContinuumIO,170,"Hi, this appears to be a problem with anaconda and the terminal you are using, rather than a problem with scisapcy - maybe take a look at this issue:. https://github.com/ContinuumIO/anaconda-issues/issues/1831. If you can't fix it and figure out that it is a scispacy issue directly, please re-open!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/193
https://github.com/allenai/scispacy/pull/194:39,reliability,doe,does,39,"Hi, thanks for the PR! How much bigger does this make the json file? I'm not sure we'll accept this change, because you could just create this mapping separately and use it (i.e it is not actually required to train the linker). Hopefully that makes sense? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:281,interoperability,ontolog,ontology,281,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:459,interoperability,ontolog,ontology,459,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:829,interoperability,ontolog,ontology-aware,829,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:521,reliability,diagno,diagnosis,521,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:42,security,access,access,42,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:266,security,access,access,266,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:349,security,sign,signal,349,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:521,testability,diagno,diagnosis,521,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:424,usability,prefer,preference,424,"I can't compare exactly (since I only had access to MRCONSO, not the other files), but maybe 800MB or so? So way bigger. Totally reasonable to map things separately for exactly the reason you suggest. That said, I think there could be some heuristic value to having access to code/ontology data in the linker -- the count of mapped codes could be a signal for CUI importance/relevance, or you could link in a way that gives preference to a particular codeset/ontology (e.g., require ICD10CM linkages for entities in the ""diagnosis vector space""). I'm trying to come up with a good example use case for this heuristic, but all the entity-CUI linking misses I'm seeing are mostly from common clinical abbreviations (e.g., ""CAD"" for coronary artery disease, ""DM2"" for type 2 diabetes) that I don't think would be solved by using an ontology-aware linker (since those abbreviations aren't in MRCONSO in a useful way). I'll keep looking for a good example of where this would be useful, but for now it's just a hunch.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:114,performance,perform,performance,114,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:37,safety,detect,detector,37,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:37,security,detect,detector,37,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:88,usability,help,help,88,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:114,usability,perform,performance,114,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/pull/194:173,usability,close,close,173,"Gotcha - FYI we have an abbreviation detector, which if you run before the linker, will help abbreviation linking performance - you might want to try it out! . I'm going to close this, as I think until we have a concrete use-case, it might be best to leave it out.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/194
https://github.com/allenai/scispacy/issues/195:77,energy efficiency,gpu,gpu,77,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:125,energy efficiency,core,core,125,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:136,energy efficiency,model,models,136,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:19,interoperability,specif,specific,19,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:77,performance,gpu,gpu,77,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:136,security,model,models,136,Is this a scispacy specific issue? could you see if you can get vectors with gpu enabled in your environment with one of the core spacy models? This is likely to be a spacy issue (as you notice from the linked issues),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2583,deployability,modul,module,2583,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:23,energy efficiency,GPU,GPU,23,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:53,energy efficiency,core,core,53,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:64,energy efficiency,model,models,64,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:312,energy efficiency,load,load,312,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:352,energy efficiency,load,load,352,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2643,energy efficiency,core,core,2643,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2648,energy efficiency,core,core,2648,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2665,energy efficiency,core,core,2665,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2670,energy efficiency,core,core,2670,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2699,energy efficiency,core,core,2699,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2724,energy efficiency,core,core,2724,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2760,energy efficiency,core,core,2760,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2785,energy efficiency,core,core,2785,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:155,interoperability,conflict,conflict,155,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2583,modifiability,modul,module,2583,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:23,performance,GPU,GPU,23,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:312,performance,load,load,312,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:352,performance,load,load,352,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2556,safety,input,input-,2556,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2583,safety,modul,module,2583,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:64,security,model,models,64,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2512,testability,Trace,Traceback,2512,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:119,usability,interact,interact,119,"I can get vectors with GPU enabled, using one of the core spacy models. . I'm not familiar with how scispacy and spacy interact, but it seems there's some conflict when`spacy.prefer_gpu()` is run, and how scispacy grabs the vectors? ```python. import spacy. spacy.prefer_gpu(). import scispacy. nlp_core = spacy.load(""en_core_web_sm""). nlp_sci = spacy.load(""en_core_sci_lg""). text1 = ""Apple is looking at buying a U.K. startup."". text2 ="""""". Myeloid derived suppressor cells (MDSC) are immature . myeloid cells with immunosuppressive activity. . They accumulate in tumor-bearing mice and humans . with different types of cancer, including hepatocellular . carcinoma (HCC). """""". doc1 = nlp_core(text1). doc2 = nlp_sci(text2). doc1.vector. ```. ```python. array([ 1.87626123e+00, 1.74610004e-01, -4.07206148e-01, 1.36689353e+00,. 1.40843523e+00, 6.05548732e-03, 1.66239119e+00, -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.9",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:2556,usability,input,input-,2556,", -9.30897593e-01,. 4.57793772e-01, 8.95731628e-01, -3.08286622e-02, -1.05232155e+00,. -9.10535514e-01, -4.45902228e-01, -1.26608491e+00, -1.16015565e+00,. -7.04167783e-01, -1.32227492e+00, 2.44126424e-01, -1.16682744e+00,. 1.01085961e+00, -1.08586415e-03, 5.55718184e-01, 3.72446686e-01,. -9.01190221e-01, 1.23116934e+00, -6.60890281e-01, 6.00397348e-01,. 5.54930389e-01, -8.53769362e-01, 6.49879932e-01, 7.13668883e-01,. 1.02024949e+00, -9.36036825e-01, 4.99367177e-01, -1.58682418e+00,. 9.09082830e-01, -1.30400848e+00, -2.59107184e+00, -5.57143390e-01,. 1.04673874e+00, -3.63536745e-01, -1.13535136e-01, -8.38947952e-01,. -5.15586138e-01, 3.48068118e-01, 4.34633315e-01, 8.31843376e-01,. -1.80327475e+00, 1.34507072e+00, 8.74345064e-01, -1.11486959e+00,. 6.44101799e-01, 3.26330513e-01, -1.77515948e+00, 1.20124876e+00,. 5.46832561e-01, 4.90726799e-01, 8.51599455e-01, 3.70686591e-01,. 1.27395010e+00, 3.82406980e-01, 1.10774016e+00, 2.99000680e-01,. 1.01485348e+00, 1.80296153e-01, 3.69155794e-01, -2.23638988e+00,. -1.13989949e+00, 1.15371501e+00, 1.25055921e+00, -6.30269468e-01,. -4.70783919e-01, -1.00702071e+00, -8.97607952e-02, 1.85000479e-01,. 1.25299013e+00, -9.43444371e-01, -9.46472824e-01, -1.07134831e+00,. 5.28648794e-01, -1.34740043e+00, 3.15346926e-01, -9.12814960e-02,. 8.59327018e-01, 1.32857764e+00, -9.96670604e-01, 1.10705197e+00,. -4.88456368e-01, 4.50987555e-02, -9.75819349e-01, -1.79819620e+00,. 1.05998307e-01, 7.29284525e-01, 1.14333367e+00, 8.58014762e-01],. dtype=float32). ```. ```python. doc2.vector. ```. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-12-02f8cd16c309> in <module>(). ----> 1 doc2.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:112,deployability,patch,patch,112,"I suspect this might be related to [#4680](https://github.com/explosion/spaCy/pull/4680) in SpaCy, although the patch should be merged for v2.2.3?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:112,safety,patch,patch,112,"I suspect this might be related to [#4680](https://github.com/explosion/spaCy/pull/4680) in SpaCy, although the patch should be merged for v2.2.3?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:112,security,patch,patch,112,"I suspect this might be related to [#4680](https://github.com/explosion/spaCy/pull/4680) in SpaCy, although the patch should be merged for v2.2.3?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:68,energy efficiency,model,model,68,"Could you try it with `en_core_web_lg`? It crashes for me with that model, suggesting it is a spacy issue rather than a scispacy issue. For what its worth, it also doesn't crash for me if i just type out the text you provided, something about the formatting seems to cause the crash although i did not figure out exactly what yet.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:247,interoperability,format,formatting,247,"Could you try it with `en_core_web_lg`? It crashes for me with that model, suggesting it is a spacy issue rather than a scispacy issue. For what its worth, it also doesn't crash for me if i just type out the text you provided, something about the formatting seems to cause the crash although i did not figure out exactly what yet.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:164,reliability,doe,doesn,164,"Could you try it with `en_core_web_lg`? It crashes for me with that model, suggesting it is a spacy issue rather than a scispacy issue. For what its worth, it also doesn't crash for me if i just type out the text you provided, something about the formatting seems to cause the crash although i did not figure out exactly what yet.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:68,security,model,model,68,"Could you try it with `en_core_web_lg`? It crashes for me with that model, suggesting it is a spacy issue rather than a scispacy issue. For what its worth, it also doesn't crash for me if i just type out the text you provided, something about the formatting seems to cause the crash although i did not figure out exactly what yet.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:4,deployability,updat,update,4,Any update on this?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:4,safety,updat,update,4,Any update on this?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:4,security,updat,update,4,Any update on this?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:538,deployability,modul,module,538,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:878,deployability,version,versions,878,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:141,energy efficiency,load,load,141,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:226,energy efficiency,model,models,226,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:628,energy efficiency,core,core,628,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:633,energy efficiency,core,core,633,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:650,energy efficiency,core,core,650,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:655,energy efficiency,core,core,655,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:684,energy efficiency,core,core,684,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:709,energy efficiency,core,core,709,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:745,energy efficiency,core,core,745,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:770,energy efficiency,core,core,770,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:878,integrability,version,versions,878,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:538,modifiability,modul,module,538,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:870,modifiability,pac,package,870,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:878,modifiability,version,versions,878,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:141,performance,load,load,141,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:263,safety,test,test,263,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:512,safety,input,input-,512,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:538,safety,modul,module,538,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:226,security,model,models,226,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:263,testability,test,test,263,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:468,testability,Trace,Traceback,468,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:56,usability,document,documentation,56,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/195:512,usability,input,input-,512,"Hi @danielkingai2,. I also see your problem. . For full documentation's sake:. ```python. import spacy. spacy.prefer_gpu(). nlp_core = spacy.load(""en_core_web_lg""). text1 = ""The effect of anxiogenic treatments on three rodent models of anxiety: \. the open field test, the elevated plus-maze, and the light-dark box."". doc1 = nlp_core(text1). doc1.vector. ```. produces. ```shell. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-3-531ef58ab65a> in <module>(). 1 doc1 = nlp_core(text1). 2 . ----> 3 doc1.vector. doc.pyx in __iter__(). cupy/core/core.pyx in cupy.core.core.ndarray.__add__(). cupy/core/_kernel.pyx in cupy.core._kernel.ufunc.__call__(). cupy/core/_kernel.pyx in cupy.core._kernel._preprocess_args(). TypeError: Unsupported type <class 'numpy.ndarray'>. ```. Relevant package versions:. ```python. print(spacy.__version__). print(cupy.__version__). ```. ```shell. 2.2.3. 7.2.0. ```. Closing this for now as it seems it's a spacy issue and not scispacy's.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/195
https://github.com/allenai/scispacy/issues/197:100,deployability,infrastructur,infrastructure,100,"Hi @karelin! The demo code (i.e the actual repo) is closed source because it uses some internal AI2 infrastructure, but the streamlit part is here in this gist:. https://gist.github.com/DeNeutoy/b20860b40b9fa9d33675893c56afde42.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:52,usability,close,closed,52,"Hi @karelin! The demo code (i.e the actual repo) is closed source because it uses some internal AI2 infrastructure, but the streamlit part is here in this gist:. https://gist.github.com/DeNeutoy/b20860b40b9fa9d33675893c56afde42.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:202,availability,replic,replicating,202,> . @DeNeutoy : Do you happen to know what version of python and libraries were used in the streamlit app? The results from the streamlit public demo case were really good for me but I'm having trouble replicating them.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:43,deployability,version,version,43,> . @DeNeutoy : Do you happen to know what version of python and libraries were used in the streamlit app? The results from the streamlit public demo case were really good for me but I'm having trouble replicating them.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:43,integrability,version,version,43,> . @DeNeutoy : Do you happen to know what version of python and libraries were used in the streamlit app? The results from the streamlit public demo case were really good for me but I'm having trouble replicating them.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:138,integrability,pub,public,138,> . @DeNeutoy : Do you happen to know what version of python and libraries were used in the streamlit app? The results from the streamlit public demo case were really good for me but I'm having trouble replicating them.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/197:43,modifiability,version,version,43,> . @DeNeutoy : Do you happen to know what version of python and libraries were used in the streamlit app? The results from the streamlit public demo case were really good for me but I'm having trouble replicating them.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/197
https://github.com/allenai/scispacy/issues/198:557,deployability,api,api,557,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:14,energy efficiency,current,currently,14,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:55,energy efficiency,model,model,55,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:189,energy efficiency,model,model,189,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:609,energy efficiency,model,model,609,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:557,integrability,api,api,557,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:513,interoperability,format,format,513,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:557,interoperability,api,api,557,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:55,security,model,model,55,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:189,security,model,model,189,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:609,security,model,model,609,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/198:33,testability,plan,plans,33,"Hi, we do not currently have any plans to train an NER model on DBpedia. I am not sure where the DBpedia based dataset mentioned in that paper is, but it seems your goal is to train an NER model to recognize mentions of entities that are in Wikipedia? If so, you might be able to find some datasets just by searching around, for example I found this which looks like it might be what you are after (https://github.com/ghaddarAbs/WiNER). Once you have the data you want to train on, you just need to get it into a format that spacy accepts (https://spacy.io/api/annotation#training) and then train spacy's ner model (https://spacy.io/usage/training#ner).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/198
https://github.com/allenai/scispacy/issues/199:216,deployability,pipelin,pipeline,216,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:55,integrability,sub,substituting,55,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:216,integrability,pipelin,pipeline,216,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:265,usability,help,helpful,265,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:216,deployability,pipelin,pipeline,216,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:55,integrability,sub,substituting,55,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:216,integrability,pipelin,pipeline,216,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:265,usability,help,helpful,265,"Hi @izuna385 - yes that is correct. The only change is substituting the surface form of a mention for that of it's long form, so `span._.long_form`. To do this, you just need to add the `AbbreviationDetector` in the pipeline before the linker. This is particularly helpful for TF-IDF type candidate generation, because abbreviations are very sparse in terms of 3-grams, meaning their score is not very meaningful unless there is an exact match. Please let me know if you cannot reproduce this, it should be the easier part!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:480,safety,compl,complete,480,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:480,security,compl,complete,480,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:30,testability,simpl,simple,30,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:30,usability,simpl,simple,30,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:41,usability,effectiv,effective,41,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:165,usability,Person,Personally,165,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:233,usability,close,closely,233,"Thanks for reply. Sounds like simple but effective for abbreviation, for `short term(longer term)` and the vise versa, which is very often seen at scientific paper. Personally, abbreviation expansion is interesting to me, since it's closely related to EL. So in future I may try another algorithm and report results! Thanks to your advice, I now add pipe before each in-doc mention is going to be ANNsearched, and am checking recall per each K. I'll add result when evaluation is complete.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:59,usability,user,user-images,59,"efS=2000, char3gram+abb. Medmentions dev. ![image](https://user-images.githubusercontent.com/35322641/75342872-9d190980-58da-11ea-91ea-6167649e4a97.png). seems like reproduced! Thank you so much.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/199:18,usability,close,close,18,"Seems like we can close this issue, feel free to reopen or make a new one if you have more questions!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/199
https://github.com/allenai/scispacy/issues/200:98,deployability,instal,installing,98,It looks like something about your setup is preventing PyYAML from being uninstalled? Can you try installing scispacy in a clean conda environment?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/200
https://github.com/allenai/scispacy/issues/200:44,safety,prevent,preventing,44,It looks like something about your setup is preventing PyYAML from being uninstalled? Can you try installing scispacy in a clean conda environment?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/200
https://github.com/allenai/scispacy/issues/200:44,security,preven,preventing,44,It looks like something about your setup is preventing PyYAML from being uninstalled? Can you try installing scispacy in a clean conda environment?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/200
https://github.com/allenai/scispacy/issues/202:172,usability,prefer,preferred,172,"Sorry to keep bothering you again. I now notice this is not bug but the desired results, and candidate_generator cover all possible cui with same scores. Another example, 'preferred setting' k=10 return includes. 'Preferred Term' of C1709637 and C2347664 with score 0.6542521715164185. (Both canonical name is same, 'Preferred Term'). and 'setting' of C0542559 and 'Setting' of C4281677 with score 0.6470361948013306. After all, UMLS covers so many concepts that sometimes this can happen. This issue can be closed. Sorry for inconvenience.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/202
https://github.com/allenai/scispacy/issues/202:214,usability,Prefer,Preferred,214,"Sorry to keep bothering you again. I now notice this is not bug but the desired results, and candidate_generator cover all possible cui with same scores. Another example, 'preferred setting' k=10 return includes. 'Preferred Term' of C1709637 and C2347664 with score 0.6542521715164185. (Both canonical name is same, 'Preferred Term'). and 'setting' of C0542559 and 'Setting' of C4281677 with score 0.6470361948013306. After all, UMLS covers so many concepts that sometimes this can happen. This issue can be closed. Sorry for inconvenience.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/202
https://github.com/allenai/scispacy/issues/202:317,usability,Prefer,Preferred,317,"Sorry to keep bothering you again. I now notice this is not bug but the desired results, and candidate_generator cover all possible cui with same scores. Another example, 'preferred setting' k=10 return includes. 'Preferred Term' of C1709637 and C2347664 with score 0.6542521715164185. (Both canonical name is same, 'Preferred Term'). and 'setting' of C0542559 and 'Setting' of C4281677 with score 0.6470361948013306. After all, UMLS covers so many concepts that sometimes this can happen. This issue can be closed. Sorry for inconvenience.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/202
https://github.com/allenai/scispacy/issues/202:508,usability,close,closed,508,"Sorry to keep bothering you again. I now notice this is not bug but the desired results, and candidate_generator cover all possible cui with same scores. Another example, 'preferred setting' k=10 return includes. 'Preferred Term' of C1709637 and C2347664 with score 0.6542521715164185. (Both canonical name is same, 'Preferred Term'). and 'setting' of C0542559 and 'Setting' of C4281677 with score 0.6470361948013306. After all, UMLS covers so many concepts that sometimes this can happen. This issue can be closed. Sorry for inconvenience.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/202
https://github.com/allenai/scispacy/issues/204:157,deployability,contain,contains,157,"All the concepts in `umls_2017_aa_cat0129.json` are from `UMLS2017AA MRCONSO.RRF` for categories 0, 1, 2 and 9. Can you double check that your `MRCONSO.RRF` contains all categories 0,1,2,9 ?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/204
https://github.com/allenai/scispacy/issues/205:42,usability,help,help,42,This worked for me! Thanks a lot for your help. Let's see if spaCy might come up with a good solution for it at some point :-),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/205
https://github.com/allenai/scispacy/issues/206:184,energy efficiency,model,model,184,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:294,energy efficiency,model,model,294,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:303,energy efficiency,predict,predict,303,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:28,safety,detect,detector,28,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:303,safety,predict,predict,303,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:28,security,detect,detector,28,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:184,security,model,model,184,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:211,security,ident,identifies,211,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:294,security,model,model,294,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/206:341,usability,help,helpful,341,"Hi @rshah1990,. The mention detector is trained on med mentions:. https://github.com/chanzuckerberg/MedMentions. which is really a dataset for entity linking. Because of this, the NER model is quite generic (it identifies a lot of mentions) and so we don't provide the types. You could train a model to predict the types though, if that was helpful.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/206
https://github.com/allenai/scispacy/issues/207:640,deployability,api,api,640,"Yeah, Tom ran into this as well. It turns out that pysbd can segment a sentence in the middle of a spacy token, and I didn't handle that case, not even sure what the right thing to do in that case would be. It seemed like there were a fair number of different patterns this could happen with, and issues in pysbd haven't been fixed for quite a while. So at this point I think you should either 1) run pysbd on its own and then scispacy over individual sentences (not sure if there are other pysbd problems that might make this hard) 2) use the built in dep parser based splitter or 3) use the built in rule based splitter (https://spacy.io/api/sentencizer).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/207:640,integrability,api,api,640,"Yeah, Tom ran into this as well. It turns out that pysbd can segment a sentence in the middle of a spacy token, and I didn't handle that case, not even sure what the right thing to do in that case would be. It seemed like there were a fair number of different patterns this could happen with, and issues in pysbd haven't been fixed for quite a while. So at this point I think you should either 1) run pysbd on its own and then scispacy over individual sentences (not sure if there are other pysbd problems that might make this hard) 2) use the built in dep parser based splitter or 3) use the built in rule based splitter (https://spacy.io/api/sentencizer).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/207:640,interoperability,api,api,640,"Yeah, Tom ran into this as well. It turns out that pysbd can segment a sentence in the middle of a spacy token, and I didn't handle that case, not even sure what the right thing to do in that case would be. It seemed like there were a fair number of different patterns this could happen with, and issues in pysbd haven't been fixed for quite a while. So at this point I think you should either 1) run pysbd on its own and then scispacy over individual sentences (not sure if there are other pysbd problems that might make this hard) 2) use the built in dep parser based splitter or 3) use the built in rule based splitter (https://spacy.io/api/sentencizer).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/207:105,security,token,token,105,"Yeah, Tom ran into this as well. It turns out that pysbd can segment a sentence in the middle of a spacy token, and I didn't handle that case, not even sure what the right thing to do in that case would be. It seemed like there were a fair number of different patterns this could happen with, and issues in pysbd haven't been fixed for quite a while. So at this point I think you should either 1) run pysbd on its own and then scispacy over individual sentences (not sure if there are other pysbd problems that might make this hard) 2) use the built in dep parser based splitter or 3) use the built in rule based splitter (https://spacy.io/api/sentencizer).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/207:39,deployability,upgrad,upgraded,39,This should be fixed now because we've upgraded Pysbd 👍 .,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/207:39,modifiability,upgrad,upgraded,39,This should be fixed now because we've upgraded Pysbd 👍 .,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/207
https://github.com/allenai/scispacy/issues/208:59,deployability,depend,depend,59,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:73,energy efficiency,model,model,73,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:202,energy efficiency,predict,predicted,202,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:233,energy efficiency,predict,predictions,233,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:294,energy efficiency,model,model,294,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:59,integrability,depend,depend,59,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:59,modifiability,depend,depend,59,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:50,reliability,doe,does,50,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:59,safety,depend,depend,59,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:202,safety,predict,predicted,202,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:233,safety,predict,predictions,233,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:73,security,model,model,73,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:294,security,model,model,294,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/208:59,testability,depend,depend,59,"Hi Waleed! The entity linker is its own pipe, and does not depend on the model used. However, the entity linker just provides linking candidates for a given entity span, the entity spans themselves are predicted by the NER pipe. The predictions of the NER pipe can differ between the different model sizes.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/208
https://github.com/allenai/scispacy/issues/210:284,deployability,contain,contain,284,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/210:19,energy efficiency,model,models,19,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/210:67,energy efficiency,model,model,67,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/210:19,security,model,models,19,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/210:67,security,model,model,67,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/210:42,testability,coverag,coverage,42,"Hi, . The scispacy models have reasonable coverage (the larger the model the bigger the vocab which has vectors), but unfortunately they don't have vectors for all possible words. There's not much we can do about this - you might consider using a bigger set of vectors to see if they contain the words you are looking for or something? Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/210
https://github.com/allenai/scispacy/issues/211:127,deployability,releas,releases,127,"@prashikhurana you have an extra ""8"" character at the end of the URL. . Try https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/211
https://github.com/allenai/scispacy/issues/211:1,reliability,pra,prashikhurana,1,"@prashikhurana you have an extra ""8"" character at the end of the URL. . Try https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/211
https://github.com/allenai/scispacy/issues/213:27,deployability,updat,update,27,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:79,deployability,version,version,79,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:69,integrability,pub,published,69,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:79,integrability,version,version,79,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:108,integrability,sub,submit,108,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:79,modifiability,version,version,79,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:27,safety,updat,update,27,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/213:27,security,updat,update,27,"Thanks! We should probably update the bibtex to be a citation to the published version anyway. Feel free to submit a PR, or I'll get to it sometime soon.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/213
https://github.com/allenai/scispacy/issues/214:640,deployability,log,log,640,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:103,energy efficiency,model,models,103,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:318,energy efficiency,model,model,318,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:371,energy efficiency,model,model,371,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:622,energy efficiency,model,model,622,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:956,energy efficiency,load,load,956,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1005,energy efficiency,load,load,1005,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:342,integrability,pub,pubmed,342,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:916,integrability,filter,filter,916,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:956,performance,load,load,956,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1005,performance,load,load,1005,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:628,reliability,doe,does,628,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:879,reliability,doe,does,879,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:640,safety,log,log,640,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1173,safety,compl,complications,1173,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1354,safety,compl,complications,1354,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:103,security,model,models,103,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:318,security,model,model,318,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:371,security,model,model,371,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:622,security,model,model,622,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:640,security,log,log,640,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1072,security,control,control,1072,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1173,security,compl,complications,1173,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1253,security,control,control,1253,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1354,security,compl,complications,1354,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:640,testability,log,log,640,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1072,testability,control,control,1072,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1253,testability,control,control,1253,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1094,usability,progress,progression,1094,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/214:1275,usability,progress,progression,1275,"Hm, I'm not aware of any functionality like that off the top of my head. None of the scispacy or spacy models (that I am aware of) are trained on tweets, and so there might be some challenges off the bat. One idea that comes to mind is to compare the average probability of the words in the tweet between the scispacy model (which comes from pubmed papers) and the spacy model (which comes from web text). I don't know how well this will work on short tweets, but here is an example of it working. I picked a random sentence from a medical paper, and you can see that scispacy assigns it higher probability than the spacy model does. It is log probabilities with a min value of -20. If you do the same procedure for the above tweet, both scispacy and spacy assign it the same probability, so you may be able to look for tweets that scispacy assigns higher probability than spacy does. I'm not sure how accurate this filter will be. ```In [21]: nlp = spacy.load('en_core_web_md'). In [22]: nlp_sci = spacy.load('en_core_sci_md'). In [23]: doc = nlp(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [24]: doc_sci = nlp_sci(""Improved blood-glucose control decreases the progression of diabetic microvascular disease, but the effect on macrovascular complications is unknown.""). In [25]: probs = [t.prob for t in doc]. In [26]: probs_sci = [t.prob for t in doc_sci]. In [27]: sum(probs)/len(probs). Out[28]: -9.265402327884328. In [28]: sum(probs_sci)/len(probs_sci). Out[29]: -7.871467316150666. In [29]: nlp(""diabetic"")[0].prob. Out[30]: -13.113289833068848. In [30]: nlp_sci(""diabetic"")[0].prob. Out[30]: -10.021971702575684. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/214
https://github.com/allenai/scispacy/issues/215:265,integrability,filter,filter,265,"Hi, every UMLS entity is associated with one or more types, which come from the UMLS type tree (https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_semantic_type_tree.tsv). You could browse this type tree, find the types that are relevant to you, and then filter the results by UMLS type.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/215
https://github.com/allenai/scispacy/issues/215:68,integrability,filter,filter,68,"If you have the UMLS entity identifier for the entities you want to filter to (called a CUI), you could easily filter the output to only entities matching the CUIs you are interested in.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/215
https://github.com/allenai/scispacy/issues/215:111,integrability,filter,filter,111,"If you have the UMLS entity identifier for the entities you want to filter to (called a CUI), you could easily filter the output to only entities matching the CUIs you are interested in.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/215
https://github.com/allenai/scispacy/issues/215:28,security,ident,identifier,28,"If you have the UMLS entity identifier for the entities you want to filter to (called a CUI), you could easily filter the output to only entities matching the CUIs you are interested in.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/215
https://github.com/allenai/scispacy/issues/216:167,security,ident,identifying,167,"Could you clarify your problem here? Is that you want to extract biomedical concepts from text, but _only_ the ones that show up in your list of SNOMED concepts? What identifying information do you have for the SNOMED concepts that you want to extract?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:61,reliability,doe,does,61,"What information do you have for that concept list? That is, does each concept have an identifier that you can map to UMLS? Does it have a description? Does it have a list of aliases? Other?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:124,reliability,Doe,Does,124,"What information do you have for that concept list? That is, does each concept have an identifier that you can map to UMLS? Does it have a description? Does it have a list of aliases? Other?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:152,reliability,Doe,Does,152,"What information do you have for that concept list? That is, does each concept have an identifier that you can map to UMLS? Does it have a description? Does it have a list of aliases? Other?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:87,security,ident,identifier,87,"What information do you have for that concept list? That is, does each concept have an identifier that you can map to UMLS? Does it have a description? Does it have a list of aliases? Other?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:84,interoperability,format,format,84,I have a concept ID and its descriptions. and also its aliases from SNOMED in table format.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/216:47,integrability,filter,filter,47,"If the concept ID is a UMLS id, you could just filter the output of the linker based on your list of concept IDs.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/216
https://github.com/allenai/scispacy/issues/220:148,modifiability,paramet,parameters,148,"@Raghu17s The entity linker is quite naive, so it may not link all of your entities that are extracted. You can play around with some of the linker parameters here: https://github.com/allenai/scispacy#umlsentitylinker-alpha-feature. You might want to try lowering the thresholds for the score at which an entity is linked - be aware that this will probably increase your false positives also.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:82,integrability,coupl,couple,82,"Not in scispacy. I haven't used this package myself, but I have seen it used in a couple place, might be worth checking out: https://github.com/jenojp/negspacy",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:37,modifiability,pac,package,37,"Not in scispacy. I haven't used this package myself, but I have seen it used in a couple place, might be worth checking out: https://github.com/jenojp/negspacy",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:82,modifiability,coupl,couple,82,"Not in scispacy. I haven't used this package myself, but I have seen it used in a couple place, might be worth checking out: https://github.com/jenojp/negspacy",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:82,testability,coupl,couple,82,"Not in scispacy. I haven't used this package myself, but I have seen it used in a couple place, might be worth checking out: https://github.com/jenojp/negspacy",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:142,testability,fuzzy,fuzzy,142,"@danielkingai2 Thanks, negspacy worked for me. . Can I get information on which method was used for text matching? like levenshtein distance (fuzzy ratio, partial, cosine similarity or any other) -- . Can we change the text matching method? Should I open a new issue for this different question?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:99,availability,Robust,Robust-Models-for-Biomedical-Neumann-King,99,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:106,energy efficiency,Model,Models-for-Biomedical-Neumann-King,106,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:52,interoperability,semant,semanticscholar,52,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:99,reliability,Robust,Robust-Models-for-Biomedical-Neumann-King,99,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:99,safety,Robust,Robust-Models-for-Biomedical-Neumann-King,99,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/220:106,security,Model,Models-for-Biomedical-Neumann-King,106,The details are described in the paper (https://www.semanticscholar.org/paper/ScispaCy%3A-Fast-and-Robust-Models-for-Biomedical-Neumann-King/de28ec1d7bd38c8fc4e8ac59b6133800818b4e29) in section 5. It is an approximate nearest neighbors search over tfidf character 3-grams.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/220
https://github.com/allenai/scispacy/issues/221:219,energy efficiency,load,load,219,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:251,energy efficiency,load,load,251,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:341,energy efficiency,load,load,341,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:258,integrability,sub,substantial,258,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:29,modifiability,paramet,parameter,29,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:219,performance,load,load,219,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:251,performance,load,load,251,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:341,performance,load,load,341,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:160,testability,trace,traceback,160,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:409,testability,understand,understand,409,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:180,usability,help,help,180,"@Raghu17s The class has this parameter, you can see here:. https://github.com/allenai/scispacy/blob/master/scispacy/umls_linking.py#L64. - please post the full traceback so we can help you. . I would suggest you try to load it only once, as it had to load a substantial amount of data (this is unavoidable). It it true there may be a way to load it faster, but we haven't particularly looked into it. I don't understand your question about the absence of ""interent""? .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:123,deployability,modul,module,123,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:123,modifiability,modul,module,123,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:271,modifiability,paramet,parameters,271,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:97,safety,input,input-,97,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:123,safety,modul,module,123,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:27,testability,trace,traceback,27,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:53,testability,Trace,Traceback,53,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:97,usability,input,input-,97,"@DeNeutoy here is the full traceback. ```. TypeError Traceback (most recent call last). <ipython-input-3-ca0a2c880bef> in <module>. 1 # link to UMLS. ----> 2 linker = UmlsEntityLinker(k = 10, max_entities_per_mention = 5, threshold = 0.5, no_definition_threshold = 0.8) #parameters are tunable k = 10, max_entities_per_mention = 2. 3 nlp.add_pipe(linker). TypeError: __init__() got an unexpected keyword argument 'no_definition_threshold'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:37,deployability,version,version,37,"I would guess that you are on an old version, that parameter was introduced in `v0.2.3`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:37,integrability,version,version,37,"I would guess that you are on an old version, that parameter was introduced in `v0.2.3`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:37,modifiability,version,version,37,"I would guess that you are on an old version, that parameter was introduced in `v0.2.3`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:51,modifiability,paramet,parameter,51,"I would guess that you are on an old version, that parameter was introduced in `v0.2.3`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:6,availability,down,downgraded,6,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:48,availability,error,error,48,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:99,availability,error,error,99,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:134,availability,error,error,134,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:60,deployability,updat,update,60,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:71,deployability,version,version,71,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:395,energy efficiency,model,model,395,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:422,energy efficiency,model,models,422,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:71,integrability,version,version,71,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:71,modifiability,version,version,71,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:48,performance,error,error,48,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:99,performance,error,error,99,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:134,performance,error,error,134,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:48,safety,error,error,48,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:60,safety,updat,update,60,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:99,safety,error,error,99,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:134,safety,error,error,134,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:60,security,updat,update,60,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:395,security,model,model,395,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:422,security,model,models,422,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:48,usability,error,error,48,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:99,usability,error,error,99,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:134,usability,error,error,134,"I had downgraded to v0.2.2 due to the following error. If I update the version I receive following error. Strange thing is, following error occurs when the sentence has words like ""and"", ""reports"". ```. E167] Unknown morphological feature: 'ConjType' (9141427322507498425). . This can happen if the tagger was trained with a different set of morphological features. If you're using a pretrained model, make sure that your models are up to date:",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:51,availability,down,download,51,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:25,deployability,version,version,25,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:80,deployability,version,version,80,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:64,energy efficiency,model,models,64,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:25,integrability,version,version,25,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:80,integrability,version,version,80,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:25,modifiability,version,version,25,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:80,modifiability,version,version,80,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:64,security,model,models,64,"When you change scispacy version, you also need to download the models for that version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:148,deployability,build,build,148,"@danielkingai2 yes, it worked for me. Thanks for the suggestion. . Scispacy is really awesome. For curiosity this question. Is there any way we can build relationships from the entities extracted from text.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:202,deployability,api,api,202,"Great! For that, you'll have to explore the literature on ""relation extraction,"" as this task is not supported in scispacy :) but you may check out some related work from some of our colleagues https://api.semanticscholar.org/CorpusID:202660640",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:202,integrability,api,api,202,"Great! For that, you'll have to explore the literature on ""relation extraction,"" as this task is not supported in scispacy :) but you may check out some related work from some of our colleagues https://api.semanticscholar.org/CorpusID:202660640",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:202,interoperability,api,api,202,"Great! For that, you'll have to explore the literature on ""relation extraction,"" as this task is not supported in scispacy :) but you may check out some related work from some of our colleagues https://api.semanticscholar.org/CorpusID:202660640",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:206,interoperability,semant,semanticscholar,206,"Great! For that, you'll have to explore the literature on ""relation extraction,"" as this task is not supported in scispacy :) but you may check out some related work from some of our colleagues https://api.semanticscholar.org/CorpusID:202660640",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/221:101,usability,support,supported,101,"Great! For that, you'll have to explore the literature on ""relation extraction,"" as this task is not supported in scispacy :) but you may check out some related work from some of our colleagues https://api.semanticscholar.org/CorpusID:202660640",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/221
https://github.com/allenai/scispacy/issues/222:50,deployability,releas,released,50,"Hi, no fee is necessary - the code and models are released under the Apache 2.0 license, which allows commercial use. However, it would be great if you could let us know a bit about what you are using it for, as we want to continue to make scispacy useful and it would be great to hear what your main needs are. You can email us at `{markn, daniel} AT allenai.org`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:223,deployability,continu,continue,223,"Hi, no fee is necessary - the code and models are released under the Apache 2.0 license, which allows commercial use. However, it would be great if you could let us know a bit about what you are using it for, as we want to continue to make scispacy useful and it would be great to hear what your main needs are. You can email us at `{markn, daniel} AT allenai.org`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:39,energy efficiency,model,models,39,"Hi, no fee is necessary - the code and models are released under the Apache 2.0 license, which allows commercial use. However, it would be great if you could let us know a bit about what you are using it for, as we want to continue to make scispacy useful and it would be great to hear what your main needs are. You can email us at `{markn, daniel} AT allenai.org`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:39,security,model,models,39,"Hi, no fee is necessary - the code and models are released under the Apache 2.0 license, which allows commercial use. However, it would be great if you could let us know a bit about what you are using it for, as we want to continue to make scispacy useful and it would be great to hear what your main needs are. You can email us at `{markn, daniel} AT allenai.org`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:199,deployability,releas,released,199,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:381,deployability,continu,continue,381,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:188,energy efficiency,model,models,188,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:53,interoperability,format,format,53,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:188,security,model,models,188,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:570,security,auth,authored,570,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:784,security,auth,auth,784,"Hi,. Can you please send me your email id in correct format ? Thanks. On Mon, 4 May 2020, 9:51 pm Mark Neumann, <notifications@github.com> wrote:. > Hi, no fee is necessary - the code and models are released under the. > Apache 2.0 license, which allows commercial use. However, it would be great. > if you could let us know a bit about what you are using it for, as we want. > to continue to make scispacy useful and it would be great to hear what your. > main needs are. You can email us at {markn, daniel} AT allenai.org. >. > —. > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/allenai/scispacy/issues/222#issuecomment-623563469>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AMNKTFOQNDEE6LKVF4VIZTTRP3TQJANCNFSM4MYESH6A>. > . >.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/issues/222:15,usability,close,close,15,Thanks You can close this issue,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/222
https://github.com/allenai/scispacy/pull/223:109,availability,operat,operate,109,"@DeNeutoy CI is running now, see if you think this is correct? (even if maybe it should be rewritten to just operate on tokens)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/223
https://github.com/allenai/scispacy/pull/223:120,security,token,tokens,120,"@DeNeutoy CI is running now, see if you think this is correct? (even if maybe it should be rewritten to just operate on tokens)",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/223
https://github.com/allenai/scispacy/issues/224:151,deployability,releas,releases,151,"Hi, @vgainullin,. You can simply add the full url to the model to your requirements.txt file. e.g. `https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz. `.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:57,energy efficiency,model,model,57,"Hi, @vgainullin,. You can simply add the full url to the model to your requirements.txt file. e.g. `https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz. `.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:57,security,model,model,57,"Hi, @vgainullin,. You can simply add the full url to the model to your requirements.txt file. e.g. `https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz. `.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:26,testability,simpl,simply,26,"Hi, @vgainullin,. You can simply add the full url to the model to your requirements.txt file. e.g. `https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz. `.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:26,usability,simpl,simply,26,"Hi, @vgainullin,. You can simply add the full url to the model to your requirements.txt file. e.g. `https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz. `.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:99,deployability,depend,dependencies,99,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:99,integrability,depend,dependencies,99,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:112,interoperability,specif,specified,112,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:63,modifiability,pac,packaging,63,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:99,modifiability,depend,dependencies,99,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:82,reliability,doe,does,82,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:99,safety,depend,dependencies,99,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:99,testability,depend,dependencies,99,"@DeNeutoy, thanks for the reply. Correct me if I am wrong, but packaging for PyPi does not include dependencies specified in requirements.txt.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:177,availability,down,download,177,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:261,deployability,depend,dependencies,261,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:371,deployability,depend,dependencies,371,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:251,energy efficiency,model,models,251,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:261,integrability,depend,dependencies,261,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:371,integrability,depend,dependencies,371,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:261,modifiability,depend,dependencies,261,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:371,modifiability,depend,dependencies,371,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:321,performance,cach,cache,321,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:75,reliability,doe,does,75,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:261,safety,depend,dependencies,261,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:371,safety,depend,dependencies,371,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:251,security,model,models,251,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:261,testability,depend,dependencies,261,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/224:371,testability,depend,dependencies,371,"@vgainullin Ah! Sorry you are right, I miss read your question. Spacy also does not provide this functionality, so it is unlikely we will. It's possible you can call `spacy.cli.download` with a url path, i'm not sure. Regardless, I don't think having models as dependencies is 100% useful (they can be large, you want to cache them in a way you don't want to with normal dependencies) so it's unlikely we will implement this. Sorry!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/224
https://github.com/allenai/scispacy/issues/225:61,deployability,instal,install,61,"I believe Sagemaker relies on docker, so you'll just want to install whatever you need (including scispacy) via docker.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:58,deployability,instal,install,58,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:162,energy efficiency,model,model,162,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:311,energy efficiency,model,models,311,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:162,security,model,model,162,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:198,security,access,access,198,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:311,security,model,models,311,"Hi Dan,. You are correct we need to make a docker file to install spacy and scispacy libraries and the corresponding code . I am struggling where the pre trained model will be stored so that we can access oin our python code on docker . What should be the docker file structure to use spacy, scispacy and there models. Thanks",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:48,deployability,instal,install,48,pretty sure you just want to have. ```. RUN pip install scispacy. RUN pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz (or whatever model you want). ```. in your Dockerfile,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:74,deployability,instal,install,74,pretty sure you just want to have. ```. RUN pip install scispacy. RUN pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz (or whatever model you want). ```. in your Dockerfile,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:133,deployability,releas,releases,133,pretty sure you just want to have. ```. RUN pip install scispacy. RUN pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz (or whatever model you want). ```. in your Dockerfile,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:190,energy efficiency,model,model,190,pretty sure you just want to have. ```. RUN pip install scispacy. RUN pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz (or whatever model you want). ```. in your Dockerfile,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/225:190,security,model,model,190,pretty sure you just want to have. ```. RUN pip install scispacy. RUN pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz (or whatever model you want). ```. in your Dockerfile,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/225
https://github.com/allenai/scispacy/issues/226:47,deployability,api,api,47,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:83,deployability,modul,module,83,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:47,integrability,api,api,47,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:47,interoperability,api,api,47,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:83,modifiability,modul,module,83,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:83,safety,modul,module,83,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:153,security,hack,hack,153,"You can use the entity ruler (https://spacy.io/api/entityruler) instead of the ner module if you want to pass in entities yourself. You can also sort of hack the `doc.ents` to pass in your own entities like so:. ```. In [174]: linker = UmlsEntityLinker(resolve_abbreviations=False, filter_for_definitions=False, threshold=0.5) . In [175]: doc = base_nlp('il-10-producing regulatory t-cells') . In [176]: doc.ents = [Span(doc, 0, len(doc), label=""Entity"")] . In [177]: linked_doc = linker(doc) . In [178]: linked_doc.ents[0]._.umls_ents . Out[178]: . [('C0039198', 0.6841055154800415),. ('C4284002', 0.5307365655899048),. ('C0039194', 0.5252377986907959),. ('C3178914', 0.5139729976654053),. ('C1819477', 0.5007489323616028)]. ```. but this may cause other things to break.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:519,energy efficiency,model,models,519,"@danielkingai2 Yes, this breaks other things. . *************************************. Further, I am getting strange results in some cases (please let me know if anyone has faced the same issue). I have text as ` fever hypertension diabetes mellitus`. when I extract entities using scispacy, it output them as one entity like. `fever hypertension diabetes mellitus` . which suppose to be three different in the medical context. `fever`. `hypertension` . `diabetes mellitus`. Note: Similar results using all of Scispacy models. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:519,security,model,models,519,"@danielkingai2 Yes, this breaks other things. . *************************************. Further, I am getting strange results in some cases (please let me know if anyone has faced the same issue). I have text as ` fever hypertension diabetes mellitus`. when I extract entities using scispacy, it output them as one entity like. `fever hypertension diabetes mellitus` . which suppose to be three different in the medical context. `fever`. `hypertension` . `diabetes mellitus`. Note: Similar results using all of Scispacy models. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:419,testability,context,context,419,"@danielkingai2 Yes, this breaks other things. . *************************************. Further, I am getting strange results in some cases (please let me know if anyone has faced the same issue). I have text as ` fever hypertension diabetes mellitus`. when I extract entities using scispacy, it output them as one entity like. `fever hypertension diabetes mellitus` . which suppose to be three different in the medical context. `fever`. `hypertension` . `diabetes mellitus`. Note: Similar results using all of Scispacy models. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:4,energy efficiency,model,models,4,"The models were trained on proper sentences, and are likely to not do what you expect given less well formed text.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:4,security,model,models,4,"The models were trained on proper sentences, and are likely to not do what you expect given less well formed text.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:63,interoperability,format,format,63,You are correct. Sorry for the wrong question. . My input data format is wrong.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:52,safety,input,input,52,You are correct. Sorry for the wrong question. . My input data format is wrong.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/226:52,usability,input,input,52,You are correct. Sorry for the wrong question. . My input data format is wrong.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/226
https://github.com/allenai/scispacy/issues/227:27,deployability,stack,stack,27,Please re-open with a full stack trace so we can actually help.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:33,testability,trace,trace,33,Please re-open with a full stack trace so we can actually help.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:58,usability,help,help,58,Please re-open with a full stack trace so we can actually help.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:91,availability,error,error,91,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:29,deployability,stack,stack,29,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:363,deployability,Continu,Continuum,363,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:556,deployability,Continu,Continuum,556,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:727,deployability,Continu,Continuum,727,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:893,deployability,Continu,Continuum,893,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1065,deployability,Continu,Continuum,1065,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1198,deployability,Continu,Continuum,1198,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1350,deployability,Continu,Continuum,1350,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:819,energy efficiency,load,load,819,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:946,energy efficiency,load,load,946,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1118,energy efficiency,load,loads,1118,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:97,integrability,messag,message,97,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:97,interoperability,messag,message,97,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:392,modifiability,pac,packages,392,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:585,modifiability,pac,packages,585,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:756,modifiability,pac,packages,756,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1149,modifiability,deco,decode,1149,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1227,modifiability,deco,decoder,1227,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1253,modifiability,deco,decode,1253,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1379,modifiability,deco,decoder,1379,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:91,performance,error,error,91,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:819,performance,load,load,819,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:946,performance,load,load,946,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1118,performance,load,loads,1118,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:91,safety,error,error,91,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:35,testability,trace,trace,35,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:213,testability,Trace,Traceback,213,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:60,usability,help,help,60,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:91,usability,error,error,91,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:334,usability,User,Users,334,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:527,usability,User,Users,527,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:698,usability,User,Users,698,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:864,usability,User,Users,864,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1036,usability,User,Users,1036,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1169,usability,User,Users,1169,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:1321,usability,User,Users,1321,"> Please re-open with a full stack trace so we can actually help. OK! The following is the error message. from scispacy.umls_linking import UmlsEntityLinker. linker = UmlsEntityLinker(resolve_abbreviations=True). Traceback (most recent call last):. File """", line 1, in. linker = UmlsEntityLinker(resolve_abbreviations=True). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_linking.py"", line 68, in init. self.candidate_generator = candidate_generator or CandidateGenerator(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\candidate_generation.py"", line 129, in init. self.umls = umls or UmlsKnowledgeBase(). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\site-packages\scispacy\umls_utils.py"", line 47, in init. raw = json.load(open(cached_path(file_path))). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 296, in load. parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json_init_.py"", line 348, in loads. return _default_decoder.decode(s). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 337, in decode. obj, end = self.raw_decode(s, idx=_w(s, 0).end()). File ""C:\Users\ANNA.CHU\AppData\Local\Continuum\anaconda3\lib\json\decoder.py"", line 355, in raw_decode. raise JSONDecodeError(""Expecting value"", s, err.value) from None. JSONDecodeError: Expecting value.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:75,deployability,version,version,75,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:117,energy efficiency,load,load,117,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:189,energy efficiency,load,load,189,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:223,energy efficiency,load,load,223,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:75,integrability,version,version,75,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:75,modifiability,version,version,75,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:117,performance,load,load,117,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:189,performance,load,load,189,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:223,performance,load,load,223,I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:16,deployability,version,version,16,and what python version are you on?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:16,integrability,version,version,16,and what python version are you on?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:16,modifiability,version,version,16,and what python version are you on?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:77,deployability,version,version,77,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:119,energy efficiency,load,load,119,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:191,energy efficiency,load,load,191,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:225,energy efficiency,load,load,225,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:343,energy efficiency,load,load,343,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:77,integrability,version,version,77,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:77,modifiability,version,version,77,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:119,performance,load,load,119,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:191,performance,load,load,191,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:225,performance,load,load,225,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:343,performance,load,load,343,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:328,safety,test,test,328,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:308,testability,simpl,simple,308,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:328,testability,test,test,328,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:308,usability,simpl,simple,308,"> I have a feeling this is related to some combination of Windows and python version...but I'm not sure. I was able to load the entity linker on my windows machine just fine. Are you able to load other json files using `json.load`? I agree on the problem of combination of windows and python. Yes. I tried a simple json file to test the `json.load`, it work. Finally, I change to Ubuntu environment, it work successfully. I think the there are some Unicode issues on windows, but I haven't figured out. Really thanks for your reply.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:18,deployability,version,version,18,> and what python version are you on? Python 3.7.4 .,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:18,integrability,version,version,18,> and what python version are you on? Python 3.7.4 .,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/227:18,modifiability,version,version,18,> and what python version are you on? Python 3.7.4 .,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/227
https://github.com/allenai/scispacy/issues/228:78,performance,cach,cache,78,"@danielkingai2 any ideas? I think this might be a hangover from when the file cache could sign requests to private buckets. If so, we can just remove it and replace with requests as @sndrtj suggests!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:90,security,sign,sign,90,"@danielkingai2 any ideas? I think this might be a hangover from when the file cache could sign requests to private buckets. If so, we can just remove it and replace with requests as @sndrtj suggests!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:108,safety,safe,safe,108,It would appear that I put it in the requirements when I made the repo for some reason 🤷‍♂️ pretty sure its safe to remove.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:72,deployability,version,version,72,I went ahead and opened a PR (#229) that addresses this :-). I hope the version constraint I put on requests isn't too strict (or too loose).,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:72,integrability,version,version,72,I went ahead and opened a PR (#229) that addresses this :-). I hope the version constraint I put on requests isn't too strict (or too loose).,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:72,modifiability,version,version,72,I went ahead and opened a PR (#229) that addresses this :-). I hope the version constraint I put on requests isn't too strict (or too loose).,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/228:0,usability,Close,Closed,0,"Closed by #229, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/228
https://github.com/allenai/scispacy/issues/230:51,deployability,api,api,51,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/230:86,deployability,pipelin,pipelines,86,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/230:51,integrability,api,api,51,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/230:86,integrability,pipelin,pipelines,86,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/230:51,interoperability,api,api,51,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/230:132,usability,interact,interacts,132,"You can uses spacy's pipe method (https://spacy.io/api/language#pipe) with all of our pipelines, although I am not certain how this interacts with added pipes like the UmlsEntityLinker. You could find out experimentally",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/230
https://github.com/allenai/scispacy/issues/231:267,deployability,stack,stack,267,"Hi, unfortunately we don't have the time to provide extended tech support to your projects. It seems likely to me that pyspark is compatible with scispacy, but I don't know. I would like to keep scispacy issues relevant to the library itself - i'd suggest you search stack overflow for issues related to this to see if you can find anything related to spacy and pyspark. Good luck!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:130,interoperability,compatib,compatible,130,"Hi, unfortunately we don't have the time to provide extended tech support to your projects. It seems likely to me that pyspark is compatible with scispacy, but I don't know. I would like to keep scispacy issues relevant to the library itself - i'd suggest you search stack overflow for issues related to this to see if you can find anything related to spacy and pyspark. Good luck!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:52,modifiability,exten,extended,52,"Hi, unfortunately we don't have the time to provide extended tech support to your projects. It seems likely to me that pyspark is compatible with scispacy, but I don't know. I would like to keep scispacy issues relevant to the library itself - i'd suggest you search stack overflow for issues related to this to see if you can find anything related to spacy and pyspark. Good luck!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:36,performance,time,time,36,"Hi, unfortunately we don't have the time to provide extended tech support to your projects. It seems likely to me that pyspark is compatible with scispacy, but I don't know. I would like to keep scispacy issues relevant to the library itself - i'd suggest you search stack overflow for issues related to this to see if you can find anything related to spacy and pyspark. Good luck!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:66,usability,support,support,66,"Hi, unfortunately we don't have the time to provide extended tech support to your projects. It seems likely to me that pyspark is compatible with scispacy, but I don't know. I would like to keep scispacy issues relevant to the library itself - i'd suggest you search stack overflow for issues related to this to see if you can find anything related to spacy and pyspark. Good luck!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:50,deployability,stack,stack,50,Sorry Mark if that offended you . I will do it on stack overflow . I thought it will be relevant here as for production usage we have to use production grade frameworks and spark is the most commonly used prod grade framework . So comaptability of any model with Spark is imp,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:252,energy efficiency,model,model,252,Sorry Mark if that offended you . I will do it on stack overflow . I thought it will be relevant here as for production usage we have to use production grade frameworks and spark is the most commonly used prod grade framework . So comaptability of any model with Spark is imp,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/issues/231:252,security,model,model,252,Sorry Mark if that offended you . I will do it on stack overflow . I thought it will be relevant here as for production usage we have to use production grade frameworks and spark is the most commonly used prod grade framework . So comaptability of any model with Spark is imp,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/231
https://github.com/allenai/scispacy/pull/233:157,deployability,version,version,157,"Ok, I moved from `umls` to `kb`, including for the spacy span annotations, but I left umls_ents there too for the time being. We can remove it in some later version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/233
https://github.com/allenai/scispacy/pull/233:157,integrability,version,version,157,"Ok, I moved from `umls` to `kb`, including for the spacy span annotations, but I left umls_ents there too for the time being. We can remove it in some later version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/233
https://github.com/allenai/scispacy/pull/233:157,modifiability,version,version,157,"Ok, I moved from `umls` to `kb`, including for the spacy span annotations, but I left umls_ents there too for the time being. We can remove it in some later version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/233
https://github.com/allenai/scispacy/pull/233:114,performance,time,time,114,"Ok, I moved from `umls` to `kb`, including for the spacy span annotations, but I left umls_ents there too for the time being. We can remove it in some later version.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/233
https://github.com/allenai/scispacy/issues/234:153,modifiability,refact,refactor,153,@DeNeutoy Are the scripts set up such that it would be easy to add your own entities and then retrain the tfidf/ann stuff? (especially after your recent refactor),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/234
https://github.com/allenai/scispacy/issues/234:153,performance,refactor,refactor,153,@DeNeutoy Are the scripts set up such that it would be easy to add your own entities and then retrain the tfidf/ann stuff? (especially after your recent refactor),MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/234
https://github.com/allenai/scispacy/issues/234:306,interoperability,format,format,306,"Hi @rshah1990 , @fcggamou . This function trains a linker:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L325. which takes a `KnowledgeBase`: https://github.com/allenai/scispacy/blob/master/scispacy/linking_utils.py#L45. which reads JSON/JSONL with the following simple format:. ```. # Json per entity you have:. {. ""concept_id"": ""The ID for the concept"",. ""canonical_name"": ""MyEntity"",. ""aliases"": [""List of alternative ways to refer to the entity""],. ""definition"": ""Longer form def of entity"", # optional. ""types"": [""The type of the entity""] # optional. }. ```. Also note that this will only work if you work off of the master branch. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/234
https://github.com/allenai/scispacy/issues/234:299,testability,simpl,simple,299,"Hi @rshah1990 , @fcggamou . This function trains a linker:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L325. which takes a `KnowledgeBase`: https://github.com/allenai/scispacy/blob/master/scispacy/linking_utils.py#L45. which reads JSON/JSONL with the following simple format:. ```. # Json per entity you have:. {. ""concept_id"": ""The ID for the concept"",. ""canonical_name"": ""MyEntity"",. ""aliases"": [""List of alternative ways to refer to the entity""],. ""definition"": ""Longer form def of entity"", # optional. ""types"": [""The type of the entity""] # optional. }. ```. Also note that this will only work if you work off of the master branch. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/234
https://github.com/allenai/scispacy/issues/234:299,usability,simpl,simple,299,"Hi @rshah1990 , @fcggamou . This function trains a linker:. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L325. which takes a `KnowledgeBase`: https://github.com/allenai/scispacy/blob/master/scispacy/linking_utils.py#L45. which reads JSON/JSONL with the following simple format:. ```. # Json per entity you have:. {. ""concept_id"": ""The ID for the concept"",. ""canonical_name"": ""MyEntity"",. ""aliases"": [""List of alternative ways to refer to the entity""],. ""definition"": ""Longer form def of entity"", # optional. ""types"": [""The type of the entity""] # optional. }. ```. Also note that this will only work if you work off of the master branch. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/234
https://github.com/allenai/scispacy/issues/235:22,energy efficiency,current,currently,22,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:48,energy efficiency,model,models,48,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:88,energy efficiency,model,models,88,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:180,energy efficiency,model,models,180,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:187,energy efficiency,current,currently,187,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:232,energy efficiency,model,model,232,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:170,integrability,sub,submitted,170,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:211,interoperability,share,share,211,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:121,modifiability,maintain,maintain,121,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:121,safety,maintain,maintain,121,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:48,security,model,models,48,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:88,security,model,models,88,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:180,security,model,models,180,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:232,security,model,model,232,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:43,usability,user,user,43,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/235:165,usability,user,user,165,"Hello! Scispacy isn't currently soliciting user models for hosting. We provide a set of models which we have trained and maintain, but we don't want to do this with user submitted models currently. Feel free to share a link to your model here and interested people will probably see it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/235
https://github.com/allenai/scispacy/issues/236:58,availability,error,errors,58,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:167,availability,consist,consistently,167,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:58,performance,error,errors,58,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:58,safety,error,errors,58,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:234,safety,except,exceptions,234,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:45,security,token,tokenization,45,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:208,security,token,tokenization,208,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:258,security,token,tokenizer,258,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:275,security,token,tokenize,275,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:58,usability,error,errors,58,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:167,usability,consist,consistently,167,"Hmm, thanks @iacopy! Most of these look like tokenization errors, leading to misclassification. Some of them also look like reasonable entities to me also. If you can consistently recognise an issue with the tokenization, you can add exceptions to the spacy tokenizer, or re-tokenize after the fact to fix them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:138,modifiability,pac,package,138,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:158,modifiability,pac,package,158,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:190,modifiability,variab,variable,190,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:227,reliability,doe,does,227,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:8,safety,reme,remember,8,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:40,security,token,tokenizer,40,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/236:236,usability,support,support,236,"Yeah, I remember I had some code in the tokenizer to deal with parentheses a bit better, but at some point spacy changed from the `regex` package to the `re` package, and that code required variable width lookbehinds, which re does not support, so it was commented out. Not sure thats the entirety of the problem, but given how many of these have unbalanced parens, i think it is part of it.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/236
https://github.com/allenai/scispacy/issues/237:104,deployability,releas,release,104,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:125,deployability,fail,failed,125,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:423,deployability,build,build,423,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:504,deployability,releas,release,504,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:607,deployability,releas,release,607,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:820,deployability,updat,update,820,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:857,deployability,releas,releases,857,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:144,integrability,sub,subscription,144,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:253,interoperability,format,format,253,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:125,reliability,fail,failed,125,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:820,safety,updat,update,820,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:83,security,access,access,83,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:820,security,updat,update,820,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:701,usability,prefer,prefer,701,"Hi @ChantalvanSon, sorry for the delay in getting back to you. I was trying to get access to the latest release of UMLS, but failed because our subscription had run out 🙄 . . Overall the steps you describe are accurate - the only important thing is the format of the kb file. After that it should be pretty straightforward - let us know if you run into any problems. Note that for all of UMLS it can take a little while to build the ANN index, maybe 2-3 hours. Overall, it wouldn't be too much effort to release multiple entity linkers, but I want to make sure they would see good use. E.g for the upcoming release, I have created one which links to MESH terms. However, for very niche use cases, i'd prefer to just make it easy for people to create their own, so consider yourself a guinea pig for that! We will try to update the entity linker in upcoming releases though, it is a bit old certainly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:585,availability,down,down,585,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2109,availability,avail,available,2109,"the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:68,deployability,manag,managed,68,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:130,deployability,releas,release,130,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:174,deployability,build,build,174,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1650,deployability,releas,release,1650,"e-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1813,deployability,releas,release,1813,"de your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_v",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2017,deployability,releas,release,2017,"aths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2283,deployability,releas,release,2283,"y.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:68,energy efficiency,manag,managed,68,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:632,energy efficiency,current,currently,632,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:927,energy efficiency,load,loaded,927,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1907,energy efficiency,Load,Loads,1907,"first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candid",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1967,energy efficiency,load,loading,1967,"bours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but thi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1989,energy efficiency,model,model,1989,"s one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2081,energy efficiency,load,load,2081,"ng (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2089,energy efficiency,Current,Currently,2089,"n how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `Cand",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2295,energy efficiency,load,load,2295,"e_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_conc",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2466,energy efficiency,load,load,2466,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2592,energy efficiency,load,load,2592,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2603,energy efficiency,load,load,2603,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:254,integrability,sub,subset,254,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1995,integrability,compon,components,1995,"ly accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if inste",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:55,interoperability,share,share,55,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1995,interoperability,compon,components,1995,"ly accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if inste",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2195,interoperability,format,format,2195,"t json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = Candidat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1995,modifiability,compon,components,1995,"ly accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if inste",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:470,performance,time,time,470,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:927,performance,load,loaded,927,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1907,performance,Load,Loads,1907,"first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candid",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1967,performance,load,loading,1967,"bours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but thi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2011,performance,disk,disk,2011,"`LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2081,performance,load,load,2081,"ng (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2295,performance,load,load,2295,"e_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_conc",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2466,performance,load,load,2466,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2592,performance,load,load,2592,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2603,performance,load,load,2603,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2109,reliability,availab,available,2109,"the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:68,safety,manag,managed,68,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2109,safety,avail,available,2109,"the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1989,security,model,model,1989,"s one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:2109,security,availab,available,2109,"the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:3014,testability,simpl,simply,3014,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:89,usability,custom,custom,89,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:537,usability,help,help,537,"Hi @DeNeutoy, thanks for the information! I'm happy to share that I managed to create my custom Entity Linker based on the 2020AA release. It took a bit longer (~8 hours) to build the ANN index, but this could very well be because of the size of my UMLS subset (all level 0 sources + SNOMED). . Overall, it was not tóó difficult to do, but I think some small changes in the code would make it even easier. I don't have an answer to this question myself yet -- if I have time and I do think of a good solution, I will try to see if I can help out by creating a PR. But I think it comes down to the following:. `CandidateGenerator()` currently accepts a pre-trained linker (`umls` or `mesh`), for which the default `LinkerPaths` have been defined globally in the `candidate_generation.py`. While it is possible to provide your own `ann_index`, `tfidf_vectorizer`, `ann_concept_aliases_list` and `kb`, these will first have to be loaded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model compo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1927,usability,custom,custom,1927,"ded using `load_approximate_nearest_neighbours_index`, and this one only accepts a `LinkerPaths` object. So I ended up writing something like the following (based on how it's done for the pre-trained `umls` and `mesh` linkers in `candidate_generation.py`):. ```. import json. import joblib. from scispacy.linking_utils import UmlsKnowledgeBase. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths,. load_approximate_nearest_neighbours_index,. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:3014,usability,simpl,simply,3014,"ath/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). # set default release. DEFAULT_RELEASE = ""2020AA"". DEFAULT_KB_PATH = ""path/to/2020AA.json"". DEFAULT_PATHS = {""2020AA"": CustomLinkerPaths_2020AA}. def load_candidate_generator(. release: str = DEFAULT_RELEASE, kb_path: str = DEFAULT_KB_PATH,. ) -> CandidateGenerator:. """"""Loads a pre-trained custom scispacy candidate generator by. loading the different model components from disk. release: str. The name of the pretrained candidate generator to load. . Currently, the only available (and default) is ""2020AA"". kb_path: str. Path to the Knowledge Base in JSON format as required by scispacy. """""". # create LinkerPaths. linker_paths = DEFAULT_PATHS[release]. # load ann_index, tfifd_vectorizer and ann_concept_aliases_list. ann_index = load_approximate_nearest_neighbours_index(linker_paths=linker_paths). tfidf_vectorizer = joblib.load(linker_paths.tfidf_vectorizer). with open(linker_paths.concept_aliases_list, ""r"") as f:. ann_concept_aliases_list = json.load(f). # load UMLS KnowledgeBase (converted json file). umls_kb = UmlsKnowledgeBase(file_path=kb_path). # create candidate generator. candidate_generator = CandidateGenerator(. ann_index=ann_index,. tfidf_vectorizer=tfidf_vectorizer,. ann_concept_aliases_list=ann_concept_aliases_list,. kb=umls_kb,. ). return candidate_generator. ```. I'm not sure if this makes sense, but think it would be great if instead, you could simply provide the paths to the necessary files directly when initiating a `CandidateGenerator`, so that you could do something like the following:. ```. candidate_generator = CandidateGenerator(. ann_index=""path/to/ann_index"",. tfidf_vectorizer=""path/to/tfidf_vectorizer"",. ann_concept_aliases_list=""path/to/ann_concept_aliases_list"",. kb=""path/to/kb"",. ). ```. I hope I explained my thoughts properly :-) Thanks and keep up the good work!!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1693,availability,error,errors,1693,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:170,energy efficiency,load,loads,170,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1136,integrability,interfac,interface,1136,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:867,interoperability,registr,registry,867,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1136,interoperability,interfac,interface,1136,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1861,interoperability,specif,specific,1861,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1136,modifiability,interfac,interface,1136,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1465,modifiability,deco,decorator,1465,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:170,performance,load,loads,170,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1693,performance,error,errors,1693,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1636,reliability,doe,does,1636,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1693,safety,error,errors,1693,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:789,security,hack,hack,789,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1118,testability,simpl,simplest,1118,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1118,usability,simpl,simplest,1118,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1693,usability,error,errors,1693,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:1870,usability,custom,custom,1870,"Hi @ChantalvanSon ,. Great that you got it working, sorry it was a bit tricky. You raise some good points - there is one way that you can not require your function which loads all the pieces which is this:. ```python. from scispacy.candidate_generation import DEFAULT_PATHS, DEFAULT_KNOWLEDGE_BASES. from scispacy.candidate_generation import (. CandidateGenerator,. LinkerPaths. ). CustomLinkerPaths_2020AA = LinkerPaths(. ann_index=""path/to/nmslib_index.bin"",. tfidf_vectorizer=""path/to//nmslib_index.bin"",. tfidf_vectors=""path/to/tfidf_vectorizer.joblib"",. concept_aliases_list=""path/to/concept_aliases.json"",. ). class UMLS2020KnowledgeBase(KnowledgeBase):. def __init__(. self,. file_path: str = ""path/to/2020AA.json"",. ):. super().__init__(file_path). # Admittedly this is a bit of a hack, because we are mutating a global object. # However, it's just a kind of registry, so maybe it's ok. DEFAULT_PATHS[""umls2020""] = CustomLinkerPaths_2020AA. DEFAULT_KNOWLEDGE_BASES[""umls2020""] = UMLS2020KnowledgeBase. linker = CandidateGenerator(name=""umls2020""). ```. Overall, we have it like this so that we can present the simplest possible interface to people who are using scispacy (i.e being able to just pass names to get particular linkers rather than having to know the internals of how the linker is implemented). However I definitely see your point that we should try to make this a bit nicer. In another project I used to work on, we had the concept of using a decorator to register this type of info with the base class, so it can construct itself. That might be a bit of overkill here, but maybe we could provide a function which does this global mutation for you and throws intelligent errors if you e.g try to overwrite something in there? . I think you're right that we need to fix this if we want people to frequently be able to create their own very specific/custom linkers though so thanks for raising it!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:261,availability,error,errors,261,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:340,availability,error,error,340,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:261,performance,error,errors,261,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:340,performance,error,error,340,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:218,reliability,doe,does,218,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:123,safety,compl,completely,123,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:261,safety,error,errors,261,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:340,safety,error,error,340,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:123,security,compl,completely,123,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:134,testability,understand,understand,134,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:261,usability,error,errors,261,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:340,usability,error,error,340,"Hi @DeNeutoy,. Thanks for the alternative! I'm adopting that, because it's indeed a bit nicer than my previous solution. I completely understand the reasons for implementing it as you did :-) Providing a function that does this global mutation with intelligent errors sounds like a nice addition to `scispacy`! *Edit: I just posted another error here that appeared to be my own mistake, so I have deleted it again.*",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:178,interoperability,registr,registry,178,"I think this issue has been mostly resolved by #247 - if people like the new entity linkers and we get requests for people to be able to make their own, we might add this global registry in a bit more of a formal way, but I think we'll punt on that for now as @ChantalvanSon seems to have figured out a reasonable way to make custom linkers.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:326,usability,custom,custom,326,"I think this issue has been mostly resolved by #247 - if people like the new entity linkers and we get requests for people to be able to make their own, we might add this global registry in a bit more of a formal way, but I think we'll punt on that for now as @ChantalvanSon seems to have figured out a reasonable way to make custom linkers.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:54,integrability,coupl,couple,54,"I was able to get this working. I needed to include a couple of minor tweaks. Added: . `from scispacy.linking_utils import KnowledgeBase`. I applied to code shown by @DeNeutoy . then I was able to add_pipe with the new name: . `umls_nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""umls2020"" } )`. see linker_name is changed to the custom value ""umls2020""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:54,modifiability,coupl,couple,54,"I was able to get this working. I needed to include a couple of minor tweaks. Added: . `from scispacy.linking_utils import KnowledgeBase`. I applied to code shown by @DeNeutoy . then I was able to add_pipe with the new name: . `umls_nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""umls2020"" } )`. see linker_name is changed to the custom value ""umls2020""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:54,testability,coupl,couple,54,"I was able to get this working. I needed to include a couple of minor tweaks. Added: . `from scispacy.linking_utils import KnowledgeBase`. I applied to code shown by @DeNeutoy . then I was able to add_pipe with the new name: . `umls_nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""umls2020"" } )`. see linker_name is changed to the custom value ""umls2020""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/237:370,usability,custom,custom,370,"I was able to get this working. I needed to include a couple of minor tweaks. Added: . `from scispacy.linking_utils import KnowledgeBase`. I applied to code shown by @DeNeutoy . then I was able to add_pipe with the new name: . `umls_nlp.add_pipe(""scispacy_linker"", config={""resolve_abbreviations"": True, ""linker_name"": ""umls2020"" } )`. see linker_name is changed to the custom value ""umls2020""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/237
https://github.com/allenai/scispacy/issues/238:255,interoperability,specif,specific,255,"Hi @radiatechs-himanshu , yes the doc vectors are just averages of the word vectors, which means they aren't that great past the sentence/phrase level. Sorry, there isn't much we can do about that because this is spacy functionality, rather than scispacy specific.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/238
https://github.com/allenai/scispacy/issues/239:110,usability,help,help,110,Could you please paste your whole code and the output of `pip list` in your environment so that we can try to help?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:29,deployability,updat,updated,29,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:105,deployability,releas,released,105,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:114,deployability,version,version,114,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:114,integrability,version,version,114,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:114,modifiability,version,version,114,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:29,safety,updat,updated,29,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/239:29,security,updat,updated,29,"@maxfarrell , we've recently updated the entity linking code so the master branch is not correct for the released version. Please try the instructions/snippets on the `v0.2.4` branch here:. https://github.com/allenai/scispacy/tree/v0.2.4.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/239
https://github.com/allenai/scispacy/issues/240:19,energy efficiency,load,load,19,"resolved by `spacy.load(""en_ner_bc5cdr_md"")`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/240
https://github.com/allenai/scispacy/issues/240:19,performance,load,load,19,"resolved by `spacy.load(""en_ner_bc5cdr_md"")`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/240
https://github.com/allenai/scispacy/issues/241:36,availability,Avail,Available,36,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:113,availability,avail,available-models,113,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:46,energy efficiency,Model,Models,46,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:123,energy efficiency,model,models,123,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:36,reliability,Availab,Available,36,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:113,reliability,availab,available-models,113,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:36,safety,Avail,Available,36,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:113,safety,avail,available-models,113,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:36,security,Availab,Available,36,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:46,security,Model,Models,46,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/241:113,security,availab,available-models,113,@IbtihalFerwana please look at the `Available Models` section of the readme: https://github.com/allenai/scispacy#available-models.,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/241
https://github.com/allenai/scispacy/issues/242:44,availability,down,downloaded,44,"Ok, it is looking on ('~.scispacy'). I have downloaded the file tfidf_vectors_sparse.npz there and in the subfolder 'datasets' but still, when I run linker = UmlsEntityLinker(resolve_abbreviations=True) it doesn't find anything in cache.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:106,integrability,sub,subfolder,106,"Ok, it is looking on ('~.scispacy'). I have downloaded the file tfidf_vectors_sparse.npz there and in the subfolder 'datasets' but still, when I run linker = UmlsEntityLinker(resolve_abbreviations=True) it doesn't find anything in cache.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:231,performance,cach,cache,231,"Ok, it is looking on ('~.scispacy'). I have downloaded the file tfidf_vectors_sparse.npz there and in the subfolder 'datasets' but still, when I run linker = UmlsEntityLinker(resolve_abbreviations=True) it doesn't find anything in cache.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:206,reliability,doe,doesn,206,"Ok, it is looking on ('~.scispacy'). I have downloaded the file tfidf_vectors_sparse.npz there and in the subfolder 'datasets' but still, when I run linker = UmlsEntityLinker(resolve_abbreviations=True) it doesn't find anything in cache.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:100,performance,content,contents,100,"@giuliacassara hmm, that is surprising. Can you paste the output of running it twice along with the contents of `ls ~/.scispacy` please?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:24,availability,error,error,24,"The main reason of this error is scispacy check cache_path with a sha256 prefix in **file_cache.py**, putting **tfidf_vectors_sparse.npz** in **~/.scispacy/datasets** is not enough. ```python. filename = url_to_filename(url, etag). cache_path = os.path.join(cache_dir, filename). ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:24,performance,error,error,24,"The main reason of this error is scispacy check cache_path with a sha256 prefix in **file_cache.py**, putting **tfidf_vectors_sparse.npz** in **~/.scispacy/datasets** is not enough. ```python. filename = url_to_filename(url, etag). cache_path = os.path.join(cache_dir, filename). ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:24,safety,error,error,24,"The main reason of this error is scispacy check cache_path with a sha256 prefix in **file_cache.py**, putting **tfidf_vectors_sparse.npz** in **~/.scispacy/datasets** is not enough. ```python. filename = url_to_filename(url, etag). cache_path = os.path.join(cache_dir, filename). ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/242:24,usability,error,error,24,"The main reason of this error is scispacy check cache_path with a sha256 prefix in **file_cache.py**, putting **tfidf_vectors_sparse.npz** in **~/.scispacy/datasets** is not enough. ```python. filename = url_to_filename(url, etag). cache_path = os.path.join(cache_dir, filename). ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/242
https://github.com/allenai/scispacy/issues/243:35,energy efficiency,model,model,35,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:192,energy efficiency,model,models,192,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:41,reliability,doe,does,41,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:171,safety,detect,detector,171,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:35,security,model,model,35,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:171,security,detect,detector,171,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:192,security,model,models,192,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:236,security,ident,identify,236,"Hi @mariosaenger ,. The bionlp13cg model does not have a `SPECIES/ORGANISM` entity type. So this is likely the reason. You might have better luck with the general mention detector in the main models, and then using the entity linker to identify types.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1246,integrability,transform,transformed,1246,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1329,integrability,transform,transforming,1329,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:684,interoperability,bind,binding,684,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1246,interoperability,transform,transformed,1246,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1329,interoperability,transform,transforming,1329,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:684,modifiability,bind,binding,684,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:953,safety,detect,detection,953,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:953,security,detect,detection,953,"Hi @DeNeutoy ,. may I was a bit misleading. I meant `ORGANISM`, however this entity type is called `SPECIES` in other corpora. According to https://allenai.github.io/scispacy/, bionlp13cg should have this entity type and there over over 100 occurrences of ""patients"" as `ORGANISM` in the training set of the corpus. . Additionally, I found such issues (with two entities that occur consecutively) in several other cases, e.g. - In this work, we show that an 11-amino acid peptide derived from the second immunoglobulin-like domain of Flt-1 functions as an angiogenic inhibitor in chick chorioallantoic membrane and inhibited VEGF-induced vascular permeability in Miles' assay without binding to VEGF directly. -> ... -> **chick chorioallantoic membrane(ORGANISM)**. -> ... Here, ""chick"" is `ORGANISM` and chorioallantoic membrane is `MULTI-TISSUE_STRUCTURE`. . - Taken together , our studies , based on a molecular imaging approach for semiquantitative detection of micrometastases , point to an important role of tumor lymphatics in the metastatic process of human prostate cancer . -> ... -> **human prostate cancer(ORGANISM)**. -> ... Here, ""human"" is `ORGANISM` and ""prostate cancer"" is `CANCER` . . - DNA of the non-tumorigenic cell hybrids transformed Rat-1 cells to anchorage-independent proliferation as expected for the transforming human Ha-ras gene present in the donor DNA. -> .. -> **human Ha-ras(ORGANISM)**. -> .. Here, ""human"" is `ORGANISM` and ""Ha-ras"" is `GENE_OR_GENE_PRODUCT` .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:370,energy efficiency,model,model,370,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:376,integrability,sub,substantially,376,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:514,integrability,abstract,abstract,514,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1434,integrability,filter,filter,1434,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:514,modifiability,abstract,abstract,514,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:917,performance,perform,performance,917,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:356,reliability,pra,practical,356,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:265,security,modif,modifiers,265,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:370,security,model,model,370,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:533,security,modif,modify,533,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:815,security,modif,modifiers,815,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1013,security,modif,modifiers,1013,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:1469,security,modif,modifiers,1469,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/243:917,usability,perform,performance,917,"Hi @mariosaenger thanks for the additional info. It seems like this is an annotation design in the original data which is a bit unfortunate:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2167. It annotates noun modifiers here as separate entities, which in some cases can be correct, but makes using a practical NER model substantially harder. For example in the line linked above, I don't really think that ""human"" refers to an entity - it's being used in an abstract sense, to modify the cell type. The word ""human"" in this sentence has no agency. . Not only is this kind of dubious annotation, but it is also inconsistent:. https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L2450. Here only _some_ of the noun modifiers are included in the entity. For me this is pretty damning and likely the reason that the F1 performance on this dataset is not that high. Even within this phenomena of annotating organism modifiers as entities, it is done inconsistently: . https://github.com/cambridgeltl/MTL-Bioinformatics-2016/blob/master/data/BioNLP13CG-IOB/train.tsv#L7570. here, it's pretty hard to argue that ""amphibian"" shouldn't also be an ORGANISM. This is actually quite interesting, but it's kind of tricky to fix without a bit of effort cleaning up the training data. However, that's probably not too difficult, to go through and filter entity boundaries which are modifiers or something. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/243
https://github.com/allenai/scispacy/issues/244:27,deployability,releas,release,27,Looks like the spacy 2.3.0 release requires retraining the models. Can you go back to `spacy==2.2.4`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:59,energy efficiency,model,models,59,Looks like the spacy 2.3.0 release requires retraining the models. Can you go back to `spacy==2.2.4`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:59,security,model,models,59,Looks like the spacy 2.3.0 release requires retraining the models. Can you go back to `spacy==2.2.4`?,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:56,energy efficiency,model,models,56,"I'm going to reopen this because we need to retrain the models for spacy 2.3.0 and other people will hit this, thanks for reporting!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:56,security,model,models,56,"I'm going to reopen this because we need to retrain the models for spacy 2.3.0 and other people will hit this, thanks for reporting!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:7,deployability,observ,observed,7,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:68,deployability,releas,release,68,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:221,energy efficiency,model,models,221,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:207,performance,tune,tune,207,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:221,security,model,models,221,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:7,testability,observ,observed,7,"I have observed the same problem. . Also, notice that the [new 1.10 release of Prodigy](https://prodi.gy/docs/changelog#v1.10.0) requires `spacy` v2.3. This means that `prodigy` v1.10 cannot be used to fine-tune ScispaCy models.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:32,deployability,releas,release,32,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:86,deployability,releas,release,86,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:212,deployability,version,versions,212,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:186,energy efficiency,model,models,186,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:212,integrability,version,versions,212,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:165,interoperability,incompatib,incompatibility,165,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:212,modifiability,version,versions,212,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:186,security,model,models,186,I ran into this as well -- 1.10 release of Prodigy requires spacy 2.3. Here are some [release notes on spacy 2.3](https://spacy.io/usage/v2-3#incompat) that mention incompatibility with models trained on earlier versions,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:0,usability,close,closed,0,closed by #247,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:89,deployability,version,version,89,i am facing same issue while importing en_core_web_sm in python3 and can't retrain spacy version from 2.3.5 to 2.2.5,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:89,integrability,version,version,89,i am facing same issue while importing en_core_web_sm in python3 and can't retrain spacy version from 2.3.5 to 2.2.5,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:89,modifiability,version,version,89,i am facing same issue while importing en_core_web_sm in python3 and can't retrain spacy version from 2.3.5 to 2.2.5,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:234,availability,avail,available,234,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:40,deployability,instal,install,40,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:234,reliability,availab,available,234,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:234,safety,avail,available,234,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:234,security,availab,available,234,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:272,security,ident,identification,272,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:104,usability,user,user-images,104,"a similar issue here. After using `!pip install spacy_fastlang`, I got the following:. ![image](https://user-images.githubusercontent.com/34965389/138071671-5dfc1eaa-d937-4db5-9cb2-38d8c26908f1.png). Basically I'm benchmarking Python available libraries for multilanguage identification. I regret SpaCy seems to have more issues than other alternatives. Any recommendation to fix this?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:139,availability,down,download,139,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:174,availability,ERROR,ERROR,174,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:68,deployability,instal,install,68,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:105,deployability,instal,install,105,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,deployability,depend,dependency,187,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:270,deployability,instal,installed,270,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:327,deployability,depend,dependency,327,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:651,deployability,instal,installed,651,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:216,energy efficiency,current,currently,216,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:352,energy efficiency,core,core-web-sm,352,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:451,energy efficiency,core,core-web-lg,451,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,integrability,depend,dependency,187,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:327,integrability,depend,dependency,327,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:338,interoperability,conflict,conflicts,338,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:434,interoperability,incompatib,incompatible,434,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:533,interoperability,incompatib,incompatible,533,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:624,interoperability,incompatib,incompatible,624,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,modifiability,depend,dependency,187,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:252,modifiability,pac,packages,252,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:327,modifiability,depend,dependency,327,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:174,performance,ERROR,ERROR,174,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:207,reliability,doe,does,207,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:174,safety,ERROR,ERROR,174,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,safety,depend,dependency,187,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:327,safety,depend,dependency,327,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,testability,depend,dependency,187,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:327,testability,depend,dependency,327,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:174,usability,ERROR,ERROR,174,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:286,usability,behavi,behaviour,286,"I followed the instructions here:. https://spacy.io/usage. ```. pip install -U pip setuptools wheel. pip install -U spacy. python -m spacy download en_core_web_sm. ```. ```. ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. en-core-web-sm 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. en-core-web-lg 3.1.0 requires spacy<3.2.0,>=3.1.0, but you have spacy 3.2.1 which is incompatible. allennlp 2.8.0 requires spacy<3.2,>=2.1.0, but you have spacy 3.2.1 which is incompatible. Successfully installed spacy-3.2.1. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:106,deployability,version,version,106,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,deployability,version,versions,187,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:213,deployability,version,versions,213,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:226,deployability,releas,released,226,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:354,deployability,version,version,354,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:38,energy efficiency,Model,Model,38,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:248,energy efficiency,model,model,248,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:106,integrability,version,version,106,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,integrability,version,versions,187,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:213,integrability,version,versions,213,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:354,integrability,version,version,354,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:69,interoperability,specif,specifies,69,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:153,interoperability,compatib,compatibility,153,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:267,interoperability,compatib,compatible,267,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:106,modifiability,version,version,106,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:187,modifiability,version,versions,187,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:213,modifiability,version,versions,213,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:354,modifiability,version,version,354,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:38,security,Model,Model,38,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:248,security,model,model,248,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/issues/244:18,usability,User,UserWarning,18,"Any fix to this? `UserWarning: [W094] Model 'en_core_web_sm' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the ""spacy_version"" in your meta.json to a version range, with a lower and upper pin. For example: >=3.4.2,<3.5.0. warnings.warn(warn_msg)`",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/244
https://github.com/allenai/scispacy/pull/245:365,deployability,releas,release,365,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:376,deployability,releas,release,376,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:65,energy efficiency,model,models,65,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:117,interoperability,format,formatting,117,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:199,interoperability,format,format,199,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:33,safety,review,review,33,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:65,security,model,models,65,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/pull/245:33,testability,review,review,33,"@danielkingai2 Just beginning to review this now, will check the models etc. Do you mind actually removing the black formatting commits? I know this wasn't mentioned anywhere, but I purposely didn't format these training files because they are duplicates of some spacy examples. Having them unformatted makes it easier to diff them if the training procedure breaks release to release. .",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/pull/245
https://github.com/allenai/scispacy/issues/248:60,safety,detect,detector,60,"Hi, are you referring to the entities output by the mention detector (i.e. strings) or the entities output by the entity linker (i.e. umls entities)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:60,security,detect,detector,60,"Hi, are you referring to the entities output by the mention detector (i.e. strings) or the entities output by the entity linker (i.e. umls entities)?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:158,energy efficiency,model,model,158,"Hi,. I am referring to all the entities trained in scispacy (md). Not wrt to any input. . And Also, is there any way in can remove some entities from trained model? Let us say, I don't want to extract them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:81,safety,input,input,81,"Hi,. I am referring to all the entities trained in scispacy (md). Not wrt to any input. . And Also, is there any way in can remove some entities from trained model? Let us say, I don't want to extract them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:158,security,model,model,158,"Hi,. I am referring to all the entities trained in scispacy (md). Not wrt to any input. . And Also, is there any way in can remove some entities from trained model? Let us say, I don't want to extract them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:81,usability,input,input,81,"Hi,. I am referring to all the entities trained in scispacy (md). Not wrt to any input. . And Also, is there any way in can remove some entities from trained model? Let us say, I don't want to extract them.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:110,energy efficiency,model,model,110,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:145,energy efficiency,load,load,145,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:246,energy efficiency,load,load,246,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:145,performance,load,load,145,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:246,performance,load,load,246,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:61,safety,detect,detector,61,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:61,security,detect,detector,61,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/248:110,security,model,model,110,"I still don't know whether you are talking about the mention detector or the entity linker. Are you using the model like this:. ```. nlp = spacy.load('en_core_sci_md'). doc = nlp(""Text""). entities = doc.ents. ```. or like this:. ```. nlp = spacy.load('en_core_sci_md'). nlp.add_pipe(EntityLinker()). doc = nlp(""Text""). entities = [ent._.kb_ents for ent in doc.ents]. ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/248
https://github.com/allenai/scispacy/issues/249:66,availability,error,error,66,"@diegoolano Derp sorry, my mistake. This is just a copy and paste error. I will fix this and release a fix to pypi on monday.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:93,deployability,releas,release,93,"@diegoolano Derp sorry, my mistake. This is just a copy and paste error. I will fix this and release a fix to pypi on monday.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:66,performance,error,error,66,"@diegoolano Derp sorry, my mistake. This is just a copy and paste error. I will fix this and release a fix to pypi on monday.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:66,safety,error,error,66,"@diegoolano Derp sorry, my mistake. This is just a copy and paste error. I will fix this and release a fix to pypi on monday.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:66,usability,error,error,66,"@diegoolano Derp sorry, my mistake. This is just a copy and paste error. I will fix this and release a fix to pypi on monday.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:91,availability,error,error,91,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:104,deployability,instal,install,104,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:129,deployability,instal,install,129,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:188,deployability,releas,releases,188,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:664,deployability,modul,module,664,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:361,energy efficiency,load,load,361,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:664,modifiability,modul,module,664,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:779,modifiability,pac,packages,779,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:91,performance,error,error,91,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:361,performance,load,load,361,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:91,safety,error,error,91,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:637,safety,input,input-,637,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:664,safety,modul,module,664,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:593,testability,Trace,Traceback,593,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:91,usability,error,error,91,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:637,usability,input,input-,637,"@DeNeutoy Just curious, is this issue resolved? Below is my code and I'm getting a similar error. `!pip install scispacy`. `!pip install https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.4/en_core_sci_sm-0.2.4.tar.gz`. `import spacy`. `import scispacy`. `from scispacy.linking import EntityLinker`. `import en_core_sci_sm`. `nlp = en_core_sci_sm.load()`. `linker = EntityLinker(resolve_abbreviations=False, name=""rxnorm"")`. `nlp.add_pipe(linker)`. `text = nlp(""Aspirin"")`. `print(doc.ents)`. ---------------------------------------------------------------------------. KeyError Traceback (most recent call last). <ipython-input-14-da740430c41c> in <module>(). ----> 1 text = nlp(""Aspirin""). 2 print(doc). 3 print(doc.ents). 2 frames. /usr/local/lib/python3.6/dist-packages/scispacy/candidate_generation.py in __call__(self, mention_texts, k). 342 for neighbor_index, distance in zip(neighbors, distances):. 343 mention = self.ann_concept_aliases_list[neighbor_index]. --> 344 concepts_for_mention = self.kb.alias_to_cuis[mention]. 345 for concept_id in concepts_for_mention:. 346 concept_to_mentions[concept_id].append(mention). KeyError: 'Aspirin'.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:102,availability,error,error,102,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:81,deployability,releas,release,81,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:274,deployability,version,version,274,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:368,deployability,instal,installed,368,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:274,integrability,version,version,274,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:274,modifiability,version,version,274,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:102,performance,error,error,102,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:294,reliability,doe,does,294,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:102,safety,error,error,102,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:38,security,Iso,Isopto,38,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:331,security,modif,modifying,331,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:102,usability,error,error,102,"I do have the same issue . KeyError: 'Isopto Alkaline'. It seems that in the new release he fixed the error, the file path is correct. file_path: str = ""https://ai2-s2-scispacy.s3-us-west-2.amazonaws.com/data/umls_2020_rxnorm.jsonl"", but I still get KeyError. EDIT: The pip version of scispacy does not have the fix. I have solved modifying the code directly into the installed library.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:66,deployability,releas,releasing,66,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:105,deployability,version,version,105,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:116,deployability,instal,installing,116,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:204,deployability,releas,release,204,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:105,integrability,version,version,105,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:152,integrability,coupl,couple,152,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:105,modifiability,version,version,105,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:152,modifiability,coupl,couple,152,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/249:152,testability,coupl,couple,152,"Hi, @giuliacassara and @sahas- - apologies, I never got around to releasing this. You can use the latest version by installing from master. There are a couple of other fixes I want to include in the next release, so we don't have a particular deadline for that at the moment sorry.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/249
https://github.com/allenai/scispacy/issues/251:508,deployability,contain,contains,508,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:537,energy efficiency,load,loaded,537,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:590,energy efficiency,model,model,590,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:892,energy efficiency,model,model,892,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:903,energy efficiency,predict,predict,903,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:976,energy efficiency,model,model,976,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:754,interoperability,format,formatting,754,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:537,performance,load,loaded,537,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:898,reliability,doe,does,898,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:903,safety,predict,predict,903,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:590,security,model,model,590,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:892,security,model,model,892,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:976,security,model,model,976,"Thanks for the report! The list of labels present in the dataset is:. ```. {'AMINO_ACID',. 'ANATOMICAL_SYSTEM',. 'CANCER',. 'CELL',. 'CELLULAR_COMPONENT',. 'DEVELOPING_ANATOMICAL_STRUCTURE',. 'GENE_OR_GENE_PRODUCT',. 'IMMATERIAL_ANATOMICAL_ENTITY',. 'MULTI-TISSUE_STRUCTURE',. 'ORGAN',. 'ORGANISM',. 'ORGANISM_SUBDIVISION',. 'ORGANISM_SUBSTANCE',. 'PATHOLOGICAL_FORMATION',. 'SIMPLE_CHEMICAL',. 'TISSUE'}. ```. This is basically your first list (with some small changes to the exact names). Your second list contains ""ENTITY"" because we loaded the generic NER pipe first when training this model, this should not affect the output. I am not sure why spacy splits up `MULTI-TISSUE_STRUCTURE` when displaying `nlp.entity.labels`, perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. I'd have to look into that more, but since you said the model does predict `MULTI-TISSUE_STRUCTURE`, I'm guessing this is not affecting the model either. The third list is just wrong (it is missing `PATHOLOGICAL_FORMATION` and `ORGANISM_SUBSTANCE`), and we need to fix that, thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:340,deployability,pipelin,pipeline,340,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:198,energy efficiency,model,model,198,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:470,energy efficiency,model,model,470,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:529,energy efficiency,model,model,529,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:340,integrability,pipelin,pipeline,340,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:77,interoperability,format,formatting,77,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:198,security,model,model,198,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:470,security,model,model,470,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:529,security,model,model,529,"Dear @danielkingai2 thanks for the prompt reply. > perhaps this is just some formatting thing, like maybe spacy expects no hyphens in the labels or something. Yes, I just found the reason why your `model.entity.labels` is broken. The reason is found in [these lines of the source code|. https://github.com/explosion/spaCy/blob/master/spacy/pipeline/pipes.pyx#L1124-L1133]. Basically, `labels` is a `property` set by taking `label = move.split(""-"")[1]` for each `move in model.entity.move_names`. So you should remove hyphens or `model.entity.labels` will be broken: can you do that? . > The third list is just wrong (it is missing PATHOLOGICAL_FORMATION and ORGANISM_SUBSTANCE), and we need to fix that, thanks! If you can fix it it would be super useful, thank you very much!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:70,deployability,version,version,70,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:365,deployability,releas,release,365,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:114,energy efficiency,model,model,114,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:236,energy efficiency,predict,predicted,236,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:318,energy efficiency,model,model,318,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:70,integrability,version,version,70,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:402,integrability,sub,submit,402,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:70,modifiability,version,version,70,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:141,safety,compl,complete,141,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:236,safety,predict,predicted,236,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:114,security,model,model,114,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:141,security,compl,complete,141,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:318,security,model,model,318,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:435,usability,document,documentation,435,"I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:174,energy efficiency,model,models,174,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:300,energy efficiency,model,models,300,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:154,performance,time,time,154,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:282,performance,time,time,282,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:174,security,model,models,174,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:300,security,model,models,300,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:26,usability,close,close,26,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:73,usability,document,documentation,73,"I'm going to go ahead and close this. I just merged #254 which fixes the documentation, and will fix the printing issue with `nlp.entity.labels` the next time we retrain the models. The presence of the generic `ENTITY` tag is something we will have to think about more for the next time we train the models. Thanks!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:72,deployability,version,version,72,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:367,deployability,releas,release,367,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:116,energy efficiency,model,model,116,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:238,energy efficiency,predict,predicted,238,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:320,energy efficiency,model,model,320,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:560,energy efficiency,model,model,560,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:72,integrability,version,version,72,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:404,integrability,sub,submit,404,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:72,modifiability,version,version,72,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:143,safety,compl,complete,143,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:238,safety,predict,predicted,238,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:116,security,model,model,116,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:143,security,compl,complete,143,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:320,security,model,model,320,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:560,security,model,model,560,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/251:437,usability,document,documentation,437,"> I will likely not be fixing the issue in `nlp.entity.labels` for this version, as it would require retraining the model, but you can get the complete list from `nlp.entity.move_names` if you desire. The generic ""ENTITY"" should never be predicted since its not in the training data, but whether or not this impacts the model is something I will look at for the next release. And on the last point, I'll submit a fix to the github pages documentation shortly. For anyone landing on this issue before the bug is fixed, you can get the correct labels from _any_ model using the following snippet:. ```python. def get_labels(ner):. '''Like ner.labels, but correctly handles bug in en_ner_bionlp13cg_md.'''. return sorted({'-'.join(move.split('-')[1:]) . for move in ner.move_names. if move[:2] in ['B-', 'I-', 'L-', 'U-']}). ```",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/251
https://github.com/allenai/scispacy/issues/252:97,availability,down,downloading,97,"Hi @DeNeutoy , well making it smaller in size probably is already quite helpful, especially when downloading the files for the first time and initialising the Entity Linker? That's what I meant with more efficient, actually - the linking itself is quite fast, I think. Anyway, thanks a lot for taking this up!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:133,performance,time,time,133,"Hi @DeNeutoy , well making it smaller in size probably is already quite helpful, especially when downloading the files for the first time and initialising the Entity Linker? That's what I meant with more efficient, actually - the linking itself is quite fast, I think. Anyway, thanks a lot for taking this up!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:72,usability,help,helpful,72,"Hi @DeNeutoy , well making it smaller in size probably is already quite helpful, especially when downloading the files for the first time and initialising the Entity Linker? That's what I meant with more efficient, actually - the linking itself is quite fast, I think. Anyway, thanks a lot for taking this up!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:204,usability,efficien,efficient,204,"Hi @DeNeutoy , well making it smaller in size probably is already quite helpful, especially when downloading the files for the first time and initialising the Entity Linker? That's what I meant with more efficient, actually - the linking itself is quite fast, I think. Anyway, thanks a lot for taking this up!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:0,usability,Close,Closed,0,Closed by #275,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:114,interoperability,convers,conversation,114,"@DeNeutoy @danielkingai2 . In case you have missed it, I have made a suggestion on creating unique aliases in the conversation of https://github.com/allenai/scispacy/pull/274#issuecomment-726096229.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:100,deployability,modul,modules,100,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:488,energy efficiency,reduc,reduction,488,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:1021,energy efficiency,frequenc,frequency,1021,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:100,modifiability,modul,modules,100,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:822,modifiability,paramet,parameter,822,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:100,safety,modul,modules,100,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:252,security,token,tokenizing,252,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:83,usability,learn,learn,83,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/252:1012,usability,document,document,1012,"By default strings are converted into lowercase by TfidfVectorizer. https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html. ```. lowercase : bool, default=True. Convert all characters to lowercase before tokenizing. ```. So isn't it that when removing duplicate aliases, we should ignore the case? In that case, in the example mentioned by @ChantalvanSon . `'NIVOLUMAB', 'nivolumab', 'Nivolumab'`. becomes same? So this can lead to further reduction in size of concept_aliases.json. TfIdf vectorizer is called at. https://github.com/allenai/scispacy/blob/master/scispacy/candidate_generation.py#L410. ```. tfidf_vectorizer = TfidfVectorizer(. analyzer=""char_wb"", ngram_range=(3, 3), min_df=10, dtype=numpy.float32. ). ```. which means we are using the default value for the parameter `lowercase`. ### A question:. @DeNeutoy @danielkingai2. As we change the list of concept aliases, it would also change the vector representation of these concept aliases since the document frequency of the char trigram vocabulary also changes. Isn't that going to impact the similarity score of entity candidate with the concept aliases?",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/252
https://github.com/allenai/scispacy/issues/253:269,availability,down,download,269,"Hi @pixelicus, is having the HPO ids a hard requirement for you? I don't think we're going to get to that in the short term - mostly because i'm not entirely sure how to extract this cross linking info out of UMLS. The easiest thing to do in the short term would be to download the HPO and create a reverse mapping (i.e from UMLS ids -> HPO ids) - e.g you can see here that the UMLS id is in the ""cross reference"" section: https://hpo.jax.org/app/browse/term/HP:0001631",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:727,availability,avail,available,727,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:366,deployability,contain,contains,366,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:327,interoperability,Ontolog,Ontology,327,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:357,interoperability,Ontolog,Ontology,357,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:727,reliability,availab,available,727,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:727,safety,avail,available,727,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:727,security,availab,available,727,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:737,usability,document,documentation,737,"Thanks for the answer. Yep, in our case, HPO entity recognition (with HP ids) is needed. We've tried other scripts to do so but I liked very much the idea of using spacy and scispacy, mostly because already used to get UMLs mappings. Reading https://github.com/allenai/scispacy#entitylinker. ""hpo: Links to the Human Phenotype Ontology. The Human Phenotype Ontology contains 16k concepts focused on phenotypic abnormalities encountered in human disease."". thought it was possible to obtain such IDs. . But at least, if I can extract precise HPO terms, yes it will be possible to get Id from HPO itself. Nevertheless, I think I'm still confuse about how to exploit properly the linker, I guess I need to read more about it. Any available documentation, links or projects already known. Kind of ""entitylinker for dummies"" ? Best regards,.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:329,interoperability,ontolog,ontology,329,"the JSON file only has UMLS CUIs, so getting HPO will take an extra step. https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/scispacy/linking_utils.py#L113 . Do wish these JSON files had extra item of HPO ids. The only way to get the HPO terms is either use UMLS to crosswalk or simply use the HPO ontology files to extract the HPO-UMLS CUI mappings.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:310,testability,simpl,simply,310,"the JSON file only has UMLS CUIs, so getting HPO will take an extra step. https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/scispacy/linking_utils.py#L113 . Do wish these JSON files had extra item of HPO ids. The only way to get the HPO terms is either use UMLS to crosswalk or simply use the HPO ontology files to extract the HPO-UMLS CUI mappings.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/253:310,usability,simpl,simply,310,"the JSON file only has UMLS CUIs, so getting HPO will take an extra step. https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/scispacy/linking_utils.py#L113 . Do wish these JSON files had extra item of HPO ids. The only way to get the HPO terms is either use UMLS to crosswalk or simply use the HPO ontology files to extract the HPO-UMLS CUI mappings.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/253
https://github.com/allenai/scispacy/issues/255:17,deployability,version,version,17,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:78,deployability,version,version,78,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:72,energy efficiency,model,model,72,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:17,integrability,version,version,17,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:78,integrability,version,version,78,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:17,modifiability,version,version,17,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:78,modifiability,version,version,78,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:72,security,model,model,72,"Sorry, this is a version issue. scispacy 0.2.5 requires spacy 2.3.x and model version 0.2.5.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:12,availability,error,error,12,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:41,deployability,updat,updating,41,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:146,deployability,instal,installed,146,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:137,modifiability,pac,packages,137,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:12,performance,error,error,12,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:12,safety,error,error,12,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:41,safety,updat,updating,41,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:41,security,updat,updating,41,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:12,usability,error,error,12,"Hi still an error throwing in even after updating en_core_sci_lg to 2.5, while creating Linker. Any clue on that? i have attached all my packages installed in the env.`. [env_pack.txt](https://github.com/allenai/scispacy/files/4965782/env_pack.txt). `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:70,deployability,instal,install,70,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:143,deployability,releas,releases,143,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:34,energy efficiency,core,core-sci-lg,34,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:86,energy efficiency,model,model,86,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:5,modifiability,pac,package,5,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:86,security,model,model,86,Your package list still shows `en-core-sci-lg` 0.2.4. you need to pip install the new model https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.2.5/en_core_sci_lg-0.2.5.tar.gz,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:20,availability,error,error,20,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:160,availability,error,error,160,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:55,deployability,version,versions,55,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:64,deployability,instal,installed,64,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:251,deployability,modul,module,251,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:829,deployability,instal,installed,829,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:909,deployability,instal,installed,909,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:55,integrability,version,versions,55,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:55,modifiability,version,versions,55,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:251,modifiability,modul,module,251,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:353,modifiability,pac,packages,353,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:845,modifiability,pac,packages,845,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:925,modifiability,pac,packages,925,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:20,performance,error,error,20,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:160,performance,error,error,160,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:20,safety,error,error,20,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:160,safety,error,error,160,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:223,safety,input,input-,223,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:251,safety,modul,module,251,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:179,testability,Trace,Traceback,179,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:20,usability,error,error,20,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:160,usability,error,error,160,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:223,usability,input,input-,223,"I'm having the same error, too, but I have the correct versions installed (en-ner-bionlp13cg-md 0.2.5 + spacy 2.3.2 + scispacy 0.2.5). . Throwing the following error:. `TypeError Traceback (most recent call last). <ipython-input-262-eadd79906c1b> in <module>. ----> 1 linker = EntityLinker(resolve_abbreviations=True, name=""mesh""). ~\Anaconda3\lib\site-packages\scispacy\linking.py in __init__(self, candidate_generator, resolve_abbreviations, k, threshold, no_definition_threshold, filter_for_definitions, max_entities_per_mention, name). 75 Span.set_extension(""kb_ents"", default=[], force=True). 76 . ---> 77 self.candidate_generator = candidate_generator or CandidateGenerator(name=name). 78 self.resolve_abbreviations = resolve_abbreviations. 79 self.k = k. TypeError: __init__() got an unexpected keyword argument 'name'`. [installed conda packages.txt](https://github.com/allenai/scispacy/files/4968036/installed.conda.packages.txt).",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/255:44,usability,help,help,44,"Clean environment solved it, thanks for the help!",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/255
https://github.com/allenai/scispacy/issues/256:34,deployability,version,versions,34,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:99,deployability,releas,release,99,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:146,deployability,version,version,146,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:34,integrability,version,versions,34,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:146,integrability,version,version,146,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:47,interoperability,incompatib,incompatible,47,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:34,modifiability,version,versions,34,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/256:146,modifiability,version,version,146,"This is not possible, sorry - the versions are incompatible. The mesh linker is only in the latest release, and that requires the most up to date version of spacy - 2.3.x",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/256
https://github.com/allenai/scispacy/issues/258:147,deployability,instal,install,147,"You can clone the repo, change this line: https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/setup.py#L53. and then install the package yourself (`python setup.py install` or `pip install .`). I can't guarantee that it will work on python2.7, but it might, since spacy works on python2.7.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:194,deployability,instal,install,194,"You can clone the repo, change this line: https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/setup.py#L53. and then install the package yourself (`python setup.py install` or `pip install .`). I can't guarantee that it will work on python2.7, but it might, since spacy works on python2.7.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:211,deployability,instal,install,211,"You can clone the repo, change this line: https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/setup.py#L53. and then install the package yourself (`python setup.py install` or `pip install .`). I can't guarantee that it will work on python2.7, but it might, since spacy works on python2.7.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:159,modifiability,pac,package,159,"You can clone the repo, change this line: https://github.com/allenai/scispacy/blob/e9f0daeae9a76c644166f852f1d8a101e77d9593/setup.py#L53. and then install the package yourself (`python setup.py install` or `pip install .`). I can't guarantee that it will work on python2.7, but it might, since spacy works on python2.7.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:103,availability,error,error,103,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:145,availability,ERROR,ERROR,145,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:160,availability,error,errored,160,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2926,availability,ERROR,ERROR,2926,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3508,availability,error,error,3508,"et_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). Fil",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3516,availability,ERROR,ERROR,3516,"ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3531,availability,error,errored,3531,", get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6287,availability,ERROR,ERROR,6287,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6464,availability,error,error,6464,"nt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6472,availability,ERROR,ERROR,6472,"hub/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dis",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6487,availability,error,errored,6487,"ite-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9175,availability,ERROR,ERROR,9175,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setupto",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9354,availability,error,error,9354,"/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9362,availability,ERROR,ERROR,9362,"b/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/m",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9377,availability,error,errored,9377,"e-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jyth",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12136,availability,ERROR,ERROR,12136,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptoo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12317,availability,error,error,12317,"/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). Fil",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12325,availability,ERROR,ERROR,12325,"jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12340,availability,error,errored,12340,"packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15096,availability,ERROR,ERROR,15096,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15275,availability,error,error,15275,"/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/c",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15283,availability,ERROR,ERROR,15283,"b/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15298,availability,error,errored,15298,"e-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, i",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16703,availability,ERROR,ERROR,16703,"l -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16777,availability,ERROR,ERROR,16777,"output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16792,availability,error,errored,16792,"):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with stat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17647,availability,ERROR,ERROR,17647,"rocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17800,availability,error,error,17800," with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distr",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17808,availability,ERROR,ERROR,17808,"it status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17823,availability,error,errored,17823,"mmand: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_li",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20365,availability,ERROR,ERROR,20365,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20552,availability,error,error,20552,"b/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20560,availability,ERROR,ERROR,20560,"/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20575,availability,error,errored,20575,"es/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_com",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23371,availability,ERROR,ERROR,23371,"command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24180,availability,ERROR,ERROR,24180,"-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/L",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25214,availability,operat,operations,25214,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25348,availability,operat,operations,25348,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:303,deployability,instal,install-,303,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:364,deployability,instal,install-,364,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:614,deployability,instal,install-,614,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:733,deployability,modul,module,733,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:757,deployability,instal,install-,757,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:805,deployability,modul,module,805,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:846,deployability,instal,install-,846,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2310,deployability,modul,module,2310,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /h",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2462,deployability,modul,module,2462,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel f",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2631,deployability,modul,module,2631,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2788,deployability,modul,module,2788,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2842,deployability,modul,module,2842,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2933,deployability,Fail,Failed,2933,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_w",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2940,deployability,build,building,2940,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3004,deployability,Build,Building,3004,"/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Comp",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3055,deployability,Build,Building,3055,"class[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent cal",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3403,deployability,Build,Building,3403,"/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). Fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3449,deployability,Build,Building,3449," 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3674,deployability,instal,install-,3674,"cosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", l",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3733,deployability,instal,install-,3733,"e-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.pars",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:3981,deployability,instal,install-,3981,"clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4098,deployability,modul,module,4098,"shed with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.p",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4122,deployability,instal,install-,4122,"Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_c",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4168,deployability,modul,module,4168,"hash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_cla",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4209,deployability,instal,install-,4209,"888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Li",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5671,deployability,modul,module,5671,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__=",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5823,deployability,modul,module,5823,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5992,deployability,modul,module,5992,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_CO",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6149,deployability,modul,module,6149,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <modu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6203,deployability,modul,module,6203,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packa",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6294,deployability,Fail,Failed,6294,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6301,deployability,build,building,6301,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6361,deployability,Build,Building,6361,"ools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. o",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6406,deployability,Build,Building,6406,". self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/g",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6630,deployability,instal,install-,6630,"__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6688,deployability,instal,install-,6688,"elf.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6935,deployability,instal,install-,6935,"Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7079,deployability,modul,module,7079,"b/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7103,deployability,instal,install-,7103,"s/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/dist",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7148,deployability,modul,module,7148,"dule>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8559,deployability,modul,module,8559,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __fil",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8711,deployability,modul,module,8711,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8880,deployability,modul,module,8880,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. T",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9037,deployability,modul,module,9037,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9091,deployability,modul,module,9091,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", lin",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9182,deployability,Fail,Failed,9182,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__i",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9189,deployability,build,building,9189,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9247,deployability,Build,Building,9247,"ptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9294,deployability,Build,Building,9294,". self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/cor",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9520,deployability,instal,install-,9520,"init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9580,deployability,instal,install-,9580,"module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.pa",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9829,deployability,instal,install-,9829,"te-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9947,deployability,modul,module,9947,". File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.p",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:9971,deployability,instal,install-,9971,"hon/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_c",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:10017,deployability,modul,module,10017,""", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_cla",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:10058,deployability,instal,install-,10058,"fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Li",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11520,deployability,modul,module,11520,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11672,deployability,modul,module,11672,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11841,deployability,modul,module,11841,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Tr",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11998,deployability,modul,module,11998,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package()",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12052,deployability,modul,module,12052,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12143,deployability,Fail,Failed,12143,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__in",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12150,deployability,build,building,12150,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py""",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12212,deployability,Build,Building,12212,"ls/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). Fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12258,deployability,Build,Building,12258,"elf.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12483,deployability,instal,install-,12483,"it__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", l",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12542,deployability,instal,install-,12542,"odule_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.pars",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12790,deployability,instal,install-,12790,"te-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12907,deployability,modul,module,12907,"n. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.p",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12931,deployability,instal,install-,12931,"thon/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_c",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:12977,deployability,modul,module,12977,"y"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_cla",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:13018,deployability,instal,install-,13018,"_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Li",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14480,deployability,modul,module,14480,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14632,deployability,modul,module,14632,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14801,deployability,modul,module,14801,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Runn",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14958,deployability,modul,module,14958,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", lin",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15012,deployability,modul,module,15012,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-in",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15103,deployability,Fail,Failed,15103,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15110,deployability,build,building,15110,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. F",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15170,deployability,Build,Building,15170,"ools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15216,deployability,Build,Building,15216," self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15441,deployability,instal,install-,15441,"init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15500,deployability,instal,install-,15500,".module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. Fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15748,deployability,instal,install-,15748,"site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running s",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15902,deployability,modul,module,15902,"ite-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15926,deployability,instal,install-,15926,"_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:15972,deployability,modul,module,15972,"command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16013,deployability,instal,install-,16013,"e' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16128,deployability,instal,install-,16128,"ly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""')",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16191,deployability,modul,module,16191," (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clea",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16240,deployability,instal,install-,16240,"tup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Compl",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16305,deployability,modul,module,16305,"t with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16342,deployability,log,log,16342,"/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, us",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16362,deployability,instal,install-,16362,"ython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16399,deployability,log,log,16399,", tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cl",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16421,deployability,modul,module,16421," = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16517,deployability,instal,install-,16517,"setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git r",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16582,deployability,modul,module,16582,");code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you mu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16631,deployability,modul,module,16631,"'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . -----------------------------",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16710,deployability,Fail,Failed,16710,"mp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pat",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16717,deployability,build,building,16717,"heel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16935,deployability,instal,install-,16935,"D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; s",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16994,deployability,instal,install-,16994,"File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17217,deployability,instal,install-,17217,"er. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17449,deployability,version,versioned,17449,"red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17654,deployability,Fail,Failed,17654,"ng. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17670,deployability,build,build,17670,"----------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17691,deployability,Build,Building,17691,"------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File """,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17739,deployability,Build,Building,17739,"Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptool",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17966,deployability,instal,install-,17966," __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). Fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18027,deployability,instal,install-,18027,"getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18277,deployability,instal,install-,18277,"numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18396,deployability,modul,module,18396,"cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18420,deployability,instal,install-,18420," clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/s",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18466,deployability,modul,module,18466,"sn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, i",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:19749,deployability,modul,module,19749,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:19901,deployability,modul,module,19901,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20070,deployability,modul,module,20070,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20227,deployability,modul,module,20227,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20281,deployability,modul,module,20281,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. Fi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20372,deployability,Fail,Failed,20372,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/g",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20379,deployability,build,building,20379,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jy",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20443,deployability,Build,Building,20443,"/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in set",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20491,deployability,Build,Building,20491,"cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File """,MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20718,deployability,instal,install-,20718,"y"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:20779,deployability,instal,install-,20779,"me, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_com",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21029,deployability,instal,install-,21029,"s/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dis",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21273,deployability,modul,module,21273,"or: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/m",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21297,deployability,instal,install-,21297,"o attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/di",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21344,deployability,modul,module,21344,"----------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:22755,deployability,modul,module,22755,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will r",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:22907,deployability,modul,module,22907,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at h",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23076,deployability,modul,module,23076,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, config",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23233,deployability,modul,module,23233,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. F",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23287,deployability,modul,module,23287,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_inter",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23378,deployability,Fail,Failed,23378,"_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23385,deployability,build,building,23385,"ommand). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23486,deployability,Fail,Failed,23486,"class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self,",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23496,deployability,build,build,23496,"f.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23580,deployability,build,build,23580,"ages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23723,deployability,instal,install,23723,"py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23839,deployability,build,build,23839,"hub/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:23950,deployability,Instal,Installing,23950,"get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24710,deployability,instal,install,24710,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24741,deployability,instal,installed,24741,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24842,deployability,instal,install,24842,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24873,deployability,instal,installed,24873,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25027,deployability,instal,install,25027,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25130,deployability,instal,install,25130,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25225,deployability,instal,install,25225,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:25359,deployability,instal,install,25359,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1023,energy efficiency,core,core,1023,"n Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1085,energy efficiency,core,core,1085,"g the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1188,energy efficiency,core,core,1188,":. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2090,energy efficiency,load,load,2090,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2185,energy efficiency,load,load,2185,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4384,energy efficiency,core,core,4384,"3acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4446,energy efficiency,core,core,4446," Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4549,energy efficiency,core,core,4549,"t status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5451,energy efficiency,load,load,5451,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished wi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5546,energy efficiency,load,load,5546,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jytho",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7272,energy efficiency,core,core,7272,"-----------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7334,energy efficiency,core,core,7334,"etup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7437,energy efficiency,core,core,7437,"): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8339,energy efficiency,load,load,8339,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8434,energy efficiency,load,load,8434,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jyt",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:10233,energy efficiency,core,core,10233,"n for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:10295,energy efficiency,core,core,10295,"lding wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:10398,energy efficiency,core,core,10398,"tatus 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/wasabi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-6GDqjI. cwd: /tmp/pip-install-K8TU7D/wasabi/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 41, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/wasabi/setup.py"", line 24, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11300,energy efficiency,load,load,11300,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finishe",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:11395,energy efficiency,load,load,11395,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for wasabi. Running setup.py clean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/j",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:13193,energy efficiency,core,core,13193,"lean for wasabi. Building wheel for srsly (setup.py): started. Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:13255,energy efficiency,core,core,13255," Building wheel for srsly (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:13358,energy efficiency,core,core,13358,"t status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/srsly/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-JqCOON. cwd: /tmp/pip-install-K8TU7D/srsly/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 199, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/srsly/setup.py"", line 158, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14260,energy efficiency,load,load,14260,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:14355,energy efficiency,load,load,14355,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jyt",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:16094,energy efficiency,core,core,16094,"ERROR: Failed building wheel for srsly. Running setup.py clean for srsly. Building wheel for numpy (setup.py): started. Building wheel for numpy (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-hiH_Wq. cwd: /tmp/pip-install-K8TU7D/numpy/. Complete output (16 lines):. Running from numpy source directory. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 419, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/numpy/setup.py"", line 398, in setup_package. from numpy.distutils.core import setup. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/__init__.py"", line 6, in <module>. from . import ccompiler. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/ccompiler.py"", line 18, in <module>. from numpy.distutils import log. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/log.py"", line 10, in <module>. from .misc_util import (red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().r",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18524,energy efficiency,core,core,18524," . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:18627,energy efficiency,core,core,18627,"----------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", line 6, in <module>. setup(. File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:19529,energy efficiency,load,load,19529,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): f",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:19624,energy efficiency,load,load,19624,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for pathlib. Running setup.py clean for pathlib. Building wheel for scandir (setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/gi",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21468,energy efficiency,core,core,21468,"(setup.py): started. Building wheel for scandir (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21530,energy efficiency,core,core,21530,"nished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:21633,energy efficiency,core,core,21633,"on/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/scandir/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-st4OQK. cwd: /tmp/pip-install-K8TU7D/scandir/. Complete output (35 lines):. /mnt/d/github/jython/Lib/distutils/extension.py:133: UserWarning: Unknown Extension options: 'optional'. warnings.warn(msg). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/scandir/setup.py"", line 51, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:22535,energy efficiency,load,load,22535,""", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly num",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:22630,energy efficiency,load,load,22630,"/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for scandir. Running setup.py clean for scandir. Successfully built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:17449,integrability,version,versioned,17449,"red_text, default_text, cyan_text, green_text,. File ""/tmp/pip-install-K8TU7D/numpy/numpy/distutils/misc_util.py"", line 12, in <module>. import multiprocessing. ImportError: No module named multiprocessing. ----------------------------------------. ERROR: Failed building wheel for numpy. Running setup.py clean for numpy. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/numpy/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' clean --all. cwd: /tmp/pip-install-K8TU7D/numpy. Complete output (10 lines):. Running from numpy source directory. . `setup.py clean` is not supported, use one of the following instead:. . - `git clean -xdf` (cleans all files). - `git clean -Xdf` (cleans all versioned files, doesn't touch. files that aren't checked into the git repo). . Add `--force` to your command to use it anyway if you must (unsupported). . ----------------------------------------. ERROR: Failed cleaning build dir for numpy. Building wheel for pathlib (setup.py): started. Building wheel for pathlib (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/pathlib/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-L42Bzi. cwd: /tmp/pip-install-K8TU7D/pathlib/. Complete output (31 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/pathlib/setup.py"", ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24463,integrability,wrap,wrapper,24463,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24599,integrability,wrap,wrapper,24599,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24463,interoperability,wrapper,wrapper,24463,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:24599,interoperability,wrapper,wrapper,24599,"y built cymem murmurhash. Failed to build preshed thinc blis wasabi srsly numpy pathlib scandir. DEPRECATION: Could not build wheels for preshed, thinc, blis, wasabi, srsly, numpy, pathlib, scandir which do not use PEP 517. pip will fall back to legacy 'setup.py install' for these. pip 21.0 will remove support for this functionality. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368. Installing collected packages: setuptools, wheel, cython, cymem, murmurhash, preshed, numpy, blis, wasabi, pathlib, srsly, configparser, contextlib2, zipp, scandir, six, pathlib2, importlib-metadata, catalogue, plac, tqdm, thinc. ERROR: Exception:. Traceback (most recent call last):. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/base_command.py"", line 216, in _main. status = self.run(options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/cli/req_command.py"", line 182, in wrapper. return func(self, options, args). File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/commands/install.py"", line 412, in run. installed = install_given_reqs(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/__init__.py"", line 82, in install_given_reqs. requirement.install(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/req/req_install.py"", line 823, in install. install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 821, in install_wheel. _install_wheel(. File ""/mnt/d/github/jython/Lib/site-packages/pip/_internal/operations/install/wheel.py"", line 703, in _install_wheel. assert os.path.exists(pyc_path). AssertionError. ```.",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:733,modifiability,modul,module,733,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:805,modifiability,modul,module,805,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:952,modifiability,pac,packages,952,"So, now I am trying to run Scispacy in Jython which supports Python 2.7 but I am getting the following error: - . Any clue regarding this ? ```. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/se",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1286,modifiability,pac,packages,1286,"""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/preshed/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", lin",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1565,modifiability,pac,packages,1565,"heel -d /tmp/pip-wheel-QusvHE. cwd: /tmp/pip-install-K8TU7D/preshed/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 152, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/preshed/setup.py"", line 116, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/githu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:1989,modifiability,pac,packages,1989,"5, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean fo",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2134,modifiability,pac,packages,2134,"_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created whee",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2250,modifiability,pac,packages,2250," ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493ce",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2310,modifiability,modul,module,2310,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /h",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2417,modifiability,pac,packages,2417,"hon/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2462,modifiability,modul,module,2462,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel f",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2587,modifiability,pac,packages,2587,"y"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jyth",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2631,modifiability,modul,module,2631,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2739,modifiability,pac,packages,2739," line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2788,modifiability,modul,module,2788,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:2842,modifiability,modul,module,2842,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for preshed. Running setup.py clean for preshed. Building wheel for murmurhash (setup.py): started. Building wheel for murmurhash (setup.py): finished with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4098,modifiability,modul,module,4098,"shed with status 'done'. Created wheel for murmurhash: filename=murmurhash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.p",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4168,modifiability,modul,module,4168,"hash-1.0.2-jy27-none-java11_0_8.whl size=5888 sha256=64f485d45727cee76ee7301c0493cef441063f4d8b954c1e0d7ccc9304ea2485. Stored in directory: /home/sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_cla",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4313,modifiability,pac,packages,4313,"sachit/.cache/pip/wheels/15/e4/bd/9a3e3a5ac7ad943ff27bafc3a105ce572b73acd31019549ec2. Building wheel for thinc (setup.py): started. Building wheel for thinc (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). Fil",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4647,modifiability,pac,packages,4647,"rgv[0] = '""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/thinc/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", lin",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:4926,modifiability,pac,packages,4926,"dist_wheel -d /tmp/pip-wheel-1ofVsa. cwd: /tmp/pip-install-K8TU7D/thinc/. Complete output (35 lines):. Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 264, in <module>. setup_package(). File ""/tmp/pip-install-K8TU7D/thinc/setup.py"", line 201, in setup_package. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/githu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5350,modifiability,pac,packages,5350,"5, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5495,modifiability,pac,packages,5495,"_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out ",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5611,modifiability,pac,packages,5611," ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] =",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5671,modifiability,modul,module,5671,""", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__=",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5778,modifiability,pac,packages,5778,"hon/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.r",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5823,modifiability,modul,module,5823,"se_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5948,modifiability,pac,packages,5948,"y"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/bl",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:5992,modifiability,modul,module,5992,"s = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_CO",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6100,modifiability,pac,packages,6100," line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-i",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6149,modifiability,modul,module,6149,"elf.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <modu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:6203,modifiability,modul,module,6203,"thon/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packa",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7079,modifiability,modul,module,7079,"b/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7148,modifiability,modul,module,7148,"dule>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7201,modifiability,pac,packages,7201,"dule' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for thinc. Running setup.py clean for thinc. Building wheel for blis (setup.py): started. Building wheel for blis (setup.py): finished with status 'error'. ERROR: Command errored out with exit status 1:. command: /mnt/d/github/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). Fil",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7535,modifiability,pac,packages,7535,"hub/jython/bin/jython -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""'; __file__='""'""'/tmp/pip-install-K8TU7D/blis/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", lin",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:7814,modifiability,pac,packages,7814,"n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' bdist_wheel -d /tmp/pip-wheel-_Nn0OT. cwd: /tmp/pip-install-K8TU7D/blis/. Complete output (34 lines):. ('BLIS_COMPILER?', 'None'). Traceback (most recent call last):. File ""<string>"", line 1, in <module>. File ""/tmp/pip-install-K8TU7D/blis/setup.py"", line 239, in <module>. setup(. File ""/mnt/d/github/jython/Lib/site-packages/setuptools/__init__.py"", line 145, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/githu",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8238,modifiability,pac,packages,8238,"5, in setup. return distutils.core.setup(**attrs). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for b",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
https://github.com/allenai/scispacy/issues/258:8383,modifiability,pac,packages,8383,"_line(). File ""/mnt/d/github/jython/Lib/distutils/core.py"", line 137, in setup. ok = dist.parse_command_line(). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 703, in parse_command_line. result = _Distribution.parse_command_line(self). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 467, in parse_command_line. args = self._parse_command_opts(parser, args). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 1018, in _parse_command_opts. nargs = _Distribution._parse_command_opts(self, parser, args). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/distutils/dist.py"", line 523, in _parse_command_opts. cmd_class = self.get_command_class(command). File ""/mnt/d/github/jython/Lib/site-packages/setuptools/dist.py"", line 838, in get_command_class. self.cmdclass[command] = cmdclass = ep.load(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2434, in load. return self.resolve(). File ""/mnt/d/github/jython/Lib/site-packages/pkg_resources/__init__.py"", line 2440, in resolve. module = __import__(self.module_name, fromlist=['__name__'], level=0). File ""/mnt/d/github/jython/Lib/site-packages/wheel/bdist_wheel.py"", line 24, in <module>. from .pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag, get_platform. File ""/mnt/d/github/jython/Lib/site-packages/wheel/pep425tags.py"", line 10, in <module>. from .macosx_libfile import extract_macosx_min_system_version. File ""/mnt/d/github/jython/Lib/site-packages/wheel/macosx_libfile.py"", line 132, in <module>. segment_command_fields = [. AttributeError: 'module' object has no attribute 'c_char'. ----------------------------------------. ERROR: Failed building wheel for blis. Running setup.py clean for blis. Building wheel for wasabi (setup.py): started. Building wheel for wasabi (setup.py): finished with status 'error'. ERROR: Command errored ou",MatchSource.ISSUE_COMMENT,allenai,scispacy,v0.5.5,https://allenai.github.io/scispacy/,https://github.com/allenai/scispacy/issues/258
