id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/scverse/scanpy/issues/1168:29238,interoperability,format,format,29238,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29350,interoperability,format,format,29350,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29462,interoperability,format,format,29462,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29574,interoperability,format,format,29574,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29686,interoperability,format,format,29686,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29798,interoperability,format,format,29798,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:29910,interoperability,format,format,29910,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30022,interoperability,format,format,30022,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30134,interoperability,format,format,30134,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30246,interoperability,format,format,30246,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30358,interoperability,format,format,30358,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30470,interoperability,format,format,30470,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30582,interoperability,format,format,30582,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30694,interoperability,format,format,30694,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30806,interoperability,format,format,30806,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:30918,interoperability,format,format,30918,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31030,interoperability,format,format,31030,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31142,interoperability,format,format,31142,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31254,interoperability,format,format,31254,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31366,interoperability,format,format,31366,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31478,interoperability,format,format,31478,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31590,interoperability,format,format,31590,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31702,interoperability,format,format,31702,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31814,interoperability,format,format,31814,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31926,interoperability,format,format,31926,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32038,interoperability,format,format,32038,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32150,interoperability,format,format,32150,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32262,interoperability,format,format,32262,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32374,interoperability,format,format,32374,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32486,interoperability,format,format,32486,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32598,interoperability,format,format,32598,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32710,interoperability,format,format,32710,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32822,interoperability,format,format,32822,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:32934,interoperability,format,format,32934,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33046,interoperability,format,format,33046,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33158,interoperability,format,format,33158,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33270,interoperability,format,format,33270,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33382,interoperability,format,format,33382,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33494,interoperability,format,format,33494,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33606,interoperability,format,format,33606,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33718,interoperability,format,format,33718,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33830,interoperability,format,format,33830,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:33942,interoperability,format,format,33942,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34054,interoperability,format,format,34054,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34166,interoperability,format,format,34166,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34278,interoperability,format,format,34278,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34390,interoperability,format,format,34390,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34502,interoperability,format,format,34502,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34614,interoperability,format,format,34614,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34726,interoperability,format,format,34726,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34838,interoperability,format,format,34838,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:34950,interoperability,format,format,34950,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35062,interoperability,format,format,35062,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35174,interoperability,format,format,35174,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35286,interoperability,format,format,35286,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35398,interoperability,format,format,35398,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35510,interoperability,format,format,35510,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35622,interoperability,format,format,35622,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35734,interoperability,format,format,35734,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35846,interoperability,format,format,35846,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:35958,interoperability,format,format,35958,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36070,interoperability,format,format,36070,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36182,interoperability,format,format,36182,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36294,interoperability,format,format,36294,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36406,interoperability,format,format,36406,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36518,interoperability,format,format,36518,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36630,interoperability,format,format,36630,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36742,interoperability,format,format,36742,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36854,interoperability,format,format,36854,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:36966,interoperability,format,format,36966,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37078,interoperability,format,format,37078,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37190,interoperability,format,format,37190,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37302,interoperability,format,format,37302,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37414,interoperability,format,format,37414,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37526,interoperability,format,format,37526,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37638,interoperability,format,format,37638,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37750,interoperability,format,format,37750,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37862,interoperability,format,format,37862,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:37974,interoperability,format,format,37974,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38086,interoperability,format,format,38086,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38198,interoperability,format,format,38198,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38310,interoperability,format,format,38310,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38422,interoperability,format,format,38422,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38534,interoperability,format,format,38534,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38646,interoperability,format,format,38646,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38758,interoperability,format,format,38758,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38870,interoperability,format,format,38870,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:38982,interoperability,format,format,38982,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39094,interoperability,format,format,39094,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39206,interoperability,format,format,39206,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39318,interoperability,format,format,39318,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39430,interoperability,format,format,39430,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39542,interoperability,format,format,39542,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39654,interoperability,format,format,39654,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39766,interoperability,format,format,39766,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39878,interoperability,format,format,39878,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:39990,interoperability,format,format,39990,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40102,interoperability,format,format,40102,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40214,interoperability,format,format,40214,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40326,interoperability,format,format,40326,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40438,interoperability,format,format,40438,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40550,interoperability,format,format,40550,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40662,interoperability,format,format,40662,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40774,interoperability,format,format,40774,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40886,interoperability,format,format,40886,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:40998,interoperability,format,format,40998,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41110,interoperability,format,format,41110,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41222,interoperability,format,format,41222,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41334,interoperability,format,format,41334,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41446,interoperability,format,format,41446,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41558,interoperability,format,format,41558,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41670,interoperability,format,format,41670,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41782,interoperability,format,format,41782,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:41894,interoperability,format,format,41894,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42006,interoperability,format,format,42006,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42118,interoperability,format,format,42118,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42230,interoperability,format,format,42230,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42342,interoperability,format,format,42342,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42454,interoperability,format,format,42454,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42566,interoperability,format,format,42566,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42678,interoperability,format,format,42678,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42790,interoperability,format,format,42790,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:42902,interoperability,format,format,42902,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43014,interoperability,format,format,43014,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43126,interoperability,format,format,43126,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43238,interoperability,format,format,43238,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43350,interoperability,format,format,43350,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43462,interoperability,format,format,43462,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43574,interoperability,format,format,43574,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43686,interoperability,format,format,43686,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43798,interoperability,format,format,43798,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:43910,interoperability,format,format,43910,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44022,interoperability,format,format,44022,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44134,interoperability,format,format,44134,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44246,interoperability,format,format,44246,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44358,interoperability,format,format,44358,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44470,interoperability,format,format,44470,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44582,interoperability,format,format,44582,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44694,interoperability,format,format,44694,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44806,interoperability,format,format,44806,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:44918,interoperability,format,format,44918,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45030,interoperability,format,format,45030,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45142,interoperability,format,format,45142,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45254,interoperability,format,format,45254,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45366,interoperability,format,format,45366,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45478,interoperability,format,format,45478,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45590,interoperability,format,format,45590,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45702,interoperability,format,format,45702,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45814,interoperability,format,format,45814,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:45926,interoperability,format,format,45926,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46038,interoperability,format,format,46038,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46150,interoperability,format,format,46150,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46262,interoperability,format,format,46262,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46374,interoperability,format,format,46374,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46486,interoperability,format,format,46486,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46598,interoperability,format,format,46598,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46710,interoperability,format,format,46710,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46822,interoperability,format,format,46822,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:46934,interoperability,format,format,46934,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47046,interoperability,format,format,47046,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47158,interoperability,format,format,47158,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47270,interoperability,format,format,47270,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47382,interoperability,format,format,47382,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47494,interoperability,format,format,47494,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47606,interoperability,format,format,47606,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47718,interoperability,format,format,47718,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47830,interoperability,format,format,47830,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:47942,interoperability,format,format,47942,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48054,interoperability,format,format,48054,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48166,interoperability,format,format,48166,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48278,interoperability,format,format,48278,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48390,interoperability,format,format,48390,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48502,interoperability,format,format,48502,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48614,interoperability,format,format,48614,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48726,interoperability,format,format,48726,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48838,interoperability,format,format,48838,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:48950,interoperability,format,format,48950,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49062,interoperability,format,format,49062,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49174,interoperability,format,format,49174,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49286,interoperability,format,format,49286,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49398,interoperability,format,format,49398,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49510,interoperability,format,format,49510,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49622,interoperability,format,format,49622,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49734,interoperability,format,format,49734,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49846,interoperability,format,format,49846,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:49958,interoperability,format,format,49958,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50070,interoperability,format,format,50070,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50182,interoperability,format,format,50182,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50294,interoperability,format,format,50294,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50406,interoperability,format,format,50406,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50518,interoperability,format,format,50518,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50630,interoperability,format,format,50630,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50742,interoperability,format,format,50742,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50854,interoperability,format,format,50854,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:50966,interoperability,format,format,50966,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51078,interoperability,format,format,51078,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51190,interoperability,format,format,51190,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51302,interoperability,format,format,51302,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51414,interoperability,format,format,51414,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51526,interoperability,format,format,51526,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51638,interoperability,format,format,51638,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51750,interoperability,format,format,51750,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51862,interoperability,format,format,51862,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:51974,interoperability,format,format,51974,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52086,interoperability,format,format,52086,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52198,interoperability,format,format,52198,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52310,interoperability,format,format,52310,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52422,interoperability,format,format,52422,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52534,interoperability,format,format,52534,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52646,interoperability,format,format,52646,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52758,interoperability,format,format,52758,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52870,interoperability,format,format,52870,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:52982,interoperability,format,format,52982,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53094,interoperability,format,format,53094,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53206,interoperability,format,format,53206,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53318,interoperability,format,format,53318,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53430,interoperability,format,format,53430,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53542,interoperability,format,format,53542,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53654,interoperability,format,format,53654,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53766,interoperability,format,format,53766,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53878,interoperability,format,format,53878,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:53990,interoperability,format,format,53990,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54102,interoperability,format,format,54102,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54214,interoperability,format,format,54214,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54326,interoperability,format,format,54326,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54438,interoperability,format,format,54438,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54550,interoperability,format,format,54550,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54662,interoperability,format,format,54662,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54774,interoperability,format,format,54774,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54886,interoperability,format,format,54886,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:54998,interoperability,format,format,54998,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55110,interoperability,format,format,55110,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55222,interoperability,format,format,55222,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55334,interoperability,format,format,55334,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55446,interoperability,format,format,55446,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55558,interoperability,format,format,55558,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55670,interoperability,format,format,55670,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 0 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55782,interoperability,format,format,55782,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:55894,interoperability,format,format,55894,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56006,interoperability,format,format,56006,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56118,interoperability,format,format,56118,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56230,interoperability,format,format,56230,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56342,interoperability,format,format,56342,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56454,interoperability,format,format,56454,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56566,interoperability,format,format,56566,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56678,interoperability,format,format,56678,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56790,interoperability,format,format,56790,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:56902,interoperability,format,format,56902,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57014,interoperability,format,format,57014,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57126,interoperability,format,format,57126,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57238,interoperability,format,format,57238,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57350,interoperability,format,format,57350,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57462,interoperability,format,format,57462,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57574,interoperability,format,format,57574,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57686,interoperability,format,format,57686,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57798,interoperability,format,format,57798,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:57910,interoperability,format,format,57910,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58022,interoperability,format,format,58022,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58134,interoperability,format,format,58134,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58246,interoperability,format,format,58246,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58358,interoperability,format,format,58358,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58470,interoperability,format,format,58470,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58582,interoperability,format,format,58582,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58694,interoperability,format,format,58694,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58806,interoperability,format,format,58806,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:58918,interoperability,format,format,58918,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59030,interoperability,format,format,59030,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59142,interoperability,format,format,59142,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59254,interoperability,format,format,59254,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59366,interoperability,format,format,59366,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59478,interoperability,format,format,59478,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59590,interoperability,format,format,59590,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59702,interoperability,format,format,59702,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59814,interoperability,format,format,59814,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:59926,interoperability,format,format,59926,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60038,interoperability,format,format,60038,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60150,interoperability,format,format,60150,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60262,interoperability,format,format,60262,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60374,interoperability,format,format,60374,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60486,interoperability,format,format,60486,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60598,interoperability,format,format,60598,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60710,interoperability,format,format,60710,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60822,interoperability,format,format,60822,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:60934,interoperability,format,format,60934,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61046,interoperability,format,format,61046,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61158,interoperability,format,format,61158,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61270,interoperability,format,format,61270,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61382,interoperability,format,format,61382,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61494,interoperability,format,format,61494,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61606,interoperability,format,format,61606,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61718,interoperability,format,format,61718,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61830,interoperability,format,format,61830,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:61942,interoperability,format,format,61942,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62054,interoperability,format,format,62054,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62166,interoperability,format,format,62166,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62278,interoperability,format,format,62278,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62390,interoperability,format,format,62390,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62502,interoperability,format,format,62502,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62614,interoperability,format,format,62614,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62726,interoperability,format,format,62726,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62838,interoperability,format,format,62838,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:62950,interoperability,format,format,62950,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63062,interoperability,format,format,63062,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63174,interoperability,format,format,63174,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63286,interoperability,format,format,63286,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63398,interoperability,format,format,63398,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63510,interoperability,format,format,63510,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63622,interoperability,format,format,63622,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63734,interoperability,format,format,63734,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63846,interoperability,format,format,63846,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:63958,interoperability,format,format,63958,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64070,interoperability,format,format,64070,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64182,interoperability,format,format,64182,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64294,interoperability,format,format,64294,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64406,interoperability,format,format,64406,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64518,interoperability,format,format,64518,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64630,interoperability,format,format,64630,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64742,interoperability,format,format,64742,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64854,interoperability,format,format,64854,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:64966,interoperability,format,format,64966,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65078,interoperability,format,format,65078,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65190,interoperability,format,format,65190,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65302,interoperability,format,format,65302,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65414,interoperability,format,format,65414,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65526,interoperability,format,format,65526,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65638,interoperability,format,format,65638,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65750,interoperability,format,format,65750,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65862,interoperability,format,format,65862,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:65974,interoperability,format,format,65974,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66086,interoperability,format,format,66086,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66198,interoperability,format,format,66198,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66310,interoperability,format,format,66310,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66422,interoperability,format,format,66422,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66534,interoperability,format,format,66534,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66646,interoperability,format,format,66646,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66758,interoperability,format,format,66758,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66870,interoperability,format,format,66870,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:66982,interoperability,format,format,66982,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67094,interoperability,format,format,67094,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67206,interoperability,format,format,67206,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67318,interoperability,format,format,67318,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67430,interoperability,format,format,67430,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67542,interoperability,format,format,67542,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67654,interoperability,format,format,67654,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67766,interoperability,format,format,67766,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67878,interoperability,format,format,67878,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:67990,interoperability,format,format,67990,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68102,interoperability,format,format,68102,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68214,interoperability,format,format,68214,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68326,interoperability,format,format,68326,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68438,interoperability,format,format,68438,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68550,interoperability,format,format,68550,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68662,interoperability,format,format,68662,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68774,interoperability,format,format,68774,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68886,interoperability,format,format,68886,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:68998,interoperability,format,format,68998,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69110,interoperability,format,format,69110,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69222,interoperability,format,format,69222,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69334,interoperability,format,format,69334,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69446,interoperability,format,format,69446,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69558,interoperability,format,format,69558,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69670,interoperability,format,format,69670,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69782,interoperability,format,format,69782,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:69894,interoperability,format,format,69894,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70006,interoperability,format,format,70006,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70118,interoperability,format,format,70118,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70230,interoperability,format,format,70230,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70342,interoperability,format,format,70342,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70454,interoperability,format,format,70454,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70566,interoperability,format,format,70566,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70678,interoperability,format,format,70678,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70790,interoperability,format,format,70790,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:70902,interoperability,format,format,70902,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71014,interoperability,format,format,71014,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71126,interoperability,format,format,71126,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71238,interoperability,format,format,71238,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71350,interoperability,format,format,71350,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71462,interoperability,format,format,71462,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71574,interoperability,format,format,71574,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71686,interoperability,format,format,71686,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71798,interoperability,format,format,71798,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:71910,interoperability,format,format,71910,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72022,interoperability,format,format,72022,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72134,interoperability,format,format,72134,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72246,interoperability,format,format,72246,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72358,interoperability,format,format,72358,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72470,interoperability,format,format,72470,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72582,interoperability,format,format,72582,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72694,interoperability,format,format,72694,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72806,interoperability,format,format,72806,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:72918,interoperability,format,format,72918,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73030,interoperability,format,format,73030,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73142,interoperability,format,format,73142,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73254,interoperability,format,format,73254,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73366,interoperability,format,format,73366,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73478,interoperability,format,format,73478,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73590,interoperability,format,format,73590,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73702,interoperability,format,format,73702,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73814,interoperability,format,format,73814,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:73926,interoperability,format,format,73926,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74038,interoperability,format,format,74038,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74150,interoperability,format,format,74150,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74262,interoperability,format,format,74262,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74374,interoperability,format,format,74374,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74486,interoperability,format,format,74486,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74598,interoperability,format,format,74598,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74710,interoperability,format,format,74710,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74822,interoperability,format,format,74822,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:74934,interoperability,format,format,74934,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75046,interoperability,format,format,75046,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75158,interoperability,format,format,75158,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75270,interoperability,format,format,75270,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75382,interoperability,format,format,75382,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75494,interoperability,format,format,75494,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75606,interoperability,format,format,75606,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75718,interoperability,format,format,75718,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75830,interoperability,format,format,75830,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:75942,interoperability,format,format,75942,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76054,interoperability,format,format,76054,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76166,interoperability,format,format,76166,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76278,interoperability,format,format,76278,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76390,interoperability,format,format,76390,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76502,interoperability,format,format,76502,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76614,interoperability,format,format,76614,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76726,interoperability,format,format,76726,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76838,interoperability,format,format,76838,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:76950,interoperability,format,format,76950,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77062,interoperability,format,format,77062,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77174,interoperability,format,format,77174,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77286,interoperability,format,format,77286,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77398,interoperability,format,format,77398,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77510,interoperability,format,format,77510,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77622,interoperability,format,format,77622,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77734,interoperability,format,format,77734,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77846,interoperability,format,format,77846,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:77958,interoperability,format,format,77958,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78070,interoperability,format,format,78070,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c8",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78182,interoperability,format,format,78182,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78294,interoperability,format,format,78294,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\e",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78406,interoperability,format,format,78406,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotatio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78518,interoperability,format,format,78518,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78630,interoperability,format,format,78630,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_t",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78742,interoperability,format,format,78742,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78854,interoperability,format,format,78854,"x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanp",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79210,interoperability,format,format,79210,"type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=fl",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79087,modifiability,modul,module,79087," matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79318,modifiability,pac,packages,79318,"of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79843,modifiability,pac,packages,79843,"se Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnume",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:80072,modifiability,pac,packages,80072,"8e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. ValueError: setting ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:80375,modifiability,pac,packages,80375,"=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:80580,modifiability,pac,packages,80580,"=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:80819,modifiability,pac,packages,80819,"=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79060,safety,input,input-,79060,"se Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79087,safety,modul,module,79087," matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_u",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:80897,safety,except,except,80897,"=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[:-n]. 378 return ret[n - 1:] / n. <__array_function__ internals> in cumsum(*args, **kwargs). ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in cumsum(a, axis, dtype, out). 2421 . 2422 """""". -> 2423 return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out). 2424 . 2425 . ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapfunc(obj, method, *args, **kwds). 56 bound = getattr(obj, method, None). 57 if bound is None:. ---> 58 return _wrapit(obj, method, *args, **kwds). 59 . 60 try:. ~\Miniconda3\envs\project\lib\site-packages\numpy\core\fromnumeric.py in _wrapit(obj, method, *args, **kwds). 45 except AttributeError:. 46 wrap = None. ---> 47 result = getattr(asarray(obj), method)(*args, **kwds). 48 if wrap:. 49 if not isinstance(result, mu.ndarray):. ValueError: setting an array element with a sequence. ```. </details>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:78897,testability,trace,traceback,78897,"32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79016,testability,Trace,Traceback,79016,"	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax i",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79060,usability,input,input-,79060,"se Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79176,usability,User,Users,79176,"ow format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". -",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:79244,usability,User,Users,79244,"ith 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>, <1x1 sparse matrix of type '<class 'numpy.float32'>'. 	with 1 stored elements in Compressed Sparse Row format>]. </details>. <details>. <summary> traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-41-14c81f38e281> in <module>. 18 return_data=True,. 19 show=True,. ---> 20 use_raw=False). 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in paga_path(adata, nodes, keys, use_raw, annotations, color_map, color_maps_annotations, palette_groups, n_avg, groups_key, xlim, title, left_margin, ytick_fontsize, title_fontsize, show_node_names, show_yticks, show_colorbar, legend_fontsize, legend_fontweight, normalize_to_zero_one, as_heatmap, return_data, show, save, ax). 1038 old_len_x = len(x). 1039 print(x). -> 1040 x = moving_average(x). 1041 if ikey == 0:. 1042 for key in annotations:. ~\Miniconda3\envs\project\lib\site-packages\scanpy\plotting\_tools\paga.py in moving_average(a). 980 . 981 def moving_average(a):. --> 982 return _sc_utils.moving_average(a, n_avg). 983 . 984 ax = pl.gca() if ax is None else ax. ~\Miniconda3\envs\project\lib\site-packages\scanpy\_utils.py in moving_average(a, n). 374 An array view storing the moving average. 375 """""". --> 376 ret = np.cumsum(a, dtype=float). 377 ret[n:] = ret[n:] - ret[",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:99,availability,error,error,99,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:273,deployability,modul,module,273,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:512,energy efficiency,core,core,512,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:374,interoperability,format,format,374,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:785,interoperability,format,formatter,785,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:894,interoperability,format,formats,894,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:273,modifiability,modul,module,273,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:496,modifiability,pac,packages,496,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:875,modifiability,pac,packages,875,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:1069,modifiability,pac,packages,1069,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:99,performance,error,error,99,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:99,safety,error,error,99,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:246,safety,input,input-,246,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:273,safety,modul,module,273,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:202,testability,Trace,Traceback,202,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:99,usability,error,error,99,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:246,usability,input,input-,246,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:340,usability,User,Users,340,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:408,usability,User,Users,408,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:1020,usability,close,close,1020,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:1386,usability,User,Users,1386,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:1437,usability,user,user-images,1437,"@HypoChloremic,. I did but it comes out with weird PAGA pathway analysis plot (shown blow) and new error:. ---------------------------------------------------------------------------. FileNotFoundError Traceback (most recent call last). <ipython-input-46-42a11a5bd10f> in <module>. 19 show=True,. 20 use_raw=False). ---> 21 data.to_csv(""C:/Users/Lin/write/paga_path_{}.csv"".format(descr)). 22 pl.savefig(""C:/Users/Lin/figures/paga_path_KTC.pdf""). 23 pl.show(). ~\Miniconda3\envs\project\lib\site-packages\pandas\core\generic.py in to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal). 3226 decimal=decimal,. 3227 ). -> 3228 formatter.save(). 3229 . 3230 if path_or_buf is None:. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\formats\csvs.py in save(self). 181 self.mode,. 182 encoding=self.encoding,. --> 183 compression=self.compression,. 184 ). 185 close = True. ~\Miniconda3\envs\project\lib\site-packages\pandas\io\common.py in _get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text). 397 if encoding:. 398 # Encoding. --> 399 f = open(path_or_buf, mode, encoding=encoding, newline=""""). 400 elif is_text:. 401 # No explicit encoding. FileNotFoundError: [Errno 2] No such file or directory: 'C:/Users/Lin/write/paga_path_DC/LC.csv'. [](https://user-images.githubusercontent.com/57272642/80230003-47818480-861f-11ea-96ce-db1128b4a6eb.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:111,availability,error,errors,111,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:111,performance,error,errors,111,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:111,safety,error,errors,111,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:111,usability,error,errors,111,"@rsggsr remove the `data.to_csv()` part, it seems to have worked otherwise, if the ``tl.paga_path` ran without errors",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31,availability,error,error,31,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31,performance,error,error,31,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31,safety,error,error,31,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:31,usability,error,error,31,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:122,usability,user,user-images,122,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:235,usability,user,user-images,235,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1168:348,usability,user,user-images,348,@HypoChloremic . Right now the error is gone but still got three weird PAGA pathay graphs shown below:. ![ (1)](https://user-images.githubusercontent.com/57272642/80285540-c1833d80-86f3-11ea-9a35-4fdf7385eaab.png). ![ (2)](https://user-images.githubusercontent.com/57272642/80285541-c47e2e00-86f3-11ea-9b10-1427ccfc978e.png). ![ (3)](https://user-images.githubusercontent.com/57272642/80285543-c7791e80-86f3-11ea-8c66-9ec7226de7c6.png).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1168
https://github.com/scverse/scanpy/issues/1169:37,deployability,releas,release,37,I would like to do this for the next release series.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1169:21,deployability,stage,staged-recipes,21,Fixed in conda-forge/staged-recipes#15083,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1169
https://github.com/scverse/scanpy/issues/1170:210,usability,minim,minimal-bug-reports,210,Not sure what could cause this without a bit more info. Could you make an example that reproduces this bug that I could run on my machine? Something like [this](https://mrocklin.github.com/blog/work/2018/02/28/minimal-bug-reports).,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:103,usability,minim,minimal-bug-reports,103,"> [](https://mrocklin.github.com/blog/work/2018/02/28/minimal-bug-reports). sorry, I cannot open the URL https://mrocklin.github.com/blog/work/2018/02/28/minimal-bug-reports. Can I send a tiny data and my code to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:204,usability,minim,minimal-bug-reports,204,"> [](https://mrocklin.github.com/blog/work/2018/02/28/minimal-bug-reports). sorry, I cannot open the URL https://mrocklin.github.com/blog/work/2018/02/28/minimal-bug-reports. Can I send a tiny data and my code to you?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:157,availability,replic,replicates,157,"The best thing to do would just be to put a link to the data here, and paste the code. It's actually easier to debug the more you can simplify the data that replicates the bug. Ideally, you could just send code that generates the data to replicate the bug. If that isn't working out, you could send me a DM on the discourse forum?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:238,availability,replic,replicate,238,"The best thing to do would just be to put a link to the data here, and paste the code. It's actually easier to debug the more you can simplify the data that replicates the bug. Ideally, you could just send code that generates the data to replicate the bug. If that isn't working out, you could send me a DM on the discourse forum?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:134,testability,simpl,simplify,134,"The best thing to do would just be to put a link to the data here, and paste the code. It's actually easier to debug the more you can simplify the data that replicates the bug. Ideally, you could just send code that generates the data to replicate the bug. If that isn't working out, you could send me a DM on the discourse forum?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:134,usability,simpl,simplify,134,"The best thing to do would just be to put a link to the data here, and paste the code. It's actually easier to debug the more you can simplify the data that replicates the bug. Ideally, you could just send code that generates the data to replicate the bug. If that isn't working out, you could send me a DM on the discourse forum?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:45,availability,error,error,45,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:433,availability,error,error,433,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:295,integrability,batch,batch,295,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:309,interoperability,specif,specified,309,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:45,performance,error,error,45,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:295,performance,batch,batch,295,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:433,performance,error,error,433,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:45,safety,error,error,45,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:433,safety,error,error,433,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:524,testability,trace,trace,524,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:45,usability,error,error,45,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:433,usability,error,error,433,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:590,usability,help,helps,590,"@Zifeng1995, @ivirshup . I received the same error caused by wrong shape of ""numer"" in line 268 in _combat.py. . In my case, I could resolved this problem by generating unique cell names ( i.e. adata.obs_names) as following. . **Workaround** . Before combat execution, in concatenate process of batch data, I specified index_unique='-' . . e.g.) adata1.concatenate(adata2, adata3, ..., index_unique='-'). When index_unique=None, the error was occurred. However index_unique='-' was fine in my case. I'm afraid that couldn't trace root cause of this problem due to busy day, but I hope this helps you. . Sincerely. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:517,deployability,modul,module,517,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1159,deployability,observ,observation,1159,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1126,energy efficiency,current,currently,1126,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:226,integrability,batch,batch,226,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:292,integrability,batch,batch,292,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:547,integrability,batch,batch,547,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:623,integrability,batch,batch,623,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:517,modifiability,modul,module,517,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:226,performance,batch,batch,226,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:292,performance,batch,batch,292,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:547,performance,batch,batch,547,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:623,performance,batch,batch,623,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1136,reliability,doe,does,1136,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:490,safety,input,input-,490,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:517,safety,modul,module,517,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:327,testability,Trace,Traceback,327,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:446,testability,Trace,Traceback,446,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:1159,testability,observ,observation,1159,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:28,usability,help,helpful,28,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1170:490,usability,input,input-,490,"Thanks @rika-N! That's very helpful in figuring this out. I can now reproduce this with:. ```python. import scanpy as sc. import numpy as np. import pandas as pd. a = sc.AnnData(. np.random.random((5, 5)),. obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). ). sc.pp.combat(a, ""batch""). ```. <details>. <summary> Traceback </summary>. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-16-e35e04bc067c> in <module>. 7 obs=pd.DataFrame({""batch"": list(""aaabb"")}, index=list(""11234"")). 8 ). ----> 9 sc.pp.combat(a, ""batch""). ~/github/scanpy/scanpy/preprocessing/_combat.py in combat(adata, key, covariates, inplace). 266 denom = np.dot(dsq, np.ones((1, n_batches[j]))). 267 numer = np.array(bayesdata[batch_idxs] - np.dot(batch_design.loc[batch_idxs], gamma_star).T). --> 268 bayesdata[batch_idxs] = numer / denom. 269 . 270 vpsq = np.sqrt(var_pooled).reshape((len(var_pooled), 1)). ValueError: operands could not be broadcast together with shapes (5,5) (5,3) . ```. </details>. The issue is that the `combat` function currently does not work when the observation names are not unique.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1170
https://github.com/scverse/scanpy/issues/1172:127,energy efficiency,model,model,127,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:94,integrability,coupl,couple,94,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:176,integrability,batch,batch,176,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:205,integrability,batch,batches,205,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:94,modifiability,coupl,couple,94,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:176,performance,batch,batch,176,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:205,performance,batch,batches,205,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:127,security,model,model,127,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:94,testability,coupl,couple,94,It might have sth to do with this line:. >Found 3 genes with zero variance. Maybe there are a couple of genes where the combat model can't be fit due to having 0 variance in a batch or 0 mean across a few batches? Could you check where the NaN values are in your `adata.X` post combat?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:616,energy efficiency,model,model,616,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:486,integrability,Standardiz,Standardizing,486,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:528,integrability,batch,batches,528,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:486,interoperability,Standard,Standardizing,486,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:555,modifiability,variab,variables,555,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:650,modifiability,paramet,parametric,650,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:744,modifiability,pac,packages,744,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:988,modifiability,pac,packages,988,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:528,performance,batch,batches,528,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:616,security,model,model,616,"In theory Combat knows how to take care of zero variance genes according to the. [code](https://github.com/theislab/scanpy/blob/4156314407c5368fa0b66ac18470d80f3748a71f/scanpy/preprocessing/_combat.py#L124). Well, post-Combat apparently NaNs are everywhere:. ```. np.sum(np.isnan(adata_Combat.X)). Out[2]: 8089368. np.sum(~np.isnan(adata_Combat.X)). Out[3]: 0. ```. This is really weird if only 3 genes have zero variance, right? Could it have anything to do with this warnings?:. ```. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Found 3 genes with zero variance. Fitting L/S model and finding priors. Finding parametric adjustments. Adjusting data. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: invalid value encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:249,availability,error,error,249,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:570,availability,avail,available,570,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:538,deployability,version,version,538,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:761,deployability,modul,module,761,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:785,deployability,version,version,785,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:821,deployability,version,version,821,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:906,deployability,version,version,906,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1857,deployability,modul,module,1857,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:481,energy efficiency,core,core,481,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:620,energy efficiency,core,core,620,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1253,energy efficiency,model,model,1253,"hen trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2373,energy efficiency,core,core,2373,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2514,energy efficiency,core,core,2514,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:75,integrability,sub,subset,75,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:538,integrability,version,version,538,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:551,integrability,pub,public,551,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:785,integrability,version,version,785,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:821,integrability,version,version,821,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:906,integrability,version,version,906,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1157,integrability,Standardiz,Standardizing,1157," and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1199,integrability,batch,batches,1199,"ne but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1157,interoperability,Standard,Standardizing,1157," and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preproces",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:421,modifiability,pac,packages,421,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:538,modifiability,version,version,538,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:704,modifiability,pac,packages,704,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:761,modifiability,modul,module,761,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:785,modifiability,version,version,785,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:821,modifiability,version,version,821,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:906,modifiability,version,version,906,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1226,modifiability,variab,variables,1226,"ame NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1287,modifiability,paramet,parametric,1287,"riable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bi",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1365,modifiability,pac,packages,1365,"ome/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pan",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1754,modifiability,variab,variable,1754,"he module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, n",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1857,modifiability,modul,module,1857,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1969,modifiability,pac,packages,1969,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2139,modifiability,pac,packages,2139,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2357,modifiability,pac,packages,2357,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:2498,modifiability,pac,packages,2498,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:249,performance,error,error,249,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1199,performance,batch,batches,1199,"ne but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 6",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:570,reliability,availab,available,570,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:249,safety,error,error,249,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:570,safety,avail,available,570,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:761,safety,modul,module,761,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1821,safety,input,input-,1821,"sion 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1857,safety,modul,module,1857,"n 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwarg.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:570,security,availab,available,570,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1253,security,model,model,1253,"hen trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_b",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1770,testability,Trace,Traceback,1770,"ecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can dro",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:249,usability,error,error,249,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:854,usability,support,support,854,"OK, I got rid of a few genes that were not expressed in the dataset (its a subset of cells from the full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1095,usability,learn,learn,1095,"e full dataset) with ```sc.pp.filter_genes(adata, min_counts=1)``` and now the zero variance genes are gone but still same warning, same NaNs and same error when trying to run ```sc.pp.highly_variable_genes()```:. ```. In [1]: sc.pp.combat(adata_Combat, key='sample'). /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/anndata/_core/anndata.py:21: FutureWarning: pandas.core.index is deprecated and will be removed in a future version. The public classes are available in the top-level namespace. from pandas.core.index import RangeIndex. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:1821,usability,input,input-,1821,"sion 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/). ""(https://pypi.org/project/six/)."", FutureWarning). scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. Standardizing Data across genes. Found 11 batches. Found 0 numerical variables:. 	. Fitting L/S model and finding priors. Finding parametric adjustments. /home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_combat.py:338: RuntimeWarning: divide by zero encountered in true_divide. change = max((abs(g_new - g_old) / g_old).max(), (abs(d_new - d_old) / d_old).max()). Adjusting data. In [2]: np.sum(~np.isnan(adata_Combat.X)). Out[2]: 0. In [3]: np.sum(np.isnan(adata_Combat.X)). Out[3]: 7644442. In [4]: sc.pp.highly_variable_genes(adata_Combat). extracting highly variable genes. Traceback (most recent call last):. File ""<ipython-input-4-a706aaf6f1f8>"", line 1, in <module>. sc.pp.highly_variable_genes(adata_Combat). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 235, in highly_variable_genes. flavor=flavor,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/scanpy/preprocessing/_highly_variable_genes.py"", line 65, in _highly_variable_genes_single_batch. df['mean_bin'] = pd.cut(df['means'], bins=n_bins). File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 265, in cut. duplicates=duplicates,. File ""/home/auesro/anaconda3/envs/Scanpy/lib/python3.7/site-packages/pandas/core/reshape/tile.py"", line 381, in _bins_to_cuts. f""Bin edges must be unique: {repr(bins)}.\n"". ValueError: Bin edges must be unique: array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,. nan, nan, nan, nan, nan, nan, nan, nan]). You can drop duplicate edges by setting the 'duplicates' kwa",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:197,usability,minim,minimal,197,It's hard to say what's going on here. There seems to be sth happening in `sc.pp.combat()` so I would evaluate this separately from `sc.pp.highly_variable_genes()`. It would be important to have a minimal reproducible example it seems.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:277,availability,Escal,Escalante,277,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:466,availability,error,error,466,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:352,integrability,Sub,Subject,352,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:466,performance,error,error,466,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:302,safety,hot,hotmail,302,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:466,safety,error,error,466,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:277,security,Escal,Escalante,277,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:316,security,Auth,Author,316,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:324,security,auth,author,324,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:751,security,auth,authored,751,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:952,security,auth,auth,952,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:466,usability,error,error,466,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:674,usability,minim,minimal,674,"It's only 538 cells, so it's a small file, I can send it to you, if you want to have a look. ________________________________. From: MalteDLuecken <notifications@github.com>. Sent: Monday, April 20, 2020 2:42:07 PM. To: theislab/scanpy <scanpy@noreply.github.com>. Cc: Augusto Escalante <ae_rodriguez_@hotmail.com>; Author <author@noreply.github.com>. Subject: Re: [theislab/scanpy] Combat populates adata.X with NANs so sc.pp.highly_variable_genes function outputs error (#1172). It's hard to say what's going on here. There seems to be sth happening in sc.pp.combat() so I would evaluate this separately from sc.pp.highly_variable_genes(). It would be important to have a minimal reproducible example it seems. . You are receiving this because you authored the thread. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1172#issuecomment-616527285>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AFZKH4VCL573RRAU55AHS23RNQ7J7ANCNFSM4ML4AVXA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:175,integrability,batch,batches,175,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:199,integrability,batch,batches,199,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:235,integrability,filter,filtering,235,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:249,integrability,sub,subsetting,249,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:175,performance,batch,batches,175,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:199,performance,batch,batches,199,"Ok, I think I fixed it. Maybe it is mentioned somewhere or implicitly understood (sorry I am too new to this) but Combat will not do well if the number of cells in one of the batches is 1. One of my batches mantained only 1 cell after filtering and subsetting, removing this one sample from the analysis solved the Combat problem: no NaNs, so that highly_variable_genes could worked as expected.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:94,integrability,batch,batches,94,I think it's a nice corner case we should handle. Can you file another bug about having 1cell batches in combat or highly_variable_genes with batch_key option?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:94,performance,batch,batches,94,I think it's a nice corner case we should handle. Can you file another bug about having 1cell batches in combat or highly_variable_genes with batch_key option?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:173,integrability,batch,batch,173,"@LuckyMD of course your are right... @gokceneraslan sure, I can, it would be nice just to get a warning or have Combat halt the processing on first checking that there is a batch with just 1 cell.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1172:173,performance,batch,batch,173,"@LuckyMD of course your are right... @gokceneraslan sure, I can, it would be nice just to get a warning or have Combat halt the processing on first checking that there is a batch with just 1 cell.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1172
https://github.com/scverse/scanpy/issues/1176:5,safety,except,except,5,"Yes, except for `conn_key`. the right path is. ```. conn_key = adata.uns[neighbor_key]['connectivities_key']. adata.obsp[conn_key]. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:27,deployability,patch,patch,27,"Excellent, thank you. I'll patch my code accordingly. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:27,safety,patch,patch,27,"Excellent, thank you. I'll patch my code accordingly. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1176:27,security,patch,patch,27,"Excellent, thank you. I'll patch my code accordingly. .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1176
https://github.com/scverse/scanpy/issues/1177:32,usability,workflow,workflows,32,I recall looking at some ScanPy workflows and @davidsebfischer pointed out that many of them rely on Sparse data types. Is that still the case ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:34,usability,workflow,workflows,34,"> I recall looking at some ScanPy workflows and @davidsebfischer pointed out that many of them rely on Sparse data types. Is that still the case ? yes, this still is the case",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:324,energy efficiency,Current,Currently,324,"@quasiben @davidsebfischer. I've been working on using RAPIDS/CuPy to implement a Seurat / Scanpy single-cell RNA workflow. Specifically, I've been finding it quite challenging do w/ CuPy sparse arrays because of the following two issues:. https://github.com/cupy/cupy/issues/2360. https://github.com/cupy/cupy/issues/3178. Currently, I'm having to convert to `scipy.sparse` to implement filtering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:388,integrability,filter,filtering,388,"@quasiben @davidsebfischer. I've been working on using RAPIDS/CuPy to implement a Seurat / Scanpy single-cell RNA workflow. Specifically, I've been finding it quite challenging do w/ CuPy sparse arrays because of the following two issues:. https://github.com/cupy/cupy/issues/2360. https://github.com/cupy/cupy/issues/3178. Currently, I'm having to convert to `scipy.sparse` to implement filtering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:124,interoperability,Specif,Specifically,124,"@quasiben @davidsebfischer. I've been working on using RAPIDS/CuPy to implement a Seurat / Scanpy single-cell RNA workflow. Specifically, I've been finding it quite challenging do w/ CuPy sparse arrays because of the following two issues:. https://github.com/cupy/cupy/issues/2360. https://github.com/cupy/cupy/issues/3178. Currently, I'm having to convert to `scipy.sparse` to implement filtering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:114,usability,workflow,workflow,114,"@quasiben @davidsebfischer. I've been working on using RAPIDS/CuPy to implement a Seurat / Scanpy single-cell RNA workflow. Specifically, I've been finding it quite challenging do w/ CuPy sparse arrays because of the following two issues:. https://github.com/cupy/cupy/issues/2360. https://github.com/cupy/cupy/issues/3178. Currently, I'm having to convert to `scipy.sparse` to implement filtering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:73,usability,support,support,73,Do you know how hard it would be to add cuSparse to CuPy for more sparse support ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:88,availability,operat,operations,88,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:129,availability,sli,slicing,129,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:596,deployability,API,API,596,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:61,energy efficiency,current,currently,61,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:427,energy efficiency,alloc,allocated,427,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:455,energy efficiency,schedul,scheduled,455,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:596,integrability,API,API,596,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:596,interoperability,API,API,596,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:600,interoperability,compatib,compatibility,600,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:455,performance,schedul,scheduled,455,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:498,performance,parallel,parallel,498,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:632,performance,perform,performance,632,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:129,reliability,sli,slicing,129,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:155,usability,support,supported,155,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:632,usability,perform,performance,632,"@quasiben As far as I know Cusparse is being used under Cupy currently for a lot of the operations. Im not quite sure why those slicing strategies arent supported yet. I just figured maybe they were less trivial than the others and werent immediately needed so they were pushed off to future feature requests. . The issue #2360 I cant imagine is too hard- I imagine the output array the size of the selection list could be allocated and a Cuda kernel scheduled to write the selected entries in parallel. Im not as sure about the other issue, but what Dask is trying to do seems more like an API compatibility issue than one of performance/compute.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:46,availability,sli,slicing,46,What features in cuSPARSE would be useful for slicing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:46,reliability,sli,slicing,46,What features in cuSPARSE would be useful for slicing?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:31,availability,sli,slicing,31,"@jakirkham, Im not sure about slicing. @quasiben s question seems to imply the use of cusparse in cupy for general sparse operations. Please correct me if I misunderstood. I believe once the two issues above are resolved, much of the scipy.sparse functionality for the preprocessing in Scanpy should be able to be swapped with cupy.sparse. . The ML stuff is a little but different, and Ive created a separate issue to track that discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:124,availability,operat,operations,124,"@jakirkham, Im not sure about slicing. @quasiben s question seems to imply the use of cusparse in cupy for general sparse operations. Please correct me if I misunderstood. I believe once the two issues above are resolved, much of the scipy.sparse functionality for the preprocessing in Scanpy should be able to be swapped with cupy.sparse. . The ML stuff is a little but different, and Ive created a separate issue to track that discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:31,reliability,sli,slicing,31,"@jakirkham, Im not sure about slicing. @quasiben s question seems to imply the use of cusparse in cupy for general sparse operations. Please correct me if I misunderstood. I believe once the two issues above are resolved, much of the scipy.sparse functionality for the preprocessing in Scanpy should be able to be swapped with cupy.sparse. . The ML stuff is a little but different, and Ive created a separate issue to track that discussion.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:289,availability,avail,available,289,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:354,availability,operat,operations,354,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1643,availability,operat,operate,1643,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:416,deployability,deploy,deploys,416,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:541,deployability,build,build,541,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:583,deployability,deploy,deployed,583,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:951,deployability,build,build,951,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:957,deployability,pipelin,pipelines,957,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1246,deployability,contain,contains,1246,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:221,energy efficiency,GPU,GPU,221,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:325,energy efficiency,GPU,GPU,325,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:391,energy efficiency,CPU,CPU,391,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:444,energy efficiency,GPU,GPU,444,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:559,energy efficiency,CPU,CPU,559,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:607,energy efficiency,GPU,GPU,607,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:640,energy efficiency,estimat,estimation,640,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1005,energy efficiency,GPU,GPU,1005,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1488,energy efficiency,core,core,1488,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1544,energy efficiency,GPU,GPU-based,1544,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1658,energy efficiency,GPU,GPU,1658,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:206,integrability,translat,translation,206,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:452,integrability,batch,batchglm,452,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:500,integrability,batch,batchglm,500,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:957,integrability,pipelin,pipelines,957,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1207,integrability,sub,submodule,1207,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:206,interoperability,translat,translation,206,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:676,modifiability,pac,package,676,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:33,performance,bottleneck,bottleneck,33,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:186,performance,bottleneck,bottlenecks,186,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:221,performance,GPU,GPU,221,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:325,performance,GPU,GPU,325,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:342,performance,perform,perform,342,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:391,performance,CPU,CPU,391,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:444,performance,GPU,GPU,444,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:452,performance,batch,batchglm,452,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:500,performance,batch,batchglm,500,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:559,performance,CPU,CPU,559,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:607,performance,GPU,GPU,607,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:820,performance,time,time,820,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:943,performance,time,time,943,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1005,performance,GPU,GPU,1005,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1110,performance,time,time,1110,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1270,performance,bottleneck,bottlenecks,1270,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1440,performance,perform,performance,1440,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1544,performance,GPU,GPU-based,1544,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1658,performance,GPU,GPU,1658,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:289,reliability,availab,available,289,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1329,reliability,doe,doesnt,1329,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:289,safety,avail,available,289,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:22,security,ident,identified,22,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:289,security,availab,available,289,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1612,security,modif,modify,1612,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:138,usability,workflow,workflows,138,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:166,usability,clear,clear,166,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:342,usability,perform,perform,342,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1041,usability,tool,tools,1041,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1082,usability,tool,tool,1082,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1125,usability,workflow,workflows,1125,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1440,usability,perform,performance,1440,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1625,usability,tool,tools,1625,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1732,usability,clear,clear,1732,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1800,usability,document,documenting,1800,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/issues/1177:1849,usability,help,help,1849,"I think our initially identified bottleneck with using sparse arrays was this here https://github.com/cupy/cupy/issues/2359. The analysis workflows usually have very clear computational bottlenecks, so the translation to GPU should take this into consideration: Is it feasible in terms of available code to keep the array on GPU and actually perform all operations there or will this stay a CPU centric library that deploys particular steps to GPU. In[batchglm / diffxpy](https://github.com/theislab/batchglm) we took the first approach, we build ontop of (a CPU centric scanpy and) deployed GLM fitting to GPU via tensorflow2, we also use estimation code in dask in the same package that we could in principle use with cupy, right now this just sits ontop of numpy. . Happy to be involved with this stuff, I spent some time thinking about this with @quasiben already. I think it is really crucial to figure out where it makes sense to invest time to build pipelines that can be end-to-end be executed on GPU: because of the large number of tools this will not be the entire scanpy tool environment for a long time, so mixed workflows will be necessary. . 1. I would for example restrict all efforts to the submodule `sc.tl` for now because this contains most potential bottlenecks I think that are frequently used. ""end-to-end"" doesnt need to go all the way up to analysis graph leaves, such as plotting, in my opinion, as their is little performance gain there. 2. Nice to have for non-core functionalities would then be some examples of how GPU-based arrays can be used within anndata so that 3rd parties can modify their tools to directly operate on the GPU array rather then starting to copy arrays. I think this is not really clear for most people right now (I have never done that either) and documenting this properly / improving this would help a lot.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1177
https://github.com/scverse/scanpy/pull/1179:85,deployability,fail,fails,85,"@ivirshup @flying-sheep . Hi, do you know how to find out why `docs/readthedocs.com` fails?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1179
https://github.com/scverse/scanpy/pull/1179:85,reliability,fail,fails,85,"@ivirshup @flying-sheep . Hi, do you know how to find out why `docs/readthedocs.com` fails?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1179
https://github.com/scverse/scanpy/pull/1179:22,deployability,build,build,22,Not sure. Do the docs build fine for you locally?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1179
https://github.com/scverse/scanpy/pull/1179:20,deployability,build,build,20,"@ivirshup yes, they build fine but there are a lot of warnings of the form `""WARNING: py:class reference target not found: scanpy._compat.Literal_""`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1179
https://github.com/scverse/scanpy/pull/1180:34,usability,close,closed,34,Was there an issue that should be closed by this?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1180
https://github.com/scverse/scanpy/issues/1181:122,deployability,instal,install,122,"Hi, @plrlhb12 . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:197,deployability,releas,release,197,"Hi, @plrlhb12 . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:284,availability,error,error,284,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:92,deployability,version,version,92,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:114,deployability,instal,installing,114,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:133,deployability,version,version,133,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:168,deployability,version,versions,168,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:345,deployability,version,version,345,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:926,deployability,instal,install,926,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1001,deployability,releas,release,1001,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:92,integrability,version,version,92,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:133,integrability,version,version,133,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:168,integrability,version,versions,168,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:290,integrability,messag,messages,290,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:345,integrability,version,version,345,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:290,interoperability,messag,messages,290,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:315,interoperability,compatib,compatible,315,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:92,modifiability,version,version,92,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:133,modifiability,version,version,133,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:168,modifiability,version,versions,168,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:302,modifiability,pac,packages,302,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:345,modifiability,version,version,345,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:284,performance,error,error,284,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:284,safety,error,error,284,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:670,safety,hot,hotmail,670,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:1244,security,auth,auth,1244,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:284,usability,error,error,284,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:405,usability,help,help,405,"Hi Sergei,. Thank you very much for your fast reply. Do you mean I can still use the latest version of scanpy but installing a lower version of umap? I tried different versions of scanpy, including pastiest, stable, 1.4.5, 1.4.5post3, 1.4.4post1... They seem to either have different error messages or packages not compatible. Do you know which version of the scanpy has it fixed? Thank you for your kind help. Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:569,deployability,instal,install,569,"It works now by changing umap to 0.3.9. Thanks a lot! Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:644,deployability,releas,release,644,"It works now by changing umap to 0.3.9. Thanks a lot! Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:313,safety,hot,hotmail,313,"It works now by changing umap to 0.3.9. Thanks a lot! Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/issues/1181:887,security,auth,auth,887,"It works now by changing umap to 0.3.9. Thanks a lot! Best regards,. Lirong.  Outlook for iOS<https://aka.ms/o0ukef>. ________________________________. : Sergei R. <notifications@github.com>. : Wednesday, April 22, 2020 12:44:36 PM. : theislab/scanpy <scanpy@noreply.github.com>. : plrlhb12 <lrpeng@hotmail.com>; Mention <mention@noreply.github.com>. : Re: [theislab/scanpy] Issue with ingest (#1181). Hi, @plrlhb12<https://github.com/plrlhb12> . Yes, this is a known problem. The easiest fix for now is to use umap 0.3.9 instead of 0.4.1. You can also install scanpy from github where it is fixed or just wait for a new scanpy release. . You are receiving this because you were mentioned. Reply to this email directly, view it on GitHub<https://github.com/theislab/scanpy/issues/1181#issuecomment-617895856>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKHCBZKH4TYT5672QNGFW33RN4NHJANCNFSM4MNX44PA>.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1181
https://github.com/scverse/scanpy/pull/1182:157,integrability,pub,publication,157,"Thanks for the review. I will add the other requested changes/additions soon. So also the way I interpreted the way they clip values based on the Stuart '19 publication is different than what it appears they do in their code, which I linked in the overleaf doc in the docstring. My original interpretation is the first code in the linked issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:15,safety,review,review,15,"Thanks for the review. I will add the other requested changes/additions soon. So also the way I interpreted the way they clip values based on the Stuart '19 publication is different than what it appears they do in their code, which I linked in the overleaf doc in the docstring. My original interpretation is the first code in the linked issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:15,testability,review,review,15,"Thanks for the review. I will add the other requested changes/additions soon. So also the way I interpreted the way they clip values based on the Stuart '19 publication is different than what it appears they do in their code, which I linked in the overleaf doc in the docstring. My original interpretation is the first code in the linked issue.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:131,availability,slo,slow,131,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:432,availability,slo,slow,432,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:131,reliability,slo,slow,131,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:432,reliability,slo,slow,432,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:20,usability,custom,custom,20,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:86,usability,close,closer,86,"@ivirshup I added a custom implementation of loess, which uses a degree 2 polynomial (closer to seurat implementation). It's a bit slow, I'm sure it can be sped up with numba, but it's having a problem with this line:. https://github.com/adamgayoso/scanpy/blob/b48d5729a075bc6f7fa0bbbf38a856d4c2e720ba/scanpy/preprocessing/_highly_variable_genes.py#L607. Any idea why? Edit: I got it to work by not using clip, but it's still a bit slow. Please let me know if you have any ideas! Edit 2: I found a stable python implementation of degree 2 loess",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:34,deployability,fail,failing,34,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:34,reliability,fail,failing,34,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:26,safety,test,test,26,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:26,testability,test,test,26,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:54,usability,interact,interactively,54,I'm also not sure why the test is failing -- it works interactively locally for me.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:85,availability,error,error,85,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:41,performance,cach,cached,41,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:85,performance,error,error,85,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:229,reliability,doe,does,229,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:85,safety,error,error,85,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:172,safety,review,review,172,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:172,testability,review,review,172,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:184,testability,understand,understand,184,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:85,usability,error,error,85,"@ivirshup is it possible that Travis has cached pbmc3k and that's what's causing the error? I really don't have it running pytest locally either. . Also as far as the code review -- I understand code is duplicated, but this code does not really fit in the existing implementation because it works a bit differently and requires raw data. Let me know how you'd like to address this. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:59,safety,test,tests,59,This got a bit messy -- travis is defeating me because the tests work locally. I'm going to close this and figure it out on my fork and make a new PR with a clean history.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:59,testability,test,tests,59,This got a bit messy -- travis is defeating me because the tests work locally. I'm going to close this and figure it out on my fork and make a new PR with a clean history.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:92,usability,close,close,92,This got a bit messy -- travis is defeating me because the tests work locally. I'm going to close this and figure it out on my fork and make a new PR with a clean history.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:22,usability,feedback,feedback,22,Sorry for the lack of feedback! I got caught up in my own work. * Have you made any progress on the travis issue? * Is it an issue of getting different results from computing variance?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:84,usability,progress,progress,84,Sorry for the lack of feedback! I got caught up in my own work. * Have you made any progress on the travis issue? * Is it an issue of getting different results from computing variance?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:84,availability,error,error,84,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1605,availability,error,error,1605,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:280,deployability,modul,module,280,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1071,energy efficiency,model,model,1071,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1121,energy efficiency,model,model,1121,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1162,energy efficiency,model,model,1162,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:701,integrability,sub,subset,701,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1016,integrability,sub,subset,1016,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1611,integrability,messag,message,1611,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1611,interoperability,messag,message,1611,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:280,modifiability,modul,module,280,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:371,modifiability,layer,layer,371,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:531,modifiability,pac,packages,531,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:619,modifiability,layer,layer,619,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:833,modifiability,layer,layer,833,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:839,modifiability,layer,layer,839,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:880,modifiability,pac,packages,880,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:979,modifiability,layer,layer,979,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:84,performance,error,error,84,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1605,performance,error,error,1605,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:84,safety,error,error,84,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:252,safety,input,input-,252,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:280,safety,modul,module,280,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1605,safety,error,error,1605,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1071,security,model,model,1071,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1121,security,model,model,1121,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1162,security,model,model,1162,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:208,testability,Trace,Traceback,208,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:84,usability,error,error,84,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:252,usability,input,input-,252,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1605,usability,error,error,1605,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/pull/1182:1627,usability,user,users,1627,"Hey @adamgayoso ,. I really love this HVG method, but sometimes I get the following error from the loess fit:. ```pytb. ---------------------------------------------------------------------------. ValueError Traceback (most recent call last). <ipython-input-244-764977f87ce6> in <module>. ----> 1 sc.pp.highly_variable_genes(ad_sub, n_top_genes=1500, flavor='seurat_v3', layer='counts'). 2 sc.pp.pca(ad_sub). 3 sc.pp.neighbors(ad_sub). 4 sc.tl.umap(ad_sub). 5 sc.tl.leiden(ad_sub, resolution=2.0). ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in highly_variable_genes(adata, layer, n_top_genes, min_disp, max_disp, min_mean, max_mean, span, n_bins, flavor, subset, inplace, batch_key). 413 . 414 if flavor == 'seurat_v3':. --> 415 return _highly_variable_genes_seurat_v3(. 416 adata,. 417 layer=layer,. ~/.miniconda3/lib/python3.8/site-packages/scanpy/preprocessing/_highly_variable_genes.py in _highly_variable_genes_seurat_v3(adata, layer, n_top_genes, batch_key, span, subset, inplace). 82 x = np.log10(mean[not_const]). 83 model = loess(x, y, span=span, degree=2). ---> 84 model.fit(). 85 estimat_var[not_const] = model.outputs.fitted_values. 86 reg_std = np.sqrt(10 ** estimat_var). _loess.pyx in _loess.loess.fit(). ValueError: b'reciprocal condition number 7.4971e-16\n'. ```. This is due to the very low but non-zero variance genes, I think. It goes away when I run `sc.pp.filter_genes(ad_sub, min_cells=5)` but not when I run only `sc.pp.filter_genes(ad_sub, min_cells=1)`. Maybe we can make the variance check more stringent, or we can print a better error message for the users?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1182
https://github.com/scverse/scanpy/issues/1183:21,availability,error,error,21,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]. https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt. [ipynb]. https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:21,performance,error,error,21,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]. https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt. [ipynb]. https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:21,safety,error,error,21,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]. https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt. [ipynb]. https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:21,usability,error,error,21,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]. https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt. [ipynb]. https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:199,usability,learn,learn,199,"I encounter the same error as well when i tried sc.pp.normalize_total(adata, target_sum=5e4). . Environment:. scanpy==1.4.6 anndata==0.7.1 umap==0.4.1 numpy==1.18.1 scipy==1.4.1 pandas==1.0.3 scikit-learn==0.22.2.post1 statsmodels==0.11.1 python-igraph==0.8.0. [conda list]. https://github.com/phamidko/codesnippets/blob/master/scanpy-conda-list.txt. [ipynb]. https://github.com/phamidko/codesnippets/blob/master/Tissue-Tcell-activation.ipynb.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:52,availability,down,downgrading,52,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:87,availability,error,error,87,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:87,performance,error,error,87,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:87,safety,error,error,87,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:633,security,auth,auth,633,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:87,usability,error,error,87,"Hi Issac,. Thank you for looking into this. I tried downgrading to python 3.7 but the. error still persists. Best,. Philip. On Tue, Apr 28, 2020 at 12:16 AM Isaac Virshup <notifications@github.com>. wrote:. > @phamidko <https://github.com/phamidko>, could you export that conda. > environment with conda list --export? I'd like to see if I can recreate. > with your environment. >. > . > You are receiving this because you were mentioned. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1183#issuecomment-620426227>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AJ7QRZ6CCZW74XVYGDEPRFDROZ7CRANCNFSM4MRFHJHQ>. > . >. <envlist moved to next post by @ivirshup>",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4504,availability,error,error,4504,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5082,availability,error,error,5082,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5135,availability,error,error,5135,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:907,deployability,version,version,907,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:1743,deployability,api,api-wrap,1743,0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4886,deployability,instal,install,4886,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:907,integrability,version,version,907,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:1743,integrability,api,api-wrap,1743,0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:375,interoperability,platform,platform,375,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:1743,interoperability,api,api-wrap,1743,0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2882,interoperability,stub,stubs,2882,gfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:762,modifiability,deco,decorator,762,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:907,modifiability,version,version,907,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2517,modifiability,pac,packaging,2517,.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-s,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2382,performance,network,networkx,2382,contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4504,performance,error,error,4504,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5082,performance,error,error,5082,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5135,performance,error,error,5135,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:3685,safety,test,testpath,3685,"37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4504,safety,error,error,4504,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4930,safety,test,tested,4930,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5082,safety,error,error,5082,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5135,safety,error,error,5135,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:15,security,modif,modified,15,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:545,security,certif,certificates,545,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:609,security,certif,certifi,609,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:705,security,cryptograph,cryptography,705,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2382,security,network,networkx,2382,contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. sc,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2882,testability,stub,stubs,2882,gfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:3685,testability,test,testpath,3685,"37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4930,testability,test,tested,4930,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:184,usability,support,support,184,"@phamidko I've modified your comment, and placed the output in the collapsed section below so I don't have to scroll so much on this issue. Unfortunately replies sent from email don't support markdown :(. <details>. <summary> phamidko's environment </summary>. ```. # This file may be used to create an environment using:. # $ conda create --name <env> --file <this file>. # platform: linux-64. _libgcc_mutex=0.1=main. anndata=0.7.1=pypi_0. attrs=19.3.0=py_0. backcall=0.1.0=py_0. bleach=3.1.4=pyh9f0ad1d_0. brotlipy=0.7.0=py37h8f50634_1000. ca-certificates=2020.4.5.1=hecc5488_0. cairo=1.16.0=hcf35c78_1003. certifi=2020.4.5.1=py37hc8dfbb8_0. cffi=1.14.0=py37hd463f26_0. chardet=3.0.4=py37hc8dfbb8_1006. cryptography=2.9.2=py37hb09aad4_0. cycler=0.10.0=pypi_0. decorator=4.4.2=py_0. defusedxml=0.6.0=py_0. entrypoints=0.3=py37hc8dfbb8_1001. fontconfig=2.13.1=h86ecdb6_1001. freetype=2.10.1=he06d7ca_0. get-version=2.1=pypi_0. gettext=0.19.8.1=hc5be6a0_1002. glib=2.64.2=h6f030ca_0. gmp=6.2.0=he1b5a44_2. h5py=2.10.0=pypi_0. icu=64.2=he1b5a44_1. idna=2.9=py_1. importlib-metadata=1.6.0=py37hc8dfbb8_0. importlib_metadata=1.6.0=0. ipykernel=5.2.1=py37h43977f1_0. ipython=7.13.0=py37hc8dfbb8_2. ipython_genutils=0.2.0=py_1. jedi=0.17.0=py37hc8dfbb8_0. jinja2=2.11.2=pyh9f0ad1d_0. joblib=0.14.1=pypi_0. json5=0.9.0=py_0. jsonschema=3.2.0=py37hc8dfbb8_1. jupyter_client=6.1.3=py_0. jupyter_contrib_core=0.3.3=py_2. jupyter_contrib_nbextensions=0.5.1=py37_0. jupyter_core=4.6.3=py37hc8dfbb8_1. jupyter_highlight_selected_word=0.2.0=py37_1000. jupyter_latex_envs=1.4.6=py37_1000. jupyter_nbextensions_configurator=0.4.1=py37_0. jupyterlab=2.1.1=py_0. jupyterlab_server=1.1.1=py_0. kiwisolver=1.2.0=pypi_0. ld_impl_linux-64=2.33.1=h53a641e_7. legacy-api-wrap=1.2=pypi_0. leidenalg=0.8.0=py37h43df1e8_0. libedit=3.1.20181209=hc058e9b_0. libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:2825,usability,tool,toolkit,2825,libffi=3.2.1=hd88cf55_4. libgcc-ng=9.1.0=hdf63c60_0. libgfortran-ng=7.3.0=hdf63c60_5. libiconv=1.15=h516909a_1006. libpng=1.6.37=hed695b0_1. libsodium=1.0.17=h516909a_0. libstdcxx-ng=9.1.0=hdf63c60_0. libuuid=2.32.1=h14c3975_1000. libxcb=1.13=h14c3975_1002. libxml2=2.9.10=hee79883_0. libxslt=1.1.33=h31b3aaa_0. llvmlite=0.32.0=pypi_0. lxml=4.5.0=py37he3881c9_1. markupsafe=1.1.1=py37h8f50634_1. matplotlib=3.2.1=pypi_0. mistune=0.8.4=py37h8f50634_1001. natsort=7.0.1=pypi_0. nbconvert=5.6.1=py37hc8dfbb8_1. nbformat=5.0.6=py_0. ncurses=6.2=he6710b0_0. networkx=2.4=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:3391,usability,learn,learn,3391,=pypi_0. notebook=6.0.3=py37_0. numba=0.49.0=pypi_0. numexpr=2.7.1=pypi_0. numpy=1.18.3=pypi_0. openssl=1.1.1g=h516909a_0. packaging=20.3=pypi_0. pandas=1.0.3=pypi_0. pandoc=2.9.2.1=0. pandocfilters=1.4.2=py_1. parso=0.7.0=pyh9f0ad1d_0. patsy=0.5.1=pypi_0. pcre=8.44=he1b5a44_0. pexpect=4.8.0=py37hc8dfbb8_1. pickleshare=0.7.5=py37hc8dfbb8_1001. pip=20.0.2=py37_1. pixman=0.38.0=h516909a_1003. prometheus_client=0.7.1=py_0. prompt-toolkit=3.0.5=py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:3836,usability,learn,learn,3836,"py_0. psutil=5.7.0=py37h8f50634_1. pthread-stubs=0.4=h14c3975_1001. ptyprocess=0.6.0=py_1001. pycairo=1.19.1=py37h01af8b0_3. pycparser=2.20=py_0. pygments=2.6.1=py_0. pyopenssl=19.1.0=py_1. pyparsing=2.4.7=pypi_0. pyrsistent=0.16.0=py37h8f50634_0. pysocks=1.7.1=py37hc8dfbb8_1. python=3.7.7=hcf32534_0_cpython. python-dateutil=2.8.1=py_0. python-igraph=0.8.1=pypi_0. python_abi=3.7=1_cp37m. pytz=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:4504,usability,error,error,4504,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5082,usability,error,error,5082,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:5135,usability,error,error,5135,"z=2019.3=pypi_0. pyyaml=5.3.1=py37h8f50634_0. pyzmq=19.0.0=py37hac76be4_1. readline=8.0=h7b6447c_0. requests=2.23.0=pyh8c360ce_2. scanpy=1.4.6=pypi_0. scikit-learn=0.22.2.post1=pypi_0. scipy=1.4.1=pypi_0. seaborn=0.10.1=pypi_0. send2trash=1.5.0=py_0. setuptools=46.1.3=py37_0. setuptools-scm=3.5.0=pypi_0. six=1.14.0=py_1. sqlite=3.31.1=h62c20be_1. statsmodels=0.11.1=pypi_0. tables=3.6.1=pypi_0. tbb=2020.0.133=pypi_0. terminado=0.8.3=py37hc8dfbb8_1. testpath=0.4.4=py_0. texttable=1.6.2=py_0. tk=8.6.8=hbc83047_0. tornado=6.0.4=py37h8f50634_1. tqdm=4.45.0=pypi_0. traitlets=4.3.3=py37hc8dfbb8_1. umap-learn=0.4.1=pypi_0. urllib3=1.25.9=py_0. wcwidth=0.1.9=pyh9f0ad1d_0. webencodings=0.5.1=py_1. wheel=0.34.2=py37_0. xorg-kbproto=1.0.7=h14c3975_1002. xorg-libice=1.0.10=h516909a_0. xorg-libsm=1.2.3=h84519dc_1000. xorg-libx11=1.6.9=h516909a_0. xorg-libxau=1.0.9=h14c3975_0. xorg-libxdmcp=1.1.3=h516909a_0. xorg-libxext=1.3.4=h516909a_0. xorg-libxrender=0.9.10=h516909a_1002. xorg-renderproto=0.11.1=h14c3975_1002. xorg-xextproto=7.3.0=h14c3975_1002. xorg-xproto=7.0.31=h14c3975_1007. xz=5.2.5=h7b6447c_0. yaml=0.2.4=h516909a_0. zeromq=4.3.2=he1b5a44_2. zipp=3.1.0=py_0. zlib=1.2.11=h7b6447c_3. ```. </details>. I've recreated your environment, but cannot reproduce this error. Here's how I created the environment:. ```bash. # Where the output you pasted above is in scanpy_1183_env.txt. $ grep -v pypi_0 scanpy_1183_env.txt > scanpy_1183_env_nopip.txt. $ grep pypi_0 scanpy_1183_env.txt | sed 's/=pypi_0//' | sed 's/=/==/' > scanpy_1183_pip.txt. $ conda create -y --name scanpy1183 --file scanpy_1183_env_nopip.txt. $ conda activate scanpy1183. $ pip install -r scanpy_1183_pip.txt. ```. Then I tested this using:. ```python. import scanpy as sc. adata = sc.datasets.pbmc3k(). sc.pp.normalize_total(adata, target_sum=1e4). ```. But did not get an error. ~Could you send a snippet that reproduces the error for you?~ Oops, forgot that you already did this in the notebook. Taking a look at that now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:21,availability,replic,replicate,21,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:41,availability,error,error,41,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:262,availability,replic,replicate,262,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:277,availability,error,error,277,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:215,deployability,Updat,Update,215,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:41,performance,error,error,41,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:277,performance,error,error,277,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:320,reliability,doe,doesn,320,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:41,safety,error,error,41,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:215,safety,Updat,Update,215,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:277,safety,error,error,277,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:215,security,Updat,Update,215,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:41,usability,error,error,41,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/issues/1183:277,usability,error,error,277,"Hmm. I'm not able to replicate the exact error, but I get a different one. Could you try running:. ```python. adata = adata.copy(). ```. right before `normalize_total` and see if that works? ----------------------. Update: tried on a different machine and could replicate your error. The issue is that `normalize_total` doesn't make sure the anndata object isn't a view before assigning to it. As a work-around, you can just run `adata = adata.copy()` before `sc.pp.normalize_total(adata)`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1183
https://github.com/scverse/scanpy/pull/1186:118,security,access,accessible,118,We'll see . I'm hoping I might be able to help out with other things along these things which would make Scanpy more accessible for R users and hopefully expand the user base.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:43,usability,help,help,43,We'll see . I'm hoping I might be able to help out with other things along these things which would make Scanpy more accessible for R users and hopefully expand the user base.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:135,usability,user,users,135,We'll see . I'm hoping I might be able to help out with other things along these things which would make Scanpy more accessible for R users and hopefully expand the user base.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/pull/1186:166,usability,user,user,166,We'll see . I'm hoping I might be able to help out with other things along these things which would make Scanpy more accessible for R users and hopefully expand the user base.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1186
https://github.com/scverse/scanpy/issues/1187:52,integrability,topic,topic,52,Please check out this issue report here on the same topic: #313,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:160,performance,time,time,160,"Yes, I noticed #313 but missed #1009. #313 seems to be related to the score_genes_cell_cycle function and seems to be fixed by setting the random seed ahead of time (at least for some people). #1009 also doesn't seem to be related to the random seed but it seems that they ruled out PCA as the source of their discrepancy whereas mine seems to stem from the discrepant PCA. Should I merge this issue with one of those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:204,reliability,doe,doesn,204,"Yes, I noticed #313 but missed #1009. #313 seems to be related to the score_genes_cell_cycle function and seems to be fixed by setting the random seed ahead of time (at least for some people). #1009 also doesn't seem to be related to the random seed but it seems that they ruled out PCA as the source of their discrepancy whereas mine seems to stem from the discrepant PCA. Should I merge this issue with one of those?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:213,deployability,continu,continue,213,"That issue report mentions setting the `PYTHONHASHSEED` environment variable to `0` (next to all the seed setting) worked to create a fully reproducible workflow. If that doesn't work for you, it might be good to continue the discussion there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:68,modifiability,variab,variable,68,"That issue report mentions setting the `PYTHONHASHSEED` environment variable to `0` (next to all the seed setting) worked to create a fully reproducible workflow. If that doesn't work for you, it might be good to continue the discussion there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:171,reliability,doe,doesn,171,"That issue report mentions setting the `PYTHONHASHSEED` environment variable to `0` (next to all the seed setting) worked to create a fully reproducible workflow. If that doesn't work for you, it might be good to continue the discussion there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:153,usability,workflow,workflow,153,"That issue report mentions setting the `PYTHONHASHSEED` environment variable to `0` (next to all the seed setting) worked to create a fully reproducible workflow. If that doesn't work for you, it might be good to continue the discussion there.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1160,availability,echo,echo,1160," as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences betw",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2074,availability,echo,echo,2074,"ighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:255,deployability,pipelin,pipeline,255,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:683,deployability,scale,scale,683,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1595,deployability,scale,scale,1595,"malize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:305,energy efficiency,CPU,CPUs,305,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:683,energy efficiency,scale,scale,683,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1217,energy efficiency,CPU,CPUs,1217,"ble was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1595,energy efficiency,scale,scale,1595,"malize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2127,energy efficiency,CPU,CPUs,2127,"t8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_sta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2681,energy efficiency,CPU,CPUs,2681,"NHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:255,integrability,pipelin,pipeline,255,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:58,modifiability,variab,variable,58,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:214,modifiability,variab,variable,214,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:683,modifiability,scal,scale,683,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1595,modifiability,scal,scale,1595,"malize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:305,performance,CPU,CPUs,305,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:493,performance,cach,cache,493,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:683,performance,scale,scale,683,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1217,performance,CPU,CPUs,1217,"ble was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1405,performance,cach,cache,1405,"ead_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['co",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:1595,performance,scale,scale,1595,"malize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2127,performance,CPU,CPUs,2127,"t8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_sta",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2681,performance,CPU,CPUs,2681,"NHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Running on a machine with 16 CPUs, evaluate the differences between the results first from the arpack solver. adata8 = sc.read('test8.h5ad'). adata16 = sc.read('test16.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). # Running on a machine with 16 CPUs, evaluate the differences between the results first from the randomized solver. adata8 = sc.read('test8_randomized.h5ad'). adata16 = sc.read('test16_randomized.h5ad'). print((adata8.X != adata16.X).sum()). print((adata8.obsm['X_pca'] != adata16.obsm['X_pca']).sum()). print((adata8.uns['neighbors']['connectivities'] != adata16.uns['neighbors']['connectivities']).sum()). sc.tl.leiden(adata8, random_state=14). sc.tl.leiden(adata16, random_state=14). display(adata8.obs['leiden'].value_counts()). display(adata16.obs['leiden'].value_counts()). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:2,usability,confirm,confirmed,2,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:179,usability,confirm,confirming,179,"I confirmed that setting the PYTHONHASHSEED environmental variable to 0 did not change the results. The code run below (in jupyter notebook) gave the same results as before while confirming that the PYTHONHASHSEED variable was set to 0 before running the pipeline. ```. # First run on a machine on with 8 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test8_randomized.h5ad', adata). ! echo $PYTHONHASHSEED. # Then run on a machine on with 16 CPUs. %env PYTHONHASHSEED=0. import numpy as np. import pandas as pd. import scanpy as sc. adata = sc.read_10x_mtx(. './data/filtered_gene_bc_matrices/hg19/', . var_names='gene_symbols',. cache=True) . sc.pp.filter_cells(adata, min_genes=200). sc.pp.filter_genes(adata, min_cells=3). sc.pp.normalize_total(adata, target_sum=1e4). sc.pp.log1p(adata). adata = adata.copy(). sc.pp.scale(adata, max_value=10). sc.pp.highly_variable_genes(adata, min_mean=0.0125, max_mean=3, min_disp=0.5). adata = adata[:, adata.var.highly_variable]. sc.tl.pca(adata, svd_solver='arpack', random_state=14). sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40, random_state=14). sc.write('test16.h5ad', adata). sc.tl.pca(adata, svd_solver='randomized', random_state=14). sc.pp.neighbors(adata, n_neighbors=10,",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:165,availability,operat,operating,165,"That is interesting... do you know where the randomness is coming in? I think `sc.pp.highly_variable_genes()` can have some variability. These two VMs have the same operating system and hardware otherwise, right? I've had reproducibility issues moving between Fedora 25 and 28. In the end the libraries we use rely on underlying kernel numerics. There's a limit to how reproducible one can be. This only really becomes an issue if the biological interpretation is no longer consistent. Of course we'd like to be reproducible before then as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:474,availability,consist,consistent,474,"That is interesting... do you know where the randomness is coming in? I think `sc.pp.highly_variable_genes()` can have some variability. These two VMs have the same operating system and hardware otherwise, right? I've had reproducibility issues moving between Fedora 25 and 28. In the end the libraries we use rely on underlying kernel numerics. There's a limit to how reproducible one can be. This only really becomes an issue if the biological interpretation is no longer consistent. Of course we'd like to be reproducible before then as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:124,modifiability,variab,variability,124,"That is interesting... do you know where the randomness is coming in? I think `sc.pp.highly_variable_genes()` can have some variability. These two VMs have the same operating system and hardware otherwise, right? I've had reproducibility issues moving between Fedora 25 and 28. In the end the libraries we use rely on underlying kernel numerics. There's a limit to how reproducible one can be. This only really becomes an issue if the biological interpretation is no longer consistent. Of course we'd like to be reproducible before then as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:474,usability,consist,consistent,474,"That is interesting... do you know where the randomness is coming in? I think `sc.pp.highly_variable_genes()` can have some variability. These two VMs have the same operating system and hardware otherwise, right? I've had reproducibility issues moving between Fedora 25 and 28. In the end the libraries we use rely on underlying kernel numerics. There's a limit to how reproducible one can be. This only really becomes an issue if the biological interpretation is no longer consistent. Of course we'd like to be reproducible before then as well.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:128,availability,sli,slightly,128,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:255,availability,cluster,clusterings,255,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:255,deployability,cluster,clusterings,255,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:307,deployability,automat,automate,307,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:356,deployability,pipelin,pipeline,356,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:271,integrability,sub,subtly,271,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:356,integrability,pipelin,pipeline,356,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:391,interoperability,platform,platforms,391,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:29,modifiability,variab,variable,29,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:128,reliability,sli,slightly,128,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:307,testability,automat,automate,307,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:502,usability,learn,learn,502,"I am getting the same highly variable genes between the two runs. The discrepancy is introduced at the PCA step which generates slightly different results between the two runs. The biological interpretation ends up essentially the same in my case but the clusterings are subtly different, making it hard to automate my annotation. I would like the overall pipeline to be reproducible across platforms if possible. I can dig a bit into the PCA code... it seems like this might be an issue on the scikit-learn end.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:51,deployability,contain,container,51,"I recall that this issue occurred even in a docker container, so I'm not sure we can perfectly automate this. I'd love to know if you find out how this could be addressed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:95,deployability,automat,automate,95,"I recall that this issue occurred even in a docker container, so I'm not sure we can perfectly automate this. I'd love to know if you find out how this could be addressed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:95,testability,automat,automate,95,"I recall that this issue occurred even in a docker container, so I'm not sure we can perfectly automate this. I'd love to know if you find out how this could be addressed.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:65,deployability,contain,container,65,"Right, I think it makes sense that this would happen in a docker container based on what I'm seeing. I'll let you know if I find a solution!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:99,energy efficiency,CPU,CPUs,99,"@dylkot, a few questions:. * How different are your environments? Do they only differ in number of CPUs? Or are the OSs or BLAS libraries different? * Have you tried limiting the number of CPUs used by arpack?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:189,energy efficiency,CPU,CPUs,189,"@dylkot, a few questions:. * How different are your environments? Do they only differ in number of CPUs? Or are the OSs or BLAS libraries different? * Have you tried limiting the number of CPUs used by arpack?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:99,performance,CPU,CPUs,99,"@dylkot, a few questions:. * How different are your environments? Do they only differ in number of CPUs? Or are the OSs or BLAS libraries different? * Have you tried limiting the number of CPUs used by arpack?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:189,performance,CPU,CPUs,189,"@dylkot, a few questions:. * How different are your environments? Do they only differ in number of CPUs? Or are the OSs or BLAS libraries different? * Have you tried limiting the number of CPUs used by arpack?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:110,energy efficiency,load,loading,110,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:184,energy efficiency,CPU,CPUs,184,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:208,energy efficiency,CPU,CPUs,208,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:283,energy efficiency,CPU,CPUs,283,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:43,performance,disk,disks,43,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:110,performance,load,loading,110,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:184,performance,CPU,CPUs,184,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:208,performance,CPU,CPUs,208,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:283,performance,CPU,CPUs,283,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:52,security,ident,identical,52,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:363,usability,tip,tip,363,I am actually booting using the exact same disks so identical OS (Ubuntu 16.04) and BLAS libraries. I am just loading them up with different virtual machines with different numbers of CPUs. In both cases the CPUs are Intel Xeon E5 v3 (Haswell). Have not tried limiting the number of CPUs used by arpack. I didn't know that was something I could do! Do you have a tip on how to do so? I'll look this up and give it a shot.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:34,energy efficiency,CPU,CPUs,34,"IIRC, you can limit the number of CPUs used through blas. This works on my machine:. ```. export OMP_NUM_THREADS=1. ```. Different blas libraries use different environment variables for this, so I'd check to make sure it's actually restricting the number of threads used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:172,modifiability,variab,variables,172,"IIRC, you can limit the number of CPUs used through blas. This works on my machine:. ```. export OMP_NUM_THREADS=1. ```. Different blas libraries use different environment variables for this, so I'd check to make sure it's actually restricting the number of threads used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/issues/1187:34,performance,CPU,CPUs,34,"IIRC, you can limit the number of CPUs used through blas. This works on my machine:. ```. export OMP_NUM_THREADS=1. ```. Different blas libraries use different environment variables for this, so I'd check to make sure it's actually restricting the number of threads used.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1187
https://github.com/scverse/scanpy/pull/1188:73,integrability,sub,subset,73,"Thought about it a bit more. I'm pretty sure we've dropped the ""modify a subset of a backed dataset"" use-case since most other functions won't respect that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1188
https://github.com/scverse/scanpy/pull/1188:64,security,modif,modify,64,"Thought about it a bit more. I'm pretty sure we've dropped the ""modify a subset of a backed dataset"" use-case since most other functions won't respect that.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1188
https://github.com/scverse/scanpy/issues/1189:242,energy efficiency,current,currently,242,"Why not store whatever you have in `adata.uns` that you want to colour by in `adata.obs`? `adata.obs` is designed specifically to store univariate data with dimensions of `(n_obs,1)`. As colouring can also only work with univariate values, I currently don't really understand the need for this. Could you elaborate why this is needed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:114,interoperability,specif,specifically,114,"Why not store whatever you have in `adata.uns` that you want to colour by in `adata.obs`? `adata.obs` is designed specifically to store univariate data with dimensions of `(n_obs,1)`. As colouring can also only work with univariate values, I currently don't really understand the need for this. Could you elaborate why this is needed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:265,testability,understand,understand,265,"Why not store whatever you have in `adata.uns` that you want to colour by in `adata.obs`? `adata.obs` is designed specifically to store univariate data with dimensions of `(n_obs,1)`. As colouring can also only work with univariate values, I currently don't really understand the need for this. Could you elaborate why this is needed?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:224,deployability,modul,modules,224,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:20,energy efficiency,current,currently,20,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:100,modifiability,variab,variables,100,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:224,modifiability,modul,modules,224,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:224,safety,modul,modules,224,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:57,usability,aesthet,aesthetics,57,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:131,usability,custom,custom,131,"Yes, that is what I currently do. It is just a matter of aesthetics. Since I have a large number of variables that I generate with custom functions, I wanted to store them separately based on what they represent in separate modules under (`adata.uns`). . Adding everything to `adata.obs` quickly gets cluttered. No worries just wanted to see if it was an option. Thank you.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:140,safety,test,tests,140,"I think `adata.obsm` could make sense, but `adata.uns` would maybe be a bit too messy given the unstructured nature and the assumptions and tests that would have to be added.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:140,testability,test,tests,140,"I think `adata.obsm` could make sense, but `adata.uns` would maybe be a bit too messy given the unstructured nature and the assumptions and tests that would have to be added.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:63,modifiability,layer,layers,63,"Yeah, that makes absolute sense. . Even better would be to add layers similar to `adata.X` and pass that into any function. Something like `adata.obs_custom`. In which case `adata.obs_custom` will inherit the same properties as that of `adata.obs` and users can make as many as they need in an organized manner. It will also allow users to store different values with the same column name (of course in different layers). e.g. `adata.obs_custom['same_column_name']` and `adata.obs_custom2['same_column_name']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:197,modifiability,inherit,inherit,197,"Yeah, that makes absolute sense. . Even better would be to add layers similar to `adata.X` and pass that into any function. Something like `adata.obs_custom`. In which case `adata.obs_custom` will inherit the same properties as that of `adata.obs` and users can make as many as they need in an organized manner. It will also allow users to store different values with the same column name (of course in different layers). e.g. `adata.obs_custom['same_column_name']` and `adata.obs_custom2['same_column_name']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:413,modifiability,layer,layers,413,"Yeah, that makes absolute sense. . Even better would be to add layers similar to `adata.X` and pass that into any function. Something like `adata.obs_custom`. In which case `adata.obs_custom` will inherit the same properties as that of `adata.obs` and users can make as many as they need in an organized manner. It will also allow users to store different values with the same column name (of course in different layers). e.g. `adata.obs_custom['same_column_name']` and `adata.obs_custom2['same_column_name']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:252,usability,user,users,252,"Yeah, that makes absolute sense. . Even better would be to add layers similar to `adata.X` and pass that into any function. Something like `adata.obs_custom`. In which case `adata.obs_custom` will inherit the same properties as that of `adata.obs` and users can make as many as they need in an organized manner. It will also allow users to store different values with the same column name (of course in different layers). e.g. `adata.obs_custom['same_column_name']` and `adata.obs_custom2['same_column_name']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:331,usability,user,users,331,"Yeah, that makes absolute sense. . Even better would be to add layers similar to `adata.X` and pass that into any function. Something like `adata.obs_custom`. In which case `adata.obs_custom` will inherit the same properties as that of `adata.obs` and users can make as many as they need in an organized manner. It will also allow users to store different values with the same column name (of course in different layers). e.g. `adata.obs_custom['same_column_name']` and `adata.obs_custom2['same_column_name']`",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1189:74,testability,plan,planning,74,"@ajitjohnson, I think you could use dataframes in `obsm` for that. We are planning on letting you plot colors from `obsm`, which is being worked on in this PR: https://github.com/theislab/anndata/pull/342",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1189
https://github.com/scverse/scanpy/issues/1190:27,deployability,instal,install,27,"same here, wish I tried to install earlier....",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:14,deployability,build,builds,14,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:160,deployability,build,builds,160,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:193,deployability,instal,installation,193,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:297,deployability,instal,installation,297,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:131,modifiability,maintain,maintainers,131,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:131,safety,maintain,maintainers,131,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:225,safety,avoid,avoid,225,"The bio conda builds look like their broken at the moment, and we haven't had the bandwidth to fix them yet (we are not the direct maintainers of the bio-conda builds). You can find up to date installation instructions which avoid this on the [latest docs](https://scanpy.readthedocs.io/en/latest/installation.html)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:25,deployability,updat,updating,25,good to know. thanks for updating the doc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:25,safety,updat,updating,25,good to know. thanks for updating the doc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:25,security,updat,updating,25,good to know. thanks for updating the doc.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1190:0,reliability,doe,does,0,does the problem still persist?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1190
https://github.com/scverse/scanpy/issues/1191:68,availability,down,downgrading,68,This looks like an bug in the most recent release of `louvain`. Try downgrading? I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:119,availability,cluster,clustering,119,This looks like an bug in the most recent release of `louvain`. Try downgrading? I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:42,deployability,releas,release,42,This looks like an bug in the most recent release of `louvain`. Try downgrading? I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:119,deployability,cluster,clustering,119,This looks like an bug in the most recent release of `louvain`. Try downgrading? I would also recommend using `leiden` clustering instead.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:49,deployability,version,version,49,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:415,deployability,modul,module,415,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:743,deployability,log,logg,743,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:922,deployability,modul,module,922,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:49,integrability,version,version,49,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:49,modifiability,version,version,49,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:415,modifiability,modul,module,415,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:511,modifiability,pac,packages,511,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:775,modifiability,pac,package,775,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:922,modifiability,modul,module,922,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:389,safety,input,input-,389,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:415,safety,modul,module,415,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:743,safety,log,logg,743,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:922,safety,modul,module,922,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:743,security,log,logg,743,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:345,testability,Trace,Traceback,345,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:743,testability,log,logg,743,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:389,usability,input,input-,389,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:527,usability,tool,tools,527,"FYI, it appears that this bug remains in louvain version 0.7 . ```python. In [1]: import numpy as np. ...: import scanpy as sc. ...:. ...: adata = sc.AnnData(np.random.normal(size=(100,3))). ...:. ...: sc.pp.neighbors(adata). ...: sc.tl.louvain(adata). ---------------------------------------------------------------------------. AttributeError Traceback (most recent call last). <ipython-input-1-3505d1878068> in <module>. 5. 6 sc.pp.neighbors(adata). ----> 7 sc.tl.louvain(adata). ~/.local/lib/python3.7/site-packages/scanpy/tools/_louvain.py in louvain(adata, resolution, random_state, restrict_to, key_added, adjacency, flavor, directed, use_weights, partition_type, partition_kwargs, copy). 136 partition_kwargs[""weights""] = weights. 137 logg.info(' using the ""louvain"" package of Traag (2017)'). --> 138 louvain.set_rng_seed(random_state). 139 part = louvain.find_partition(. 140 g, partition_type,. AttributeError: module 'louvain' has no attribute 'set_rng_seed'. In [2]: import louvain. In [3]: louvain.__version__. Out[3]: '0.7.0'. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:56,availability,error,error,56,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:119,availability,cluster,clustering,119,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:119,deployability,cluster,clustering,119,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:240,deployability,modul,module,240,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:408,deployability,modul,module,408,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:477,deployability,version,version,477,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:523,deployability,version,version,523,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:477,integrability,version,version,477,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:523,integrability,version,version,523,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:151,modifiability,pac,package,151,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:240,modifiability,modul,module,240,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:298,modifiability,pac,packages,298,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:408,modifiability,modul,module,408,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:477,modifiability,version,version,477,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:523,modifiability,version,version,523,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:56,performance,error,error,56,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:56,safety,error,error,56,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:240,safety,modul,module,240,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:408,safety,modul,module,408,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:176,testability,Trace,Traceback,176,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:56,usability,error,error,56,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:314,usability,tool,tools,314,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:548,usability,help,help,548,"Hello,. I am having the same issue, here is my code and error :. sc.tl.louvain(adata,resolution=0.4) . running Louvain clustering. using the ""louvain"" package of Traag (2017). Traceback (most recent call last):. File ""<stdin>"", line 1, in <module>. File ""/home/Morgane/anaconda3/lib/python3.7/site-packages/scanpy/tools/_louvain.py"", line 138, in louvain. louvain.set_rng_seed(random_state). AttributeError: module 'louvain' has no attribute 'set_rng_seed'. I am using Louvain version 0.7.0. Did you fix this issue in that version? thanks for your help,. Morgane",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:4,deployability,API,API,4,"The API for setting the random seed changed in the recent release (`v0.7`) of `louvain`, this is fixed on master, which should see a release soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:58,deployability,releas,release,58,"The API for setting the random seed changed in the recent release (`v0.7`) of `louvain`, this is fixed on master, which should see a release soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:133,deployability,releas,release,133,"The API for setting the random seed changed in the recent release (`v0.7`) of `louvain`, this is fixed on master, which should see a release soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:4,integrability,API,API,4,"The API for setting the random seed changed in the recent release (`v0.7`) of `louvain`, this is fixed on master, which should see a release soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:4,interoperability,API,API,4,"The API for setting the random seed changed in the recent release (`v0.7`) of `louvain`, this is fixed on master, which should see a release soon.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:39,deployability,releas,release,39,"If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. Add: `partition_kwargs[""seed""] = random_state` . Remove: `louvain.set_rng_seed(random_state)`. From:. https://github.com/theislab/scanpy/pull/1197/commits/b54d67b9d6b41269c1612df0242210d1279ede85.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:90,modifiability,pac,packages,90,"If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. Add: `partition_kwargs[""seed""] = random_state` . Remove: `louvain.set_rng_seed(random_state)`. From:. https://github.com/theislab/scanpy/pull/1197/commits/b54d67b9d6b41269c1612df0242210d1279ede85.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:106,usability,tool,tools,106,"If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. Add: `partition_kwargs[""seed""] = random_state` . Remove: `louvain.set_rng_seed(random_state)`. From:. https://github.com/theislab/scanpy/pull/1197/commits/b54d67b9d6b41269c1612df0242210d1279ede85.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:41,deployability,releas,release,41,"> If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. > . > Add: `partition_kwargs[""seed""] = random_state`. > Remove: `louvain.set_rng_seed(random_state)`. > . > From:. > [b54d67b](https://github.com/theislab/scanpy/commit/b54d67b9d6b41269c1612df0242210d1279ede85). Thankx this worked",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:92,modifiability,pac,packages,92,"> If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. > . > Add: `partition_kwargs[""seed""] = random_state`. > Remove: `louvain.set_rng_seed(random_state)`. > . > From:. > [b54d67b](https://github.com/theislab/scanpy/commit/b54d67b9d6b41269c1612df0242210d1279ede85). Thankx this worked",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:108,usability,tool,tools,108,"> If anyone is stuck waiting for the new release, you can edit your `.../lib/python3.7/site-packages/scanpy/tools/_louvain.py` with these changes:. > . > Add: `partition_kwargs[""seed""] = random_state`. > Remove: `louvain.set_rng_seed(random_state)`. > . > From:. > [b54d67b](https://github.com/theislab/scanpy/commit/b54d67b9d6b41269c1612df0242210d1279ede85). Thankx this worked",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:0,deployability,Instal,Install,0,Install old louvain package will solve the problem: pip install louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:56,deployability,instal,install,56,Install old louvain package will solve the problem: pip install louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1191:20,modifiability,pac,package,20,Install old louvain package will solve the problem: pip install louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1191
https://github.com/scverse/scanpy/issues/1193:164,availability,error,error,164,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:99,deployability,version,version,99,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:129,deployability,updat,update,129,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:99,integrability,version,version,99,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:99,modifiability,version,version,99,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:164,performance,error,error,164,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:129,safety,updat,update,129,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:164,safety,error,error,164,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:129,security,updat,update,129,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:164,usability,error,error,164,"I don't think this is a segfault, but a `TypeError`. I believe this is due to using an out of date version of `numba`. Could you update that and let me know if the error persists?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:104,availability,error,error,104,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:235,deployability,modul,module,235,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:235,modifiability,modul,module,235,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:387,modifiability,pac,packages,387,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:592,modifiability,pac,packages,592,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:748,modifiability,pac,packages,748,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:97,performance,memor,memory,97,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:104,performance,error,error,104,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:199,performance,time,timeseriesScanpy,199,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:526,performance,memor,memory,526,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:877,performance,Memor,MemoryError,877,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:104,safety,error,error,104,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:235,safety,modul,module,235,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:157,testability,Trace,Traceback,157,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:97,usability,memor,memory,97,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:104,usability,error,error,104,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:526,usability,memor,memory,526,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:877,usability,Memor,MemoryError,877,"This is not related, and most certainly separate issue. <can start a new thread > . I am getting memory error with sc.tl.pca. What is your recommendation? . Traceback (most recent call last):. File ""timeseriesScanpy.py"", line 111, in <module>. sc.tl.pca(adata, svd_solver='arpack') # svd_solver='arpack' is important for reproducibility. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scanpy/preprocessing/_simple.py"", line 498, in pca. X = adata_comp.X.toarray() # Copying the whole adata_comp.X here, could cause memory problems. File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/compressed.py"", line 1024, in toarray. out = self._process_toarray_args(order, out). File ""/home/pjb40/jupytervenv/lib/python3.7/site-packages/scipy/sparse/base.py"", line 1186, in _process_toarray_args. return np.zeros(self.shape, dtype=self.dtype, order=order). MemoryError.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:187,deployability,releas,release,187,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:328,deployability,releas,release,328,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:179,energy efficiency,current,current,179,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:252,integrability,sub,subset,252,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:70,performance,memor,memory,70,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:151,performance,memor,memory,151,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:301,performance,memor,memory,301,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:363,performance,memor,memory,363,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:70,usability,memor,memory,70,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:151,usability,memor,memory,151,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:301,usability,memor,memory,301,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:363,usability,memor,memory,363,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:370,usability,efficien,efficient,370,"I think that might be due to the dense array being to large to fit in memory on your machine. Just to be sure, how large is your dataset? And how much memory do you have? For the current release, you could either try using the incremental PCA, using a subset of the data, or using a machine with more memory. In the next scanpy release, there will be a much more memory efficient PCA implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:230,availability,cluster,cluster,230,"Quite big! i have 8 samples with average of ~4000 cells. Total ~32K cells. . merged AnnData . AnnData object with n_obs  n_vars = 67948800  27998 . obs: 'sample'. var: 'gene_ids', 'feature_types', 'genome'. Also running this on cluster with 150GB mem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:230,deployability,cluster,cluster,230,"Quite big! i have 8 samples with average of ~4000 cells. Total ~32K cells. . merged AnnData . AnnData object with n_obs  n_vars = 67948800  27998 . obs: 'sample'. var: 'gene_ids', 'feature_types', 'genome'. Also running this on cluster with 150GB mem.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:321,deployability,observ,observations,321,"I think you've got more than 32k cells in the object, looks like ~68 million ()? The number of `obs` is the cells, while the number of `vars` is the genes. 150GB should be more than enough memory for 32k cells. Probably not enough for 68 million. Probably look through your code to figure out how you're getting so many observations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:190,performance,memor,memory,190,"I think you've got more than 32k cells in the object, looks like ~68 million ()? The number of `obs` is the cells, while the number of `vars` is the genes. 150GB should be more than enough memory for 32k cells. Probably not enough for 68 million. Probably look through your code to figure out how you're getting so many observations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:321,testability,observ,observations,321,"I think you've got more than 32k cells in the object, looks like ~68 million ()? The number of `obs` is the cells, while the number of `vars` is the genes. 150GB should be more than enough memory for 32k cells. Probably not enough for 68 million. Probably look through your code to figure out how you're getting so many observations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:190,usability,memor,memory,190,"I think you've got more than 32k cells in the object, looks like ~68 million ()? The number of `obs` is the cells, while the number of `vars` is the genes. 150GB should be more than enough memory for 32k cells. Probably not enough for 68 million. Probably look through your code to figure out how you're getting so many observations?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1193:26,usability,close,closed,26,I'm going to mark this as closed for the TypeError issue. I'm definitely interested to hear how you ended up with that many cells!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1193
https://github.com/scverse/scanpy/issues/1195:289,security,modif,modified,289,"For 1) the order is given by pandas categories order of the .obs data frame. The order can be changed using `reorder` https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#reordering. For 2) I am not so sure what you mean and for 3) The best is get each of the axes and modified it as you want afterwards. For this, set `show=False`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:52,usability,close,close,52,"As we haven't heard back after the followup we will close the issue at this point I think, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/issues/1195:127,usability,behavi,behaviour,127,"As we haven't heard back after the followup we will close the issue at this point I think, hopefully you obtained the expected behaviour in the end :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1195
https://github.com/scverse/scanpy/pull/1196:50,deployability,contain,contain,50,"hi,. - yeah, it should work if the original array contain `nan` (i.e. it would just ignore these entries). - ah, just saw that there's a `tests/test_score_genes.py` file, I'll add a few tests the next days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:138,safety,test,tests,138,"hi,. - yeah, it should work if the original array contain `nan` (i.e. it would just ignore these entries). - ah, just saw that there's a `tests/test_score_genes.py` file, I'll add a few tests the next days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:186,safety,test,tests,186,"hi,. - yeah, it should work if the original array contain `nan` (i.e. it would just ignore these entries). - ah, just saw that there's a `tests/test_score_genes.py` file, I'll add a few tests the next days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:138,testability,test,tests,138,"hi,. - yeah, it should work if the original array contain `nan` (i.e. it would just ignore these entries). - ah, just saw that there's a `tests/test_score_genes.py` file, I'll add a few tests the next days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:186,testability,test,tests,186,"hi,. - yeah, it should work if the original array contain `nan` (i.e. it would just ignore these entries). - ah, just saw that there's a `tests/test_score_genes.py` file, I'll add a few tests the next days!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:13,deployability,manag,managed,13,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:13,energy efficiency,manag,managed,13,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:47,modifiability,refact,refactor,47,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:47,performance,refactor,refactor,47,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:13,safety,manag,managed,13,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:33,safety,test,tests,33,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:127,safety,test,test,127,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:33,testability,test,tests,33,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/pull/1196:127,testability,test,test,127,"hi,. finally managed to add some tests. Had to refactor the original `test_score_genes.py` a little, I hope that's ok: The one test that was already there still exists, I just pulled out the creation of the adata into a separate function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1196
https://github.com/scverse/scanpy/issues/1198:197,deployability,updat,updated,197,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:129,interoperability,format,format,129,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:160,performance,disk,disk,160,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:197,safety,updat,updated,197,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1198:197,security,updat,updated,197,"Hi @honghh2018,. This might be an issue you have to raise with Seurat about their ReadH5AD function. From `AnnData` 0.7 the h5ad format has changed a little on disk, so maybe their function is not updated to this yet? Other ways you can go between Scanpy and Seurat are loom files or `anndata2ri` as shown [here](https://github.com/LuckyMD/Code_snippets/blob/master/Seurat_to_anndata.ipynb)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1198
https://github.com/scverse/scanpy/issues/1199:0,safety,Test,Test,0,Test case is included in https://github.com/theislab/scanpy/pull/1669,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:0,testability,Test,Test,0,Test case is included in https://github.com/theislab/scanpy/pull/1669,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:14,reliability,doe,does,14,"Hi @mvdbeek , does the fix in #1669 works?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:17,safety,test,tests,17,"If it passes the tests I'm sure it works, feel free to pull it in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1199:17,testability,test,tests,17,"If it passes the tests I'm sure it works, feel free to pull it in.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1199
https://github.com/scverse/scanpy/issues/1201:70,safety,test,test,70,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:175,safety,test,test,175,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:70,testability,test,test,70,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1201:175,testability,test,test,175,"I think it's normally just the string `""euclidean""`, but you can just test what is stored in `.uns['neighbors']['params']['metric']` after running `sc.pp.neighbors()` on some test data.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1201
https://github.com/scverse/scanpy/issues/1202:17,availability,error,error,17,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:48,deployability,instal,installing,48,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:17,performance,error,error,17,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:17,safety,error,error,17,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:17,usability,error,error,17,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:64,usability,learn,learn,64,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/issues/1202:96,usability,learn,learn,96,"ok, I solved the error by uninstalling umap and installing umap-learn. it only worked with umap-learn v. 0.3.9, as was suggested here: https://github.com/theislab/scanpy/issues/1181",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1202
https://github.com/scverse/scanpy/pull/1204:139,availability,error,error,139,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:46,deployability,fail,failing,46,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:145,integrability,messag,message,145,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:145,interoperability,messag,message,145,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:139,performance,error,error,139,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:46,reliability,fail,failing,46,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:163,reliability,doe,doesn,163,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:139,safety,error,error,139,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:139,usability,error,error,139,"@ivirshup -- I still can't tell why Travis is failing. For some reason on Travis, loess is outputting a zero for the gene mentioned in the error message, but this doesn't happen locally for me.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:106,reliability,doe,does,106,I think the inconsistency I'm seeing is that the loess function gives different results on my Mac than it does on linux. https://github.com/has2k1/scikit-misc/issues/8,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:183,performance,time,time,183,"> I might leave a more in depth review to people more familiar with this code. @LuckyMD or @gokceneraslan do you think you could take a look at this? Sorry, I don't think I will have time for this in the next 2 weeks. I'm finishing up a 2 larger projects atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:32,safety,review,review,32,"> I might leave a more in depth review to people more familiar with this code. @LuckyMD or @gokceneraslan do you think you could take a look at this? Sorry, I don't think I will have time for this in the next 2 weeks. I'm finishing up a 2 larger projects atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:32,testability,review,review,32,"> I might leave a more in depth review to people more familiar with this code. @LuckyMD or @gokceneraslan do you think you could take a look at this? Sorry, I don't think I will have time for this in the next 2 weeks. I'm finishing up a 2 larger projects atm.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:61,deployability,fail,failing,61,@ivirshup this should be good to go now. I don't thin Codacy failing has anything to do with my code. @gokceneraslan would you be able to review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:61,reliability,fail,failing,61,@ivirshup this should be good to go now. I don't thin Codacy failing has anything to do with my code. @gokceneraslan would you be able to review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:138,safety,review,review,138,@ivirshup this should be good to go now. I don't thin Codacy failing has anything to do with my code. @gokceneraslan would you be able to review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:138,testability,review,review,138,@ivirshup this should be good to go now. I don't thin Codacy failing has anything to do with my code. @gokceneraslan would you be able to review?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:184,energy efficiency,reduc,reduce,184,"@gokceneraslan why are the defaults for the main function all None (e.g., dispersion cutoffs)? It seems like if scanpydoc is picking up the defaults then we can make them not None and reduce some code?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:186,energy efficiency,reduc,reduce,186,"> @gokceneraslan why are the defaults for the main function all None (e.g., dispersion cutoffs)? It seems like if scanpydoc is picking up the defaults then we can make them not None and reduce some code? Honestly, I don't know. But @ivirshup also brought it up here https://github.com/theislab/scanpy/pull/1180#discussion_r412871280 and here https://github.com/theislab/scanpy/pull/1180#discussion_r413445806, I just didn't have time to address it. I am fine with making them not None.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:429,performance,time,time,429,"> @gokceneraslan why are the defaults for the main function all None (e.g., dispersion cutoffs)? It seems like if scanpydoc is picking up the defaults then we can make them not None and reduce some code? Honestly, I don't know. But @ivirshup also brought it up here https://github.com/theislab/scanpy/pull/1180#discussion_r412871280 and here https://github.com/theislab/scanpy/pull/1180#discussion_r413445806, I just didn't have time to address it. I am fine with making them not None.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:258,availability,error,error,258,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:74,deployability,build,build,74,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:282,deployability,build,builds,282,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:264,integrability,messag,message,264,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:264,interoperability,messag,message,264,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:258,performance,error,error,258,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:258,safety,error,error,258,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:60,usability,Document,Documentation,60,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:177,usability,help,help,177,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:258,usability,error,error,258,"But I think scanpydoc is very confused now for some reason. Documentation build is broken, it's visible in ~all~ some recent PRs too and there is not much we can do without the help of @falexwolf or @flying-sheep or @ivirshup, because we cannot even see the error message. My local builds are just fine ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:85,integrability,batch,batches,85,"There's a strange issue I'm having where the gene sets when combining from different batches are not equal between this code and Seurat v3. The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal. Otherwise, this PR is good to go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:243,integrability,batch,batch,243,"There's a strange issue I'm having where the gene sets when combining from different batches are not equal between this code and Seurat v3. The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal. Otherwise, this PR is good to go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:85,performance,batch,batches,85,"There's a strange issue I'm having where the gene sets when combining from different batches are not equal between this code and Seurat v3. The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal. Otherwise, this PR is good to go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:243,performance,batch,batch,243,"There's a strange issue I'm having where the gene sets when combining from different batches are not equal between this code and Seurat v3. The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal. Otherwise, this PR is good to go.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:355,availability,state,state,355,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:40,deployability,Updat,Updating,40,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:355,integrability,state,state,355,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:109,interoperability,format,formatting,109,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:40,safety,Updat,Updating,40,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:120,safety,test,test,120,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:189,safety,test,testing,189,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:40,security,Updat,Updating,40,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:120,testability,test,test,120,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:189,testability,test,testing,189,"The docs should now be fixed on master. Updating the branch should fix that. I've added a commit to fix that formatting test. @adamgayoso could you compress the data files you're using for testing, and remove to uncompressed files from the git history? This is to keep the repo size as small as possible. Otherwise, @gokceneraslan were you happy with the state this PR is in?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:18,deployability,build,build,18,Any ideas why doc build still fails?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:30,deployability,fail,fails,30,Any ideas why doc build still fails?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:30,reliability,fail,fails,30,Any ideas why doc build still fails?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:51,availability,error,error,51,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:111,availability,error,error,111,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:51,performance,error,error,51,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:111,performance,error,error,111,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:94,reliability,doe,does,94,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:51,safety,error,error,51,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:111,safety,error,error,111,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:37,security,access,access,37,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:51,usability,error,error,51,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:111,usability,error,error,111,@ivirshup @gokceneraslan Do you have access to the error details for readthedocs? I get 'page does not exists' error,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:221,availability,consist,consistent,221,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:81,deployability,releas,release,81,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:350,integrability,batch,batch,350,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:350,performance,batch,batch,350,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:221,usability,consist,consistent,221,"@gokceneraslan @ivirshup just checking in on this. Will this be part of the next release? Do you need anything else from me? It might be nice to note somewhere that when `batch_key` is not None, results aren't absolutely consistent with Seurat. > The problem appears to be due to the fact that many genes have the same normalized variance in a given batch and the merging method uses ranks. So I believe the difference is due to genes being sorted differently with the same normalized variance. Perhaps this merging scheme is not ideal.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/pull/1204:54,deployability,releas,release,54,"Awesome, thanks for this! I've added something to the release notes, let me know if you'd like to say more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1204
https://github.com/scverse/scanpy/issues/1205:571,deployability,continu,continue,571,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:412,integrability,sub,submitting,412,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:73,modifiability,deco,decompositon,73,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:245,reliability,doe,doesn,245,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:209,safety,compl,complicated,209,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:264,safety,compl,complicated,264,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:209,security,compl,complicated,209,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:264,security,compl,complicated,264,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:113,usability,learn,learning,113,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:127,usability,learn,learnt,127,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:314,usability,tool,tool,314,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1205:507,usability,close,close,507,"Hi @jorvis ,. ProjectR as far as I'm aware relies on some form of matrix decompositon (PCA, NMF) and do transfer learning with learnt weights. In some sense, it's similar to ingest. However, it would be a bit complicated to port it from R. . It doesn't seem super complicated to have it in scanpy as an additional tool, but it's not really a priority now. If you have anything in mind and would want to try with submitting a PR, it would be very much appreciated and we would definitely have a look! . I'll close this for now, but pls feel free to re-open if you want to continue discussion or would like to discuss implementation.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1205
https://github.com/scverse/scanpy/issues/1207:46,security,immut,immutable,46,"No. In general, the `raw` attribute should be immutable.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1207
https://github.com/scverse/scanpy/issues/1208:221,deployability,api,api,221,"Hi, I'm not sure where you found the function `normalize_geometric()`, but Scanpy's inbuilt normalization is called `sc.pp.normalize_total()`. You can find the documentation here:. https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:221,integrability,api,api,221,"Hi, I'm not sure where you found the function `normalize_geometric()`, but Scanpy's inbuilt normalization is called `sc.pp.normalize_total()`. You can find the documentation here:. https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:221,interoperability,api,api,221,"Hi, I'm not sure where you found the function `normalize_geometric()`, but Scanpy's inbuilt normalization is called `sc.pp.normalize_total()`. You can find the documentation here:. https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:160,usability,document,documentation,160,"Hi, I'm not sure where you found the function `normalize_geometric()`, but Scanpy's inbuilt normalization is called `sc.pp.normalize_total()`. You can find the documentation here:. https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.normalize_total.html",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:426,integrability,event,event-,426,"I found it in the CITEseq tutorial. https://scanpy-tutorials.readthedocs.io/en/multiomics/cite-seq/pbmc5k.html. Le mar. 12 mai 2020  03:59, MalteDLuecken <notifications@github.com> a. crit :. > Closed #1208 <https://github.com/theislab/scanpy/issues/1208>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1208#event-3326937703>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AG6NOAWOLOUUOMFRCYB4KMLRRETYZANCNFSM4M6NCTKQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:304,security,auth,authored,304,"I found it in the CITEseq tutorial. https://scanpy-tutorials.readthedocs.io/en/multiomics/cite-seq/pbmc5k.html. Le mar. 12 mai 2020  03:59, MalteDLuecken <notifications@github.com> a. crit :. > Closed #1208 <https://github.com/theislab/scanpy/issues/1208>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1208#event-3326937703>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AG6NOAWOLOUUOMFRCYB4KMLRRETYZANCNFSM4M6NCTKQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:512,security,auth,auth,512,"I found it in the CITEseq tutorial. https://scanpy-tutorials.readthedocs.io/en/multiomics/cite-seq/pbmc5k.html. Le mar. 12 mai 2020  03:59, MalteDLuecken <notifications@github.com> a. crit :. > Closed #1208 <https://github.com/theislab/scanpy/issues/1208>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1208#event-3326937703>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AG6NOAWOLOUUOMFRCYB4KMLRRETYZANCNFSM4M6NCTKQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:196,usability,Close,Closed,196,"I found it in the CITEseq tutorial. https://scanpy-tutorials.readthedocs.io/en/multiomics/cite-seq/pbmc5k.html. Le mar. 12 mai 2020  03:59, MalteDLuecken <notifications@github.com> a. crit :. > Closed #1208 <https://github.com/theislab/scanpy/issues/1208>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1208#event-3326937703>, or. > unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AG6NOAWOLOUUOMFRCYB4KMLRRETYZANCNFSM4M6NCTKQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:102,deployability,log,log,102,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:112,integrability,transform,transformation,112,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:341,integrability,transform,transformation,341,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:112,interoperability,transform,transformation,112,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:341,interoperability,transform,transformation,341,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:102,safety,log,log,102,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:272,safety,safe,safeguards,272,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:102,security,log,log,102,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:102,testability,log,log,102,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/issues/1208:605,usability,support,support,605,"@shendong124 @ivirshup I assume `normalize_geometric` was intended to be similar to Seurat's centered log ratio transformation, which is implemented as follows in R: `log1p(x = x / (exp(x = sum(log1p(x = x[x > 0]), na.rm = TRUE) / length(x = x))))`. This is CLR with some safeguards for 0 counts. Here's a reimplementation of the Seurat CLR transformation for scanpy. Call this with `clr_normalize_each_cell(adata)`:. ```. def clr_normalize_each_cell(adata, inplace=True):. """"""Normalize count vector for each cell, i.e. for each row of .X"""""". import numpy as np. import scipy. def seurat_clr(x):. # TODO: support sparseness. s = np.sum(np.log1p(x[x > 0])). exp = np.exp(s / len(x)). return np.log1p(x / exp). if not inplace:. adata = adata.copy(). # apply to dense or sparse matrix, along axis. returns dense matrix. adata.X = np.apply_along_axis(. seurat_clr, 1, (adata.X.A if scipy.sparse.issparse(adata.X) else adata.X). ). return adata. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1208
https://github.com/scverse/scanpy/pull/1210:21,energy efficiency,estimat,estimation,21,This looks nice. Any estimation of this will be merged into master? Thanks,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:52,reliability,doe,does,52,@z5ouyang Mostly is ready. I have been using it and does not break any previous functionality. Seems quite stable. I am now working on the tutorial.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:556,energy efficiency,current,current,556,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:585,energy efficiency,current,current,585,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:797,energy efficiency,current,current,797,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:127,modifiability,Exten,Extended,127,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:714,modifiability,refact,refactored,714,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:714,performance,refactor,refactored,714,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:364,security,access,accessed,364,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:260,usability,document,documented,260,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:342,usability,document,documented,342,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:612,usability,minim,minimal,612,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:805,usability,progress,progress,805,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:821,usability,visual,visualization,821,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:946,usability,visual,visualizing-marker-genes,946,"@ivirshup @flying-sheep @falexwolf . I would like to merge this branch soon and I would like your opinion on the following:. * Extended functionality and fine tuning of the plots is achieved by using the new plot objects. However, I don't know how they can be documented in readthedocs (or if we want that). Note: the object methods are well documented and can be accessed, for example in Jupyter notebooks. * I am using `return_fig` as an argument to return the plot object in `sc.pl.dotplot` etc. Is this a good name choice? As mentioned previously, the current PR tries to keep the current functionality with minimal changes to the way functions like `sc.pl.dotplot` are called. On the background, the code was refactored to remove much repetition as possible and allow new functionally. . The current progress on the visualization tutorial is here: https://nbviewer.jupyter.org/github/fidelram/scanpy-tutorials/blob/marker_genes_vis_tutorial/visualizing-marker-genes.ipynb",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:301,integrability,sub,subplots,301,"The last changes in `stacked_violin` allows to use a color map as in `dotplot`. ```PYTHON. pmbc = sc.datasets.pbmc68k_reduced(). marker_genes_dict = {'NK': ['GNLY', 'NKG7'], 'T-cell': ['CD3D'], . 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11,5), gridspec_kw={'wspace':0.3}). sc.pl.stacked_violin(pbmc, marker_genes_dict, groupby='bulk_labels', ax=ax1, show=False). sc.pl.dotplot(pbmc, marker_genes_dict, groupby='bulk_labels', ax=ax2, show=False). ``` . ![image](https://user-images.githubusercontent.com/4964309/84125655-23e29400-aa3d-11ea-8234-05725947d811.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:557,usability,user,user-images,557,"The last changes in `stacked_violin` allows to use a color map as in `dotplot`. ```PYTHON. pmbc = sc.datasets.pbmc68k_reduced(). marker_genes_dict = {'NK': ['GNLY', 'NKG7'], 'T-cell': ['CD3D'], . 'B-cell': ['CD79A', 'MS4A1'],. 'Monocytes': ['FCGR3A'],. 'Dendritic': ['FCER1A']}. fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11,5), gridspec_kw={'wspace':0.3}). sc.pl.stacked_violin(pbmc, marker_genes_dict, groupby='bulk_labels', ax=ax1, show=False). sc.pl.dotplot(pbmc, marker_genes_dict, groupby='bulk_labels', ax=ax2, show=False). ``` . ![image](https://user-images.githubusercontent.com/4964309/84125655-23e29400-aa3d-11ea-8234-05725947d811.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:208,energy efficiency,heat,heatmap,208,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:376,energy efficiency,heat,heatmap,376,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:219,safety,avoid,avoid,219,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:398,usability,document,documentation,398,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:535,usability,user,user-images,535,"In the dotplots, when the color_on == 'square', fixed dot edge color might lead to some trouble in visibility when the square color and dot edge color happen to be similar. There is a nice feature of seaborn heatmap to avoid exactly that, where the annotation text color is determined conditionally on the square color, see [here](https://seaborn.pydata.org/generated/seaborn.heatmap.html) for the documentation and [here](https://github.com/mwaskom/seaborn/blob/master/seaborn/matrix.py#L261) for the relevant code:. ![image](https://user-images.githubusercontent.com/1140359/84678062-8f28dc00-aefd-11ea-84f5-d1b4f1496814.png). It can be too much work, feel free to ignore but just wanted to highlight.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:176,energy efficiency,adapt,adapted,176,"@gokceneraslan Thanks for pointing this out! The `relative_luminance` function required for this can be easily imported from seaborn, therefore, I imagine that the code can be adapted easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:176,integrability,adapt,adapted,176,"@gokceneraslan Thanks for pointing this out! The `relative_luminance` function required for this can be easily imported from seaborn, therefore, I imagine that the code can be adapted easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:176,interoperability,adapt,adapted,176,"@gokceneraslan Thanks for pointing this out! The `relative_luminance` function required for this can be easily imported from seaborn, therefore, I imagine that the code can be adapted easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:176,modifiability,adapt,adapted,176,"@gokceneraslan Thanks for pointing this out! The `relative_luminance` function required for this can be easily imported from seaborn, therefore, I imagine that the code can be adapted easily.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:421,usability,user,user-images,421,"@gokceneraslan I just added the dynamic coloring of the circles when the color is on the background square. . ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). markers = {'T-cell': ['CD3D', 'CD3E', 'IL32'], . 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],. 'myeloid': ['CST3', 'LYZ']}. sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\. .style(color_on='square', cmap='binary').show(). ```. ![image](https://user-images.githubusercontent.com/4964309/85594587-5947ce00-b648-11ea-962e-a40cccbc169e.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:66,reliability,doe,does,66,"@fidelram Sorry, I completely missed your asking for a review! It does look good though. However, it looks like this is breaking the docs. Could you take a look into that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:19,safety,compl,completely,19,"@fidelram Sorry, I completely missed your asking for a review! It does look good though. However, it looks like this is breaking the docs. Could you take a look into that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:55,safety,review,review,55,"@fidelram Sorry, I completely missed your asking for a review! It does look good though. However, it looks like this is breaking the docs. Could you take a look into that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:19,security,compl,completely,19,"@fidelram Sorry, I completely missed your asking for a review! It does look good though. However, it looks like this is breaking the docs. Could you take a look into that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:55,testability,review,review,55,"@fidelram Sorry, I completely missed your asking for a review! It does look good though. However, it looks like this is breaking the docs. Could you take a look into that?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:350,availability,error,errors,350,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:298,deployability,modul,module,298,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:298,modifiability,modul,module,298,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:350,performance,error,errors,350,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:298,safety,modul,module,298,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:350,safety,error,errors,350,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:350,usability,error,errors,350,"I think the issue that there are references to the `DotPlot` class, but no doc page get's generated for that class. I think this can be fixed by adding something like:. ```rst. Classes used for these plots:. .. autosummary::. :toctree: . pl._dotplot.DotPlot. ```. to the doc-string of the plotting module. Once this exists, there might be some other errors that pop up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:124,energy efficiency,cool,cool,124,"> @gokceneraslan I just added the dynamic coloring of the circles when the color is on the background square. @fidelram The cool dynamic line coloring feature seems broken now, I wonder why :/. <img width=""613"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/91358404-c6025480-e7c0-11ea-99a9-dd803f79ca19.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:236,usability,user,user-images,236,"> @gokceneraslan I just added the dynamic coloring of the circles when the color is on the background square. @fidelram The cool dynamic line coloring feature seems broken now, I wonder why :/. <img width=""613"" alt=""image"" src=""https://user-images.githubusercontent.com/1140359/91358404-c6025480-e7c0-11ea-99a9-dd803f79ca19.png"">.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:63,deployability,releas,release,63,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON. sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\. .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:72,performance,Time,Time,72,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON. sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\. .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:86,safety,test,test,86,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON. sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\. .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/pull/1210:86,testability,test,test,86,"Is because we changed dot edge the defaults shortly before the release. Time to add a test for this. I will make a fix but meanwhile you can trigger the dynamic coloring by setting `dot_edge_color` and `dot_edge_lw` as `None`:. ```PYTHON. sc.pl.dotplot(adata, markers, groupby='bulk_labels', return_fig=True)\. .style(color_on='square', dot_edge_color=None, dot_edge_lw=None).show(). ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1210
https://github.com/scverse/scanpy/issues/1211:17,availability,ping,pinging,17,"I believe it is, pinging @Koncopd who probably knows more about it. If this is desired behaviour, we could close this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:87,usability,behavi,behaviour,87,"I believe it is, pinging @Koncopd who probably knows more about it. If this is desired behaviour, we could close this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:107,usability,close,close,107,"I believe it is, pinging @Koncopd who probably knows more about it. If this is desired behaviour, we could close this.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:115,deployability,api,api,115,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:211,deployability,api,api,211,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:115,integrability,api,api,115,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:211,integrability,api,api,211,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:115,interoperability,api,api,115,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:211,interoperability,api,api,211,Hi @HypoChloremic . would something like this be useful for your question? https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_overview.html#scanpy.pl.pca_overview. https://scanpy.readthedocs.io/en/stable/api/scanpy.pl.pca_variance_ratio.html#scanpy.pl.pca_variance_ratio. ?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1211:5,usability,close,close,5,will close this due to inactivity,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1211
https://github.com/scverse/scanpy/issues/1213:135,availability,cluster,cluster,135,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:243,availability,cluster,cluster,243,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:26,deployability,log,logic,26,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:135,deployability,cluster,cluster,135,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:243,deployability,cluster,cluster,243,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:512,deployability,updat,updated,512,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:26,safety,log,logic,26,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:512,safety,updat,updated,512,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:26,security,log,logic,26,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:512,security,updat,updated,512,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:26,testability,log,logic,26,"It makes sense to use AND logic, because the function keeps genes that satisfy all three conditions. . 1) Fraction of cells inside the cluster expressing the gene must be greater than `min_in_group_fraction`. 2) Fractions of cells outside the cluster expressing the gene must be less than `max_out_group_fraction`. 3) Fold change must be greater than `min_fold_change`. But there are remaining issues (calculation of fold change and using the absolute value of the fold change) in this function that needs to be updated #863 .",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:291,availability,cluster,cluster,291,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:402,availability,cluster,cluster,402,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:176,deployability,log,logic,176,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:291,deployability,cluster,cluster,291,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:402,deployability,cluster,cluster,402,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:683,deployability,updat,updated,683,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:50,integrability,filter,filtering,50,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:176,safety,log,logic,176,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:683,safety,updat,updated,683,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:176,security,log,logic,176,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:683,security,updat,updated,683,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:790,security,auth,authored,790,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:1004,security,auth,auth,1004,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:176,testability,log,logic,176,"Thanks for clarification. I had thought it is for filtering out genes. On Mon, May 18, 2020 at 2:21 AM Rachel Ng <notifications@github.com> wrote:. > It makes sense to use AND logic, because the function keeps genes that. > satisfy all three conditions. >. > 1. Fraction of cells inside the cluster expressing the gene must be. > greater than min_in_group_fraction. > 2. Fractions of cells outside the cluster expressing the gene must be. > less than max_out_group_fraction. > 3. Fold change must be greater than min_fold_change. >. > But there are remaining issues (calculation of fold change and using the. > absolute value of the fold change) in this function that needs to be. > updated #863 <https://github.com/theislab/scanpy/issues/863>. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1213#issuecomment-629970781>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ADG2PVZVFSYU3ST4ESJFS33RSDHVXANCNFSM4NAA5V2A>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:58,deployability,updat,update,58,After https://github.com/theislab/scanpy/pull/1156 I will update the function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:58,safety,updat,update,58,After https://github.com/theislab/scanpy/pull/1156 I will update the function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:58,security,updat,update,58,After https://github.com/theislab/scanpy/pull/1156 I will update the function.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:21,deployability,updat,update,21,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:63,deployability,log,logic,63,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:87,deployability,log,logic,87,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:48,reliability,doe,does,48,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:75,reliability,Doe,Doesn,75,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:21,safety,updat,update,21,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:63,safety,log,logic,63,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:87,safety,log,logic,87,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:21,security,updat,update,21,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:63,security,log,logic,63,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:87,security,log,logic,87,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:63,testability,log,logic,63,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/issues/1213:87,testability,log,logic,87,"> After #1156 I will update the function. Wait, does it use OR logic now?? Doesn't AND logic make more sense???",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1213
https://github.com/scverse/scanpy/pull/1216:7,deployability,instal,install,7,leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1216:86,deployability,instal,install,86,leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1216:46,energy efficiency,current,current,46,leiden install via conda code is wrong in the current page. it should be:. ```. conda install -c conda-forge leidenalg . ```,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1216
https://github.com/scverse/scanpy/pull/1217:43,interoperability,coordinat,coordinates,43,"Yes, I understand the point and agree. Now coordinates are inverted whenever `basis='spatial'` but circled are plotted only when `library_id is not None`, which is passed by `sc.pl.spatial` to embedding. Otherwise, scatterplot is used",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:7,testability,understand,understand,7,"Yes, I understand the point and agree. Now coordinates are inverted whenever `basis='spatial'` but circled are plotted only when `library_id is not None`, which is passed by `sc.pl.spatial` to embedding. Otherwise, scatterplot is used",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:102,deployability,log,logic,102,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:243,deployability,releas,release,243,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:39,integrability,coupl,couple,39,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:39,modifiability,coupl,couple,39,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:102,safety,log,logic,102,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:102,security,log,logic,102,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:39,testability,coupl,couple,39,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/pull/1217:102,testability,log,logic,102,"@giovp, I'll merge this. I'm merging a couple other things first though. I'm not super happy with the logic flow here at the moment. Could we aim for separating out the code for scatter plots, and overlaying grids on-top of images in the next release cycle?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1217
https://github.com/scverse/scanpy/issues/1220:61,availability,error,error,61,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:61,performance,error,error,61,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:61,safety,error,error,61,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:9,usability,clear,clear,9,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:61,usability,error,error,61,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:118,usability,close,close,118,"it's not clear what the problem here sorry, can you copy the error and report a reproducible example? thank you! I'll close this for now, feel free to reopen",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:320,availability,error,error,320,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:431,availability,error,error,431,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:437,deployability,log,log,437,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:193,modifiability,maintain,maintainers,193,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:361,modifiability,pac,package,361,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:320,performance,error,error,320,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:431,performance,error,error,431,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:193,safety,maintain,maintainers,193,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:320,safety,error,error,320,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:422,safety,compl,complete,422,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:431,safety,error,error,431,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:437,safety,log,log,437,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:422,security,compl,complete,422,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:437,security,log,log,437,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:437,testability,log,log,437,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:250,usability,help,help,250,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:320,usability,error,error,320,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:401,usability,help,help,401,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:431,usability,error,error,431,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:501,usability,help,helpful,501,"Hi @JayalalKJ ,. as you also pointed out, this issue is related to an environment in https://github.com/theislab/single-cell-tutorial. It's best if you open an issue there and directly address maintainers of that repo. . Beside that, we can't really help you in this case because we don't have enough information on the error and also it relates to an external package. We could provide you with more help if you post the complete error log, but pls do so not here but in the other repo. Hope this is helpful.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1220:43,modifiability,pac,package,43,This looks like you can't find the louvain package via `conda` on windows. I believe that's a known issue that we've encountered before in the scanpy issues. See for example #786,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1220
https://github.com/scverse/scanpy/issues/1221:49,deployability,version,version,49,Thanks for your help! I will try the development version! Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:49,integrability,version,version,49,Thanks for your help! I will try the development version! Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:49,modifiability,version,version,49,Thanks for your help! I will try the development version! Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/issues/1221:16,usability,help,help,16,Thanks for your help! I will try the development version! Thanks!,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1221
https://github.com/scverse/scanpy/pull/1224:235,energy efficiency,CPU,CPU,235,"@falexwolf @ivirshup please let me know what your plans are for the ""scanpy"" way of handling CITE-seq data are. Also, if somehow you could compare to totalVI in your tutorial that would be great! It takes about 20-25 minutes to run on CPU for the pbmc5k and HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:235,performance,CPU,CPU,235,"@falexwolf @ivirshup please let me know what your plans are for the ""scanpy"" way of handling CITE-seq data are. Also, if somehow you could compare to totalVI in your tutorial that would be great! It takes about 20-25 minutes to run on CPU for the pbmc5k and HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:50,testability,plan,plans,50,"@falexwolf @ivirshup please let me know what your plans are for the ""scanpy"" way of handling CITE-seq data are. Also, if somehow you could compare to totalVI in your tutorial that would be great! It takes about 20-25 minutes to run on CPU for the pbmc5k and HVGs.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:121,deployability,releas,release,121,"Thanks for this PR, this looks interesting! Sorry for taking a while to get back to you, we've been quite busy getting a release out. We'll try and get back to you with more in the next couple weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:186,integrability,coupl,couple,186,"Thanks for this PR, this looks interesting! Sorry for taking a while to get back to you, we've been quite busy getting a release out. We'll try and get back to you with more in the next couple weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:186,modifiability,coupl,couple,186,"Thanks for this PR, this looks interesting! Sorry for taking a while to get back to you, we've been quite busy getting a release out. We'll try and get back to you with more in the next couple weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1224:186,testability,coupl,couple,186,"Thanks for this PR, this looks interesting! Sorry for taking a while to get back to you, we've been quite busy getting a release out. We'll try and get back to you with more in the next couple weeks.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1224
https://github.com/scverse/scanpy/pull/1226:34,modifiability,paramet,parameter,34,Do we need to consider the `base` parameter of log1p here?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:43,deployability,log,logging,43,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:210,reliability,doe,doesn,210,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:43,safety,log,logging,43,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:228,safety,compl,completely,228,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:43,security,log,logging,43,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:228,security,compl,completely,228,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:43,testability,log,logging,43,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/pull/1226:112,usability,visual,visualize,112,"In my opinion, we'll likely move away from logging everything. Isaac built this in so that one can conveniently visualize things in seaborn; I added the switch to turn it off so that the basic tutorial of v1.5 doesn't lead to a completely cluttered AnnData object. But, I guess, we all agree that this here isn't the final solution. ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1226
https://github.com/scverse/scanpy/issues/1227:45,deployability,instal,install,45,I meet the same problem. You could use:. pip install matplotlib==2.2.3. I tried just. And it done.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,availability,error,error,121,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:342,availability,down,downgrading,342,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:258,deployability,releas,release,258,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:314,deployability,upgrad,upgrade,314,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:314,modifiability,upgrad,upgrade,314,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,performance,error,error,121,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:139,performance,network,networkx,139,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:171,performance,network,networkx,171,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:180,performance,network,networkx,180,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:196,performance,network,networkx,196,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:218,performance,network,networkx,218,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:322,performance,network,networkx,322,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,safety,error,error,121,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:139,security,network,networkx,139,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:171,security,network,networkx,171,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:180,security,network,networkx,180,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:196,security,network,networkx,196,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:218,security,network,networkx,218,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:322,security,network,networkx,322,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:106,testability,trace,traceback,106,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:121,usability,error,error,121,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1227:237,usability,document,documentation,237,"We require matplotlib 3.x for other parts of scanpy, so thats not a real solution. As you can see in the traceback, the error happens in `networkx`. It has been fixed in networkx/networkx#3179 ([networkx 2.3](https://networkx.github.io/documentation/stable/release/release_2.3.html)) in April 2019. So you should upgrade networkx instead of downgrading matplotlib.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1227
https://github.com/scverse/scanpy/issues/1233:169,availability,avail,available,169,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:382,availability,down,downstream,382,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:215,deployability,depend,depend,215,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:257,deployability,instal,installed,257,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:349,deployability,build,builds,349,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1083,deployability,version,version,1083,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:44,energy efficiency,current,currently,44,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:774,energy efficiency,current,current,774,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:215,integrability,depend,depend,215,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1083,integrability,version,version,1083,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1647,integrability,wrap,wrapped,1647,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:332,interoperability,architectur,architecture,332,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1351,interoperability,compatib,compatibility,1351,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:215,modifiability,depend,depend,215,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:724,modifiability,pac,package,724,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:754,modifiability,maintain,maintained,754,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1083,modifiability,version,version,1083,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1230,modifiability,paramet,parameters,1230,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:970,performance,perform,performance,970,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:169,reliability,availab,available,169,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:169,safety,avail,available,169,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:215,safety,depend,depend,215,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:754,safety,maintain,maintained,754,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:169,security,availab,available,169,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:215,testability,depend,depend,215,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:310,testability,understand,understand,310,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:970,usability,perform,performance,970,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1113,usability,support,support,1113,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1250,usability,learn,learning,1250,"> I'm not sure what t-SNE implementation is currently used in scanpy, but would it make sense to switch it to openTSNE? It's a Cython re-implementation of FIt-SNE, it's available on conda and should be very easy to depend on. We use `MulticoreTSNE` if it's installed, but fall back to `sklearn`. > As far as I understand the scanpy architecture, it builds a kNN graph and then runs downstream analysis. Right now, we tend to use a connectivity graph built by UMAP, but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. > 1. switch scanpy to using openTSNE for tSNE, using already constructed kNN graph. I think I'd like to see this. That package is much more actively maintained than our current backend, and looks interesting. I would like it if the TSNE was flexible about the graph that was used. I'm not sure that I'll get to this, but a PR would be welcome. I'd have to see some performance/ results before thinking about changing the defaults, or whether this would go into a major or minor version change. > 2. add tSNE support for ingest using openTSNE functionality. @Koncopd do you have any thoughts on this? > 3. change default tSNE parameters (n_iter, learning rate, initialization) following openTSNE defaults. Again, I'd have to think about backwards compatibility. Maybe this could start as a `sc.tl.opentsne` function? > 4. add some tSNE ""recipes"". I'd be interested in this. Skimming that paper now, I really like the idea of showing regions of uncertainty for projection would be very useful. I'd be interested in how these ""recipes"" could be wrapped in a function.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:201,deployability,depend,depend,201,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:201,integrability,depend,depend,201,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:201,modifiability,depend,depend,201,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:179,reliability,doe,does,179,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:201,safety,depend,depend,201,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:406,safety,input,input,406,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:540,safety,input,input,540,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:201,testability,depend,depend,201,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:421,testability,simpl,simple,421,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:267,usability,user,user,267,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:406,usability,input,input,406,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:421,usability,simpl,simple,421,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:445,usability,support,supported,445,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:540,usability,input,input,540,"Thanks! Can I ask for two clarifications before replying:. > Right now, we tend to use a connectivity graph built by UMAP ... UMAP uses Pynndescent to construct the kNN graph. So does it mean that you depend on Pynndescent to construct the kNN graph, and then if the user calls UMAP, it's run on this previously constructred kNN graph? By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy (like Euclidean or cosine). It seems to work quite a bit faster. For sparse input data and/or fancy metrics, it uses Pynndescent. > ... but are working on making this more generic. We're thinking about allowing the UMAP embedding to be generated on graphs we provide as well. What are the use cases here that you thinking of?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:112,deployability,instal,installed,112,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:316,safety,input,input,316,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:331,testability,simpl,simple,331,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:316,usability,input,input,316,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:331,usability,simpl,simple,331,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:355,usability,support,supported,355,"That sounds mostly right. We use the `nearest_neighbors` function from `umap`, which uses `pynndescent` if it's installed. https://github.com/theislab/scanpy/blob/5bc37a2b10f40463f1d90ea1d61dc599bbea2cd0/scanpy/neighbors/__init__.py#L270-L280. > By the way, openTSNE uses Annoy instead of Pynndescent for non-sparse input data and simple metrics that are supported by Annoy. I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. I'm definitely for being more generic about how the neighbors graph is generated and weighted. I haven't seen anything yet which looks at the character of the inaccuracies for each method, something that's probably important when they're used for classification. > What are the use cases here that you thinking of? Mainly cases of merged graphs, like when you have multiple datasets or modalities.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1228,availability,consist,consistent,1228,"comment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1361,availability,slo,slow,1361,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:858,deployability,build,build,858,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1641,deployability,version,version,1641,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1641,integrability,version,version,1641,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1989,integrability,sub,suboptimal,1989,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:330,interoperability,convers,conversation,330,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:633,interoperability,distribut,distributed,633,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1239,interoperability,architectur,architecture,1239,"78379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default w",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1912,interoperability,compatib,compatibility,1912,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:624,modifiability,pac,packaged,624,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:733,modifiability,paramet,parameters,733,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1641,modifiability,version,version,1641,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1721,modifiability,paramet,parameters,1721,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1361,reliability,slo,slow,1361,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:200,security,polic,policar,200,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1781,testability,simpl,simply,1781,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:2154,testability,simpl,simply,2154,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:600,usability,support,supported,600,"> I'm curious about how much the backend changes the runtime and results of nearest neighbors methods. You can see some quick comparisons between Pynndescent and Annoy here: https://github.com/pavlin-policar/openTSNE/issues/101#issuecomment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1228,usability,consist,consistent,1228,"comment-597178379. But I have not investigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init ",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1591,usability,statu,status,1591,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1733,usability,learn,learning,1733,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1781,usability,simpl,simply,1781,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:2154,usability,simpl,simply,2154,"tigated it very thoroughly. Anyway, returning to the main conversation:. I think switching to openTSNE makes sense even if nothing else that we are discussing is implemented. It's A LOT faster than Mutlicore t-SNE for large datasets: https://opentsne.readthedocs.io/en/latest/benchmarks.html. It is also more flexible, actively supported, conveniently packaged/distributed, etc. I don't see any possible disadvantage. You could potentially keep all the default parameters as you have now in scanpy (even though I would not recommend it, see below). However, what I said about using pre-build kNN graph requires some thinking. T-SNE uses perplexity=30 by default and uses kNN graph with k=3*perplexity, so that's 90 by default. UMAP uses k=15 and that's what you use in scanpy by default too. I can see three options here:. i) Let openTSNE do its own thing and ignore the kNN graph built in scanpy. Advantage: that's what you do now. Disadvantage: not very consistent architecture IMHO. . ii) Use the kNN graph built in scanpy and query() it to get 90 neighbors. Disadvantage: can be a bit slow. But I think it's better than (i). iii) Run t-SNE using 15 neighbors. Turns out, t-SNE with uniform affinities across 15 neigbours is *extremely* similar to t-SNE with perplexity 30. Evidence: https://twitter.com/hippopedoid/status/1232698023253303298. So you could run this version of t-SNE with uniform kernel. This will be very fast. Regarding default parameters: learning rate = 1000 that you use by default is simply not enough for large data (sample size in millions), as shown in that Nat Comms paper in detail. If you want to keep it for compatibility reasons, that's your choice, but be aware that you are getting suboptimal tSNE embeddings. The same about initialization: UMAP smartly uses Laplacian Eigenmaps to initialize, but sklearn/multicore tSNE use random init, which is simply a bad choice (as again shown in that paper). openTSNE now uses PCA init by default which is much more sensible.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:558,availability,cluster,clustering,558,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1358,availability,cluster,clustering,1358,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1561,availability,cluster,clustering,1561,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,deployability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:354,deployability,depend,dependency,354,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:558,deployability,cluster,clustering,558,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1358,deployability,cluster,clustering,1358,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1561,deployability,cluster,clustering,1561,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1193,energy efficiency,current,currently,1193,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,integrability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:354,integrability,depend,dependency,354,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1346,integrability,Graph-bas,Graph-based,1346,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,interoperability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,modifiability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:303,modifiability,pac,package,303,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:354,modifiability,depend,dependency,354,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,reliability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:971,reliability,doe,does,971,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:354,safety,depend,dependency,354,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,security,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:38,testability,Integr,Integrating,38,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:354,testability,depend,dependency,354,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:909,usability,close,close,909,"Glad to see this discussion going on. Integrating openTSNE into scanpy should be fairly straightforward but may require some thought. I think Dmitry has already pointed out the most important things such as improved defaults, which other t-SNE implementations are lagging behind in. Apart from that, we package prebuilt binaries, so adding openTSNE as a dependency would be incredibly easy. The main thing we'd have to agree on is how to deal with the KNN graphs. UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. t-SNE, on the other hand, calculates 90 nearest neighbors by default. This is every single t-SNE implementation, not just openTSNE. Dmitry suggested using a uniform kernel with 15 neighbors, which would fit elegantly, but then again, this isn't truly t-SNE anymore, but rather something very close. The same goes for the `ingest` functionality. openTSNE does something similar to UMAP for adding new samples to existing embeddings, and then we'd again have to figure out how to calculate nearest neighbors from the new data to the reference data. I don't know how you do this currently for UMAP. I'm not exactly sure how these neighbors are meant to be used in scanpy, since there are several different algorithms that use them. Graph-based clustering uses the KNNG, UMAP uses it, forceatlas2 uses it, PAGA probably as well? Is relying on a single k=15 from UMAP for everything really ok? For example, seurat defaults to using 30 neighbors for clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:96,availability,cluster,clustering,96,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:169,availability,cluster,clustering,169,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:872,availability,consist,consistency,872,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1100,availability,cluster,clustering,1100,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:96,deployability,cluster,clustering,96,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:169,deployability,cluster,clustering,169,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1100,deployability,cluster,clustering,1100,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:340,reliability,doe,does,340,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:888,testability,simpl,simplicity,888,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:843,usability,user,user,843,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:872,usability,consist,consistency,872,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:888,usability,simpl,simplicity,888,"> UMAP by default calculates 15 nearest neighbors, and from what I can tell, louvain and leiden clustering both use those 15 neighbors as well by default. Both of those clustering algorithms just use whatever graph is passed, so this shouldn't be an issue. > t-SNE, on the other hand, calculates 90 nearest neighbors by default. > openTSNE does something similar to UMAP for adding new samples to existing embeddings. Could there just be a separate function for computing neighbors for tsne? `sc.pp.neighbors` can be considered to be ""compute nearest neighbors and connectivity as expected by UMAP"", while a separate function could use methods and defaults appropriate to openTSNE. @Koncopd would have more to say on how this should work w.r.t. `ingest`. > Is relying on a single k=15 from UMAP for everything really ok? Ultimately, up to the user. There is an element of consistency and simplicity to using the same representation of the data for multiple parts of the analysis. I think there would have to be a good reason for using a different connectivity matrix for the 2d embedding and for the clustering.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:376,availability,cluster,clustering,376,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:458,availability,consist,consistent,458,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1348,availability,avail,available,1348,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:376,deployability,cluster,clustering,376,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:355,energy efficiency,reduc,reduction,355,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:189,integrability,topic,topics,189,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:261,interoperability,architectur,architecture,261,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1222,interoperability,standard,standard,1222,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1333,interoperability,standard,standard,1333,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1775,interoperability,standard,standard,1775,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1361,modifiability,exten,extending,1361,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1283,performance,time,times,1283,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1348,reliability,availab,available,1348,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1790,reliability,doe,does,1790,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1348,safety,avail,available,1348,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:18,security,polic,policar,18,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1348,security,availab,available,1348,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:458,usability,consist,consistent,458,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1119,usability,close,close,1119,"@ivirshup @pavlin-policar I'd like to get back to this issue. I think maybe we should postpone discussing `ingest` until later (as well as ""recipes"" based on our Nat Comms paper, and other topics raised above) and focus on switching to openTSNE first. Scanpy's architecture is to compute kNN graph by calling `sc.pp.neighbors` and then run dimensionality reduction (UMAP) and clustering (Leiden) on this graph. I think this is very neat and makes everything consistent and other functions should follow this approach as much as possible. So IMHO if it's possible to run t-SNE on the kNN graph with k=15, then that's what we should do. And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is *very* similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. Admittedly, this is not the ""vanilla"" t-SNE. But it's very close. And I think advantages outweigh the disadvantages. Actually this is quite a bit faster than the standard t-SNE, because it only uses k=15 instead of k=90 (3 times perplexity=30). Moreover, we could make the standard t-SNE available by extending `sc.pp.neighors` with `method=""tsne""` (there are several `method`s there already). What I mean is that . ```. sc.pp.neighors(). sc.tl.tsne(). ```. would use let's say uniform kernel on k=15 kNN neighbor graph (and maybe print a warning about it, but I am not even sure it's needed), while. ```. sc.pp.neighbors(method=""tsne"", perplexity=30). sc.tl.tsne(). ```. would construct k=90 weighted kNN graph as standard t-SNE does and then use that. Either way, `sc.tl.tsne()` runs openTSNE with the pre-defined affinity matrix. Thoughts?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1452,availability,avail,available,1452,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:183,deployability,modul,module,183,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:214,interoperability,standard,standard,214,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1437,interoperability,standard,standard,1437,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1941,interoperability,share,shared,1941,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:2006,interoperability,standard,standard,2006,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:183,modifiability,modul,module,183,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1465,modifiability,exten,extending,1465,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1452,reliability,availab,available,1452,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:183,safety,modul,module,183,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1452,safety,avail,available,1452,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1452,security,availab,available,1452,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:759,testability,understand,understand,759,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:1560,testability,understand,understand,1560,"itch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty much the standard thing to do in single-cell analysis.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:737,usability,prefer,prefer,737,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:938,usability,behavi,behaviour,938,"I think it would make a lot of sense to at least switch the t-SNE implementation to openTSNE at the very least. For the recipes, there' already something similar in the preprocessing module. So I'd imagine calling standard t-SNE with `sc.tl.tsne` and the recipes like `sc.tl.tsne.recipe_multiscale`. > And luckily it is possible! I can even see two approaches. (1) Either use k=15 kNN graph with the uniform similarity kernel. As I said, and as Pavlin knows, this yields result that is very similar to using perplexity=30. (2) Or use k=15 kNN graph with UMAP weights, normalize it as t-SNE expects it to be normalized and use that. My expectation is that it would yield very similar results, but I haven't actually tried it. I very much prefer option 1. If I understand option 2 correctly, we would normalize the 15 neighbors to essentially `perplexity=5`. I've never once found a case where that is useful, so having this as the default behaviour in scanpy seems like a really bad idea (I foresee a lot of issues in the style ""why is t-SNE not working?""). Using a uniform kernel produces results that are virtually indistinguishable from vanilla t-SNE, so that's fine IMO, and it's faster as well. It's still less than the default `perplexity=30`, but this seems like the best option. Whatever we agree on, the same can be applied to the ingest functionality, so adding that would also be straightforward. > Moreover, we could make the standard t-SNE available by extending sc.pp.neighors with method=""tsne"" (there are several methods there already). I don't understand this, why would this belong on `sc.pp.neighbors`? The graph weighing should go into the `sc.tl.tsne` call. Are the UMAP weights assigned to the graph in `sc.pp.neighbors`? That seems questionable. I would expect the output to be a directed, unweighted graph, and let each method take care of the graph. If anything, I'd expect it to weight it using the Jaccard index of shared nearest neighbors, which seems to me like pretty muc",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:288,deployability,api,api,288,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:463,energy efficiency,adapt,adaptive,463,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:590,energy efficiency,GPU,GPU,590,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:288,integrability,api,api,288,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:463,integrability,adapt,adaptive,463,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:288,interoperability,api,api,288,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:463,interoperability,adapt,adaptive,463,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:463,modifiability,adapt,adaptive,463,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:590,performance,GPU,GPU,590,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:10,testability,understand,understand,10,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:203,testability,understand,understanding,203,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:613,testability,understand,understand,613,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:859,usability,prefer,prefer,859,"> I don't understand this, why would this belong on sc.pp.neighbors? The graph weighing should go into the sc.tl.tsne call. Are the UMAP weights assigned to the graph in sc.pp.neighbors? Yes, this is my understanding of how it works in scanpy. See https://scanpy.readthedocs.io/en/stable/api/scanpy.pp.neighbors.html:. ```. method : {umap, gauss, rapids}, None (default: 'umap'). Use umap [McInnes18] or gauss (Gauss kernel following [Coifman05] with . adaptive width [Haghverdi16]) for computing connectivities. Use rapids for the. RAPIDS implementation of UMAP (experimental, GPU only). ```. > If I understand option 2 correctly, we would normalize the 15 neighbors to essentially perplexity=5. That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:104,reliability,doe,does,104,"> Yes, this is my understanding of how it works in scanpy. Thinking about this a bit further, yes, that does make perfect sense. I suppose we'd want to add a ""tsne"" option there as well then. > That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid. I see now and I completely agree with you: I don't really like this. This would then be some strange mesh between UMAP and t-SNE. It feels messy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:449,safety,compl,completely,449,"> Yes, this is my understanding of how it works in scanpy. Thinking about this a bit further, yes, that does make perfect sense. I suppose we'd want to add a ""tsne"" option there as well then. > That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid. I see now and I completely agree with you: I don't really like this. This would then be some strange mesh between UMAP and t-SNE. It feels messy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:449,security,compl,completely,449,"> Yes, this is my understanding of how it works in scanpy. Thinking about this a bit further, yes, that does make perfect sense. I suppose we'd want to add a ""tsne"" option there as well then. > That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid. I see now and I completely agree with you: I don't really like this. This would then be some strange mesh between UMAP and t-SNE. It feels messy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:18,testability,understand,understanding,18,"> Yes, this is my understanding of how it works in scanpy. Thinking about this a bit further, yes, that does make perfect sense. I suppose we'd want to add a ""tsne"" option there as well then. > That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid. I see now and I completely agree with you: I don't really like this. This would then be some strange mesh between UMAP and t-SNE. It feels messy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1233:344,usability,prefer,prefer,344,"> Yes, this is my understanding of how it works in scanpy. Thinking about this a bit further, yes, that does make perfect sense. I suppose we'd want to add a ""tsne"" option there as well then. > That's not what I meant. I meant taking UMAP's weights for k=15 and normalizing the matrix so that it sums to 1, as in t-SNE. That said, I would also prefer option 1 because I don't want anything that sounds like it's a UMAP/t-SNE hybrid. I see now and I completely agree with you: I don't really like this. This would then be some strange mesh between UMAP and t-SNE. It feels messy.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1233
https://github.com/scverse/scanpy/issues/1235:15,deployability,updat,update,15,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:141,energy efficiency,heat,heatmap,141,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:230,energy efficiency,heat,heatmap,230,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:15,safety,updat,update,15,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:15,security,updat,update,15,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1235:486,usability,user,user-images,486,"I just made an update in the PR #1210 that will solve the issue. Now you can do:. ```PYTHON. adata = sc.datasets.pbmc68k_reduced(). # make a heatmap with all the 765 genes in the dataset, highlight each 50th gene. ax_dict = sc.pl.heatmap(adata, adata.var_names, groupby='louvain', show=False, show_gene_labels=True, figsize=(7,4)). ax_dict['heatmap_ax'].set_xticks(range(len(adata.var_names))[::50]). ax_dict['heatmap_ax'].set_xticklabels(adata.var_names[::50]) . ```. ![image](https://user-images.githubusercontent.com/4964309/85733220-4db5df00-b6fc-11ea-9c5c-d657ebb136c8.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1235
https://github.com/scverse/scanpy/issues/1237:44,deployability,updat,updated,44,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:76,deployability,version,version,76,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:154,deployability,version,versions,154,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:76,integrability,version,version,76,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:154,integrability,version,versions,154,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:76,modifiability,version,version,76,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:154,modifiability,version,versions,154,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:44,safety,updat,updated,44,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:44,security,updat,updated,44,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:254,usability,learn,learn,254,I am facing the same issue. I have recently updated my scanpy to the latest version. I think that it was working before that. Here is rest of my software versions. scanpy==1.4.6 anndata==0.7.1 umap==0.3.9 numpy==1.17.4 scipy==1.3.1 pandas==0.25.3 scikit-learn==0.22 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1237:138,deployability,releas,release,138,@gokceneraslan . A fix is provided here https://github.com/theislab/scanpy/pull/1245. In the meanwhile until this PR is merged into a new release you can follow this https://github.com/dpeerlab/Palantir/issues/34#issuecomment-632933449,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1237
https://github.com/scverse/scanpy/issues/1239:111,availability,down,downstream,111,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:138,availability,cluster,clustering,138,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:138,deployability,cluster,clustering,138,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:46,reliability,doe,doesn,46,"I found that after doing deep copy, sc.tl.pca doesn't change the PC values in the object, which may affect the downstream umap and Leiden clustering. . But why? I thought a deep copied object was supposed to behave the same as the non-deep copy one.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:25,deployability,modul,module,25,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:507,deployability,releas,release,507,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:75,energy efficiency,current,currently,75,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:25,modifiability,modul,module,25,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:215,performance,perform,performs,215,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:540,reliability,doe,does,540,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:25,safety,modul,module,25,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:215,usability,perform,performs,215,"Copying using the `copy` module is a bit ill defined for `AnnData` objects currently. This has to do with some internals of how we do views of arrays. In general I'd recommend doing copies via `adata.copy()`, which performs a deep copy. But it looks like there might be another problem with the PCA not being exactly reproducible. After a fair amount of checking that it was exactly reproducible, it looks like we forgot to actually pass the random seed... There has been fixed, and there will be a bug-fix release soon (#1240). This still does not fix the issue of reproducibility if you've made a shallow copy of a AnnData view with `copy`. I'll have to look into this a bit more.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:4,deployability,releas,release,4,The release with PCA bug fix is now on pypi,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:118,deployability,updat,updated,118,Hmm. Did your original object already have a pca computed on it? I'm not sure if the values in `obsm` would have been updated when you made a shallow copy with `copy`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:118,safety,updat,updated,118,Hmm. Did your original object already have a pca computed on it? I'm not sure if the values in `obsm` would have been updated when you made a shallow copy with `copy`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:118,security,updat,updated,118,Hmm. Did your original object already have a pca computed on it? I'm not sure if the values in `obsm` would have been updated when you made a shallow copy with `copy`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:177,deployability,observ,observations,177,I am having a similar issue.I try to copy the AnnData object with adata.copy() but it tells me . TypeError: cannot unpack non-iterable NoneType object. I would like to copy the observations that match a criteria. . adata_subset[i] = adata[adata.obs['column']==i].copy(). Any advice?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:177,testability,observ,observations,177,I am having a similar issue.I try to copy the AnnData object with adata.copy() but it tells me . TypeError: cannot unpack non-iterable NoneType object. I would like to copy the observations that match a criteria. . adata_subset[i] = adata[adata.obs['column']==i].copy(). Any advice?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:92,deployability,version,versions,92,"@mariaasierra could you open a new issue for this on the anndata repo? A full traceback and versions of software would also be useful. I'm going to close this issue since it's quite old, I believe should be solved, and I think unrelated to what @mariaasierra is seeing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:92,integrability,version,versions,92,"@mariaasierra could you open a new issue for this on the anndata repo? A full traceback and versions of software would also be useful. I'm going to close this issue since it's quite old, I believe should be solved, and I think unrelated to what @mariaasierra is seeing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:92,modifiability,version,versions,92,"@mariaasierra could you open a new issue for this on the anndata repo? A full traceback and versions of software would also be useful. I'm going to close this issue since it's quite old, I believe should be solved, and I think unrelated to what @mariaasierra is seeing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:78,testability,trace,traceback,78,"@mariaasierra could you open a new issue for this on the anndata repo? A full traceback and versions of software would also be useful. I'm going to close this issue since it's quite old, I believe should be solved, and I think unrelated to what @mariaasierra is seeing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/issues/1239:148,usability,close,close,148,"@mariaasierra could you open a new issue for this on the anndata repo? A full traceback and versions of software would also be useful. I'm going to close this issue since it's quite old, I believe should be solved, and I think unrelated to what @mariaasierra is seeing.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1239
https://github.com/scverse/scanpy/pull/1240:23,performance,time,time,23,"To limit the amount of time we have to wait for rebuilding, I've added the change from #1236 here",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1240
https://github.com/scverse/scanpy/pull/1241:0,availability,Ping,Ping,0,Ping @flying-sheep,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:25,availability,failur,failure,25,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:19,deployability,build,build,19,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:25,deployability,fail,failure,25,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:70,deployability,fail,fails,70,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:197,deployability,updat,update,197,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:25,performance,failur,failure,25,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:25,reliability,fail,failure,25,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:70,reliability,fail,fails,70,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:197,safety,updat,update,197,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:197,security,updat,update,197,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:103,usability,document,documented,103,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/pull/1241:258,usability,document,documented,258,"can you link a doc build failure, please? Then I can check out why it fails. I assume they changed the documented location of the class. We have it in `qualname_overrides` and should probably just update the location there (or remove it that line if the new documented location now matches the qualified name). https://github.com/theislab/scanpy/blob/e5d246aacc71fb9ed71d49e2e7d5e26743fd4acb/docs/conf.py#L136-L140",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1241
https://github.com/scverse/scanpy/issues/1242:108,availability,slo,slower,108,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:82,deployability,instal,installed,82,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:306,deployability,instal,install,306,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:98,reliability,doe,does,98,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:108,reliability,slo,slower,108,@icml-compbio The `draw_graph` function calls out to `forceatlas2` if you have it installed. This does seem slower than using UMAP. @YubinXie I see some multithreading being used on my machine when I run `neighbors`. Is there none on yours? One thing I'd check first is to make sure UMAP is up to date and install `pynndescent`.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:81,deployability,releas,release,81,"Ah, my bad, I read the path wrong on my phone. In general, the most recent numba release cycle had a lot of deprecations, so many packages are throwing numba warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:130,modifiability,pac,packages,130,"Ah, my bad, I read the path wrong on my phone. In general, the most recent numba release cycle had a lot of deprecations, so many packages are throwing numba warnings.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:27,availability,slo,slower,27,`sc.tl.draw_graph` is much slower than UMAP. 20 mins for 67k cells does not surprise me. draw_graph uses by default https://github.com/bhargavchippada/forceatlas2 You may want to search in that package if computations can be speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:194,modifiability,pac,package,194,`sc.tl.draw_graph` is much slower than UMAP. 20 mins for 67k cells does not surprise me. draw_graph uses by default https://github.com/bhargavchippada/forceatlas2 You may want to search in that package if computations can be speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:27,reliability,slo,slower,27,`sc.tl.draw_graph` is much slower than UMAP. 20 mins for 67k cells does not surprise me. draw_graph uses by default https://github.com/bhargavchippada/forceatlas2 You may want to search in that package if computations can be speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:67,reliability,doe,does,67,`sc.tl.draw_graph` is much slower than UMAP. 20 mins for 67k cells does not surprise me. draw_graph uses by default https://github.com/bhargavchippada/forceatlas2 You may want to search in that package if computations can be speed up.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1242:8,usability,close,close,8,"We will close the issue for now, as based on the provided information and the discussion so far, it seems that the question has been addressed and hopefully useful insights obtained :). However, please don't hesitate to reopen this issue or create a new one if you have any more questions or run into any related problems in the future. Thanks for being a part of our community! :)",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1242
https://github.com/scverse/scanpy/issues/1243:31,deployability,instal,installation,31,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:65,deployability,instal,install,65,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:190,deployability,instal,installations,190,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:278,deployability,instal,installation,278,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:326,deployability,instal,installing,326,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:352,deployability,Instal,Installing,352,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:392,deployability,instal,install,392,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:455,deployability,instal,install,455,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:546,deployability,instal,installation,546,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:594,deployability,instal,installing,594,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:620,deployability,Instal,Installing,620,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:660,deployability,instal,install,660,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:23,energy efficiency,current,current,23,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:730,modifiability,pac,packages,730,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:159,reliability,pra,practice,159,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1243:415,usability,learn,learn,415,"What is wrong with the current installation instructions? `conda install -c conda-forge python-igraph leidenalg`. Is python-igraph not required? It's also bad practice to mix Conda and PyPI installations (yes it works). . What about changing:. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install seaborn scikit-learn statsmodels numba pytables. conda install -c conda-forge python-igraph leidenalg. ```. to. ```. If you do not have a working installation of Python 3.6 (or later), consider installing Miniconda (see Installing Miniconda). Then run:. conda install -c conda-forge scanpy python-igraph leidenalg. ```. The other packages are already included in the recipe: https://bioconda.github.io/recipes/scanpy/README.html.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1243
https://github.com/scverse/scanpy/issues/1246:50,deployability,version,version,50,Thanks for the bug report! Could you include some version information about your environment?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:50,integrability,version,version,50,Thanks for the bug report! Could you include some version information about your environment?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:50,modifiability,version,version,50,Thanks for the bug report! Could you include some version information about your environment?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:23,deployability,version,version,23,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:42,deployability,log,logging,42,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:23,integrability,version,version,23,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:23,modifiability,version,version,23,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:42,safety,log,logging,42,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:42,security,log,logging,42,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:42,testability,log,logging,42,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:165,usability,learn,learn,165,OS: Windows 10. Python version: 3.7.7. sc.logging.print_versions() gives. scanpy==1.5.1 anndata==0.7.1 umap==0.3.10 numpy==1.18.4 scipy==1.3.1 pandas==0.25.1 scikit-learn==0.21.3 statsmodels==0.10.1 python-igraph==0.7.1 louvain==0.6.1 leidenalg==0.7.0,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:15,deployability,upgrad,upgrade,15,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:26,deployability,version,version,26,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:26,integrability,version,version,26,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:15,modifiability,upgrad,upgrade,15,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:26,modifiability,version,version,26,"Maybe it's the upgrade to version 1.5.1 that leads to this bug, I can run this piece of code under 1.4.6.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:29,deployability,updat,update,29,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:40,deployability,depend,dependency,40,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:40,integrability,depend,dependency,40,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:40,modifiability,depend,dependency,40,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:29,safety,updat,update,29,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:40,safety,depend,dependency,40,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:29,security,updat,update,29,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/issues/1246:40,testability,depend,dependency,40,"Yes, it looks like we didn't update our dependency requirements correctly. It looks like the `rmatmat` argument for `LinearOperators` was only added as of `1.4`. I believe using `scanpy 1.5.1` with `scipy>1.4` should fix this. Could you let me know if that solves your problem?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1246
https://github.com/scverse/scanpy/pull/1247:83,deployability,updat,update,83,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:129,deployability,pipelin,pipelines,129,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:192,deployability,releas,release,192,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:129,integrability,pipelin,pipelines,129,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:90,modifiability,pac,packages,90,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:83,safety,updat,update,83,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1247:83,security,updat,update,83,"I think it's very likely people will hit this bug, because 1) they typically don't update packages like scipy very often 2) most pipelines use sparse datasets + PCA. I think it deserves a new release.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1247
https://github.com/scverse/scanpy/pull/1248:149,deployability,contain,contain,149,"Hi, @awnimo , sorry for the delay. It seems that this PR breaks test_harmony_timeseries.py. I get . ```. E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError. ```. On master the test works fine. Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:140,reliability,doe,does,140,"Hi, @awnimo , sorry for the delay. It seems that this PR breaks test_harmony_timeseries.py. I get . ```. E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError. ```. On master the test works fine. Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:252,safety,test,test,252,"Hi, @awnimo , sorry for the delay. It seems that this PR breaks test_harmony_timeseries.py. I get . ```. E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError. ```. On master the test works fine. Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:252,testability,test,test,252,"Hi, @awnimo , sorry for the delay. It seems that this PR breaks test_harmony_timeseries.py. I get . ```. E ValueError: 'time_points' column does not contain Categorical data. ../../external/tl/_harmony_timeseries.py:140: ValueError. ```. On master the test works fine. Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:19,availability,error,error,19,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:313,deployability,contain,contain,313,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:19,performance,error,error,19,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:304,reliability,doe,does,304,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:19,safety,error,error,19,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:430,safety,test,test,430,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:430,testability,test,test,430,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1248:19,usability,error,error,19,"Hi @Koncopd ,. The error fixed here [df8bbaf](https://github.com/theislab/scanpy/pull/1248/commits/df8bbaf5ffb58eb37d4b80ef62819f69b8fce023). Thank you! > Hi, @awnimo , sorry for the delay. > It seems that this PR breaks test_harmony_timeseries.py. I get. > . > ```. > E ValueError: 'time_points' column does not contain Categorical data. > . > ../../external/tl/_harmony_timeseries.py:140: ValueError. > ```. > . > On master the test works fine. > Could you check and fix this?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1248
https://github.com/scverse/scanpy/pull/1250:56,reliability,doe,doesn,56,"No idea... I'm afraid people do it manually because GEO doesn't allow directories (ever heard of zip files, man?) . I've already seen both the `prefix.matrix.mtx.gz` and `prefix_matrix.mtx.gz` variants...",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:218,deployability,pipelin,pipelines,218,"Good point @ivirshup , by just asking around a bit it seems that no, that's not the case and it seems there is no prefix. From the space ranger [output](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview) it seems there shouldn't be such prefix added. However, to be honest not super confident that this is not gonna happen in the future, since so far there are not do many visum datasets around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:218,integrability,pipelin,pipelines,218,"Good point @ivirshup , by just asking around a bit it seems that no, that's not the case and it seems there is no prefix. From the space ranger [output](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview) it seems there shouldn't be such prefix added. However, to be honest not super confident that this is not gonna happen in the future, since so far there are not do many visum datasets around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:161,usability,support,support,161,"Good point @ivirshup , by just asking around a bit it seems that no, that's not the case and it seems there is no prefix. From the space ranger [output](https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview) it seems there shouldn't be such prefix added. However, to be honest not super confident that this is not gonna happen in the future, since so far there are not do many visum datasets around.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:7,energy efficiency,Cool,Cool,7,"@giovp Cool, thanks for checking that out! @grst No need to add anything to `read_visium`. This argument can be added there later if it comes up.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:15,safety,test,tests,15,"@ivirshup, the tests now copies the prefix data into a temp dir.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/pull/1250:15,testability,test,tests,15,"@ivirshup, the tests now copies the prefix data into a temp dir.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1250
https://github.com/scverse/scanpy/issues/1251:28,deployability,log,log,28,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:44,performance,perform,performed,44,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:28,safety,log,log,28,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:28,security,log,log,28,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:28,testability,log,log,28,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:44,usability,perform,performed,44,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1251:198,usability,close,close,198,you can check here that the log is actually performed as you suggest: https://github.com/theislab/scanpy/blob/5533b644e796379fd146bf8e659fd49f92f718cd/scanpy/preprocessing/_recipes.py#L66-L95. I'll close this for now.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1251
https://github.com/scverse/scanpy/issues/1252:10,deployability,updat,update,10,Could you update your scipy with `pip install -U scipy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:38,deployability,instal,install,38,Could you update your scipy with `pip install -U scipy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:10,safety,updat,update,10,Could you update your scipy with `pip install -U scipy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:10,security,updat,update,10,Could you update your scipy with `pip install -U scipy`?,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:38,deployability,version,version,38,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:70,deployability,log,logging,70,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:110,deployability,version,version,110,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:165,deployability,version,version,165,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:173,deployability,instal,installed,173,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:38,integrability,version,version,38,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:110,integrability,version,version,110,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:165,integrability,version,version,165,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:38,modifiability,version,version,38,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:110,modifiability,version,version,110,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:165,modifiability,version,version,165,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:70,safety,log,logging,70,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:70,security,log,logging,70,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:70,testability,log,logging,70,When I do this it tells me I am using version 1.4.1 but when I run sc.logging.print_versions() it comes up as version 1.01. I assumed this is somehow related to the version installed with scanpy that it uses by default maybe? But I feel I am not proficient enough in python to determine that,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:29,deployability,instal,installing,29,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:210,deployability,updat,updating,210,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:323,deployability,instal,installed,323,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:210,safety,updat,updating,210,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:146,security,session,session,146,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:196,security,session,session,196,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:210,security,updat,updating,210,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:283,usability,command,commands,283,"Huh. It sounds like `pip` is installing to a different environment than the one you're using for scanpy. How are you starting the relevant python session? Also, are you sure you're restarted that session after updating scipy? To check to see if you're in the same environment, these commands should tell you where scipy is installed:. ```sh. pip show scipy. python -c ""import scipy; print(scipy.__file__)"". ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:474,availability,avail,available,474,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1344,availability,avail,available,1344,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:49,deployability,Version,Version,49,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:434,deployability,version,version,434,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:456,deployability,version,version,456,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:505,deployability,upgrad,upgrading,505,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:528,deployability,instal,install,528,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:538,deployability,upgrad,upgrade,538,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:610,deployability,Version,Version,610,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1094,deployability,api,api-wrap,1094,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1304,deployability,version,version,1304,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1326,deployability,version,version,1326,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1375,deployability,upgrad,upgrading,1375,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1398,deployability,instal,install,1398,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1408,deployability,upgrad,upgrade,1408,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1449,deployability,instal,install,1449,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1708,deployability,instal,install,1708,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1757,deployability,updat,updated,1757,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1765,deployability,version,version,1765,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1796,deployability,log,logging,1796,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1852,deployability,version,version,1852,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1927,deployability,version,version,1927,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1994,deployability,version,version,1994,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:49,integrability,Version,Version,49,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:434,integrability,version,version,434,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:456,integrability,version,version,456,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:610,integrability,Version,Version,610,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1094,integrability,api,api-wrap,1094,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1304,integrability,version,version,1304,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1326,integrability,version,version,1326,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1765,integrability,version,version,1765,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1852,integrability,version,version,1852,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1927,integrability,version,version,1927,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1994,integrability,version,version,1994,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1094,interoperability,api,api-wrap,1094,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:49,modifiability,Version,Version,49,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:243,modifiability,pac,packages,243,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:434,modifiability,version,version,434,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:456,modifiability,version,version,456,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:505,modifiability,upgrad,upgrading,505,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:538,modifiability,upgrad,upgrade,538,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:610,modifiability,Version,Version,610,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1042,modifiability,pac,packages,1042,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1062,modifiability,pac,packaging,1062,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1304,modifiability,version,version,1304,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1326,modifiability,version,version,1326,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1375,modifiability,upgrad,upgrading,1375,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1408,modifiability,upgrad,upgrade,1408,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1625,modifiability,pac,package,1625,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1765,modifiability,version,version,1765,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1852,modifiability,version,version,1852,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1927,modifiability,version,version,1927,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1994,modifiability,version,version,1994,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1181,performance,network,networkx,1181,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:474,reliability,availab,available,474,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1344,reliability,availab,available,1344,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1658,reliability,doe,doesn,1658,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:7,safety,input,input,7,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:474,safety,avail,available,474,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1344,safety,avail,available,1344,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1757,safety,updat,updated,1757,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1796,safety,log,logging,1796,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:146,security,Auth,Author,146,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:160,security,Auth,Author-email,160,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:474,security,availab,available,474,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:713,security,Auth,Author,713,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:906,security,Auth,Author-email,906,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1181,security,network,networkx,1181,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1344,security,availab,available,1344,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1489,security,session,session,1489,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1757,security,updat,updated,1757,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1796,security,log,logging,1796,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1796,testability,log,logging,1796,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:7,usability,input,input,7,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:288,usability,learn,learn,288,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:315,usability,learn,learn,315,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:551,usability,command,command,551,"When I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct versio",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1221,usability,learn,learn,1221,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1235,usability,learn,learn,1235,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1421,usability,command,command,1421,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1466,usability,user,user,1466,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:1727,usability,user,user,1727,"en I input pip show scipy I get:. Name: scipy. Version: 1.4.1. Summary: SciPy: Scientific Library for Python. Home-page: https://www.scipy.org. Author: None. Author-email: None. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: numpy. Required-by: umap-learn, statsmodels, scikit-learn, scanpy, xgboost, seaborn, mnnpy, loompy, Keras, Keras-Preprocessing, ggplot, gensim, anndata. You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. Typing in pip show scanpy returns:. Name: scanpy. Version: 1.5.1. Summary: Single-Cell Analysis in Python. Home-page: http://github.com/theislab/scanpy. Author: Alex Wolf, Philipp Angerer, Fidel Ramirez, Isaac Virshup, Sergei Rybakov, Gokcen Eraslan, Tom White, Malte Luecken, Davide Cittaro, Tobias Callies, Marius Lange, Andrs R. Muoz-Rojas. Author-email: f.alex.wolf@gmx.de, philipp.angerer@helmholtz-muenchen.de. License: BSD. Location: /home/ubuntu/.local/lib/python3.6/site-packages. Requires: packaging, h5py, joblib, legacy-api-wrap, tqdm, seaborn, setuptools-scm, statsmodels, numba, matplotlib, scipy, patsy, networkx, tables, natsort, pandas, umap-learn, scikit-learn, importlib-metadata, anndata. Required-by: . You are using pip version 18.0, however version 20.2b1 is available. You should consider upgrading via the 'pip install --upgrade pip' command. I have to use !pip install scanpy --user. when starting my session to have it work properly so I thought maybe it was an issue of being in a different directory but based on the location of each package when I look them up that doesn't appear to be the case? I tried using !pip install scipy -U --user but it tells me that the updated version is already present. sc.logging.print_versions() still shows scipy 1.0.1 as the version so I'm a bit confused. Is scanpy somehow defaulting to a different version for some reason? Is there a way to make it use the correct version?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:395,availability,state,state,395,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:27,deployability,instal,install,27,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:136,deployability,instal,installing,136,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:424,deployability,instal,installed,424,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:503,deployability,instal,installed,503,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:395,integrability,state,state,395,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:459,modifiability,pac,packages,459,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:58,security,session,session,58,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:305,testability,trace,traceback,305,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:44,usability,user,user,44,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:178,usability,help,help,178,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:442,usability,user,user,442,"That you are calling `!pip install scanpy --user` in your session definitely suggest you are not using the same environment as you were installing to before. I don't think I can help too much with this, since it sounds like there are some deeper problems with your python environment. Looking back at the traceback from your previous example, it looks like your environment is in a very strange state. You're using `scanpy` installed to your user python site packages, but importing `scipy` that's been installed via `conda`. If I were you, I think I would just try uninstalling everything and starting a new environment from scratch, possibly all through `conda`.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:227,availability,error,error,227,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:74,deployability,instal,installed,74,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:89,deployability,instal,installing,89,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:112,deployability,Instal,Installing,112,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:170,deployability,instal,install,170,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:291,deployability,instal,installed,291,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:233,integrability,messag,message,233,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:233,interoperability,messag,message,233,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:227,performance,error,error,227,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:136,safety,prevent,prevented,136,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:227,safety,error,error,227,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:136,security,preven,prevented,136,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:180,usability,user,user,180,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:227,usability,error,error,227,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:452,usability,user,user,452,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:549,usability,help,help,549,It appears this was an issue related to anndata2ri- scipy 1.0.1 was being installed when installing anndata2ri. Installing scanpy first prevented this issue. . I use pip install --user for scanpy because otherwise I receive an error message: . Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall. My workaround has been to use --user as a directory and add a path to import scanpy. I'm sorry for the trouble thank you for the help.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:974,availability,error,error,974,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:39,modifiability,pac,packages,39,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:148,modifiability,pac,packages,148,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:285,modifiability,pac,packages,285,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:406,modifiability,pac,packages,406,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:531,modifiability,pac,packages,531,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:422,performance,memor,memory,422,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:974,performance,error,error,974,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:974,safety,error,error,974,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:9,usability,User,Users,9,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:118,usability,User,Users,118,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:255,usability,User,Users,255,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:376,usability,User,Users,376,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:422,usability,memor,memory,422,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:501,usability,User,Users,501,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1252:974,usability,error,error,974,"File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 941, in fit_predict. self.fit(X). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 919, in fit. self._min_spanning_tree) = hdbscan(X, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 615, in hdbscan. core_dist_n_jobs, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\joblib\memory.py"", line 352, in __call__. return self.func(*args, **kwargs). File ""C:\Users\Reda\Anaconda3\lib\site-packages\hdbscan\hdbscan_.py"", line 274, in _hdbscan_boruvka_kdtree. tree = KDTree(X, metric=metric, leaf_size=leaf_size, **kwargs). File ""sklearn\neighbors\_binary_tree.pxi"", line 1061, in sklearn.neighbors._kd_tree.BinaryTree.__init__. File ""sklearn\neighbors\_dist_metrics.pyx"", line 289, in sklearn.neighbors._dist_metrics.DistanceMetric.get_metric. TypeError: __init__() got an unexpected keyword argument 'check_pickle'. How to fix this error?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1252
https://github.com/scverse/scanpy/issues/1254:214,deployability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,deployability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,integrability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,integrability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,interoperability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,interoperability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,modifiability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,modifiability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:51,reliability,doe,does,51,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,reliability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,reliability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,security,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,security,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:214,testability,integr,integration-scanorama,214,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:246,testability,integr,integration,246,"Much of the spatial data is stored in `uns`, which does not get combined by default. There is an example of concatenating visium datasets [in the tutorial](https://scanpy-tutorials.readthedocs.io/en/latest/spatial/integration-scanorama.html#Data-integration) and more information on concatenating `.uns` [in the latest anndata docs](https://anndata.readthedocs.io/en/latest/concatenation.html#merging-uns).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:9,availability,error,error,9,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:41,availability,sli,slides,41,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:192,availability,sli,slides,192,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:98,deployability,instal,install,98,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:117,deployability,version,version,117,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:506,deployability,modul,module,506,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:117,integrability,version,version,117,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:117,modifiability,version,version,117,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:506,modifiability,modul,module,506,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:9,performance,error,error,9,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:41,reliability,sli,slides,41,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:192,reliability,sli,slides,192,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:9,safety,error,error,9,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:480,safety,input,input-,480,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:506,safety,modul,module,506,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:436,testability,Trace,Traceback,436,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:9,usability,error,error,9,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:480,usability,input,input-,480,"I get an error trying to merge multiples slides using the code in the tutorial. Is it possible to install the scanpy version the tutorial is using? ```python. adata = adata.concatenate(. list(slides.values()),. batch_key=""sample"",. uns_merge=""unique"",. batch_categories=list(sample_data['sample_name'].values), . index_unique=None. ). ```. ```pytb. ---------------------------------------------------------------------------. TypeError Traceback (most recent call last). <ipython-input-4-fe8a54a66c17> in <module>. 40 uns_merge=""unique"",. 41 batch_categories=list(sample_data['sample_name'].values),. ---> 42 index_unique=None. 43 ). 44 . TypeError: concatenate() got an unexpected keyword argument 'uns_merge'. ```.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:23,deployability,updat,update,23,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:35,deployability,version,version,35,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:35,integrability,version,version,35,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:35,modifiability,version,version,35,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:23,safety,updat,update,23,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/issues/1254:23,security,updat,update,23,I think you'll want to update your version of anndata for that.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1254
https://github.com/scverse/scanpy/pull/1255:86,safety,test,test,86,"This seems like a very drastic change for default output, I feel like this deserves a test. Any idea what happened here? I'm very surprised this wasn't caught by a test or the tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:164,safety,test,test,164,"This seems like a very drastic change for default output, I feel like this deserves a test. Any idea what happened here? I'm very surprised this wasn't caught by a test or the tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:86,testability,test,test,86,"This seems like a very drastic change for default output, I feel like this deserves a test. Any idea what happened here? I'm very surprised this wasn't caught by a test or the tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:164,testability,test,test,164,"This seems like a very drastic change for default output, I feel like this deserves a test. Any idea what happened here? I'm very surprised this wasn't caught by a test or the tutorials.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:114,energy efficiency,Current,Current,114,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:53,safety,test,test,53,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:70,safety,test,test,70,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:122,safety,test,test,122,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:313,safety,test,test,313,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:53,testability,test,test,53,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:70,testability,test,test,70,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:122,testability,test,test,122,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:313,testability,test,test,313,"Sorry for late reply, wasn't catched by the previous test because the test set the size of the spot for plotting. Current test:. ```python. sc.pl.spatial(. adata,. color=""array_row"",. groups=[""24"", ""33""],. crop_coord=(100, 400, 400, 100),. alpha=0.5,. size=1.3,. ). ```. Shall i remove the `size` param from this test or make a new one?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:52,safety,test,test,52,"@ivirshup sorry super late on this, added a default test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/pull/1255:52,testability,test,test,52,"@ivirshup sorry super late on this, added a default test.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/pull/1255
https://github.com/scverse/scanpy/issues/1256:72,integrability,repositor,repository,72,"hi @JayalalKJ , it's best if this question is addressed in the original repository https://github.com/metgem/forceatlas2. I'll close this for the moment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:72,interoperability,repositor,repository,72,"hi @JayalalKJ , it's best if this question is addressed in the original repository https://github.com/metgem/forceatlas2. I'll close this for the moment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:127,usability,close,close,127,"hi @JayalalKJ , it's best if this question is addressed in the original repository https://github.com/metgem/forceatlas2. I'll close this for the moment",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:0,deployability,instal,install,0,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:43,deployability,instal,installing,43,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:64,deployability,instal,install,64,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:213,deployability,instal,install,213,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:361,deployability,instal,install,361,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:471,deployability,instal,install,471,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:586,deployability,instal,install,586,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:245,energy efficiency,Power,Powershell,245,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:118,modifiability,pac,package,118,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:403,usability,navigat,navigator,403,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1256:503,usability,navigat,navigator,503,"install cython in anaconda jupyter lab for installing fa2. !pip install Cython. this scanpy trajectory tutorial needs package 'fa2' (not 'forceatlas2'), otherwise the plot made by sc.pl.draw_graph() is not right. install method 1. open Anaconda Powershell Promopt. > conda activate Py36R36 (Py36R36 is the enviroment you create in anaconda for scanpy). > conda install -c conda-forge fa2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. run scanpy trajectory. install method 2. open Anaconda navigator. choose Py36R36. open Jupyter Lab. open Terminal in Jupyter Lab. > conda install -c conda-forge fa2. run scanpy trajectory",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1256
https://github.com/scverse/scanpy/issues/1257:73,availability,echo,echo,73,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:160,deployability,instal,installation,160,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:207,deployability,instal,install,207,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:226,deployability,instal,install,226,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:254,deployability,instal,installed,254,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:101,modifiability,variab,variable,101,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:222,security,apt,apt,222,"Assuming you're on a debian based linux, please check the following:. - `echo $PATH` shows your PATH variable. - `which git` shows you the location of your git installation. If nothing is shown, you need to install it. - `apt install git` if you haven't installed it yet.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1257:42,usability,close,close,42,"thanks @picciama for answering this, will close this now.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1257
https://github.com/scverse/scanpy/issues/1258:46,reliability,doe,doesn,46,Additional information: Changing `legend_loc` doesn't have any effect here either.,MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:48,reliability,doe,doesn,48,"> Additional information: Changing `legend_loc` doesn't have any effect here either. I'm having the same issue. Is there a work around for this? Changing `rcParams[""legend.loc""] ` has no effect either.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:383,deployability,contain,contain,383,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:430,deployability,contain,contain,430,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:475,deployability,manag,manage,475,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:715,deployability,version,version,715,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1288,deployability,stack,stackoverflow,1288,"he colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', si",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1760,deployability,continu,continue,1760,"d returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display p",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:245,energy efficiency,current,current,245,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:475,energy efficiency,manag,manage,475,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:664,energy efficiency,current,currently,664,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:941,energy efficiency,Current,Current,941,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:715,integrability,version,version,715,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1150,integrability,sub,subplots,1150,"5ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:2847,integrability,buffer,buffer,2847," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3161,integrability,buffer,buffer,3161," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3330,integrability,buffer,buffer,3330," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1458,interoperability,specif,specify,1458," could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](htt",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1789,interoperability,specif,specify,1789,"arning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow l",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3525,interoperability,format,format,3525," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:215,modifiability,variab,variables,215,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:674,modifiability,reu,reuses,674,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:715,modifiability,version,version,715,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3425,modifiability,deco,decode,3425," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:475,safety,manag,manage,475,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:1402,security,expos,exposing,1402,". Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:834,usability,behavi,behavior,834,"Totally forgot about this one sorry :(. **The problem** . In `scatter_base`: https://github.com/theislab/scanpy/blob/040e61ff50836d4a6cdd7da7482dcb4ee50d05ae/scanpy/plotting/_utils.py#L736-L740. For non categorical variables, this code gets the current figure and adds a separate axis on which the colorbar is plotted. Therefore, the axes objects on which the data is plotted do not contain a legend object. Instead, `fig` should contain the colorbar axis and we could maybe manage to manipulate it as a workaround. There is also this DeprecationWarning popping up. ```pytb. MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. ax_cb = fig.add_axes(rectangle). ```. **Current workaround (also for all other sort of plots)**. The problem here is really that we don't have two separate figures / axes aren't handled correctly. Good news is, that there is a way around using `plt.subplots` and using given `Axes` objects. even if we want to plot 2 plots side by side in a jupyter notebook (original post here: https://stackoverflow.com/questions/21754976/ipython-notebook-arrange-plots-horizontally). However, `sc.pl.scatter` isn't exposing the figure object but only the axis. But if we specify `show=False`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting f",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:2467,usability,user,user-images,2467,"alse`, it returns the axis and we can obtain the figure object using `matplotlib.pyplot.gcf()`. Store these figures in a list and pass them to the `plot_nice()` function which will plot all your figures side by side until it runs out of space, after which it will create a linebreak and continue. Therefore, you can specify how many figures you want to plot per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:3769,usability,close,close,3769," per line, using the individual `figsize` argument. For my example it would look like this:. ```python. from flow_layout import plot_nice # import the required plotting function. plots = []. sc.pl.scatter(adata_all, 'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""all counts""). plots.append(plt.gcf()). sc.pl.scatter(adata_all[adata_all.obs['total_counts']<1000],'total_counts','n_genes_by_counts', color='pct_counts_mt', size = 10, show=False, title=""< 1000 counts"") . plots.append(plt.gcf()). plot_nice(plots) # plot all figures. ```. Result:. ![Bildschirmfoto von 2020-10-21 12-52-22](https://user-images.githubusercontent.com/50995210/96710439-5cf02500-139c-11eb-884b-bd27790fdcaa.png). In order to import the function, place the following code in a file called `flow_layout.py` in the same folder as your notebooks:. ```python. class FlowLayout(object):. ''' A class / object to display plots in a horizontal / flow layout below a cell '''. def __init__(self):. # string buffer for the HTML: initially some CSS; images to be appended. self.sHtml = """""". <style>. .floating-box {. display: inline-block;. margin: 10px;. # border: 3px solid #888888;. }. </style>. """""". def add_plot(self, oAxes):. ''' Saves a PNG representation of a Matplotlib Axes object '''. Bio = io.BytesIO() # bytes buffer for the plot. if not isinstance(oAxes, matplotlib.figure.Figure):. fig = oAxes.fig. else:. fig = oAxes. fig.canvas.print_png(Bio) # make a png of the plot in the buffer. # encode the bytes as string using base 64. sB64Img = base64.b64encode(Bio.getvalue()).decode(). self.sHtml += (. '<div class=""floating-box"">'. + '<img src=""data:image/png;base64,{}\n"">'.format(sB64Img). + '</div>'). def PassHtmlToCell(self):. ''' Final step - display the accumulated HTML '''. display(HTML(self.sHtml)). def plot_nice(plots: list):. oPlot = FlowLayout(). for fig in plots:. oPlot.add_plot(fig). matplotlib.pyplot.close(). oPlot.PassHtmlToCell(). ```. Hope this is useful :).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:152,deployability,version,version,152,"I am surprised, it's year 2023 with scanpy==1.9.3, and I am facing exactly the same issue posted in 2020. Really hope it will be dealt with in a future version. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:152,integrability,version,version,152,"I am surprised, it's year 2023 with scanpy==1.9.3, and I am facing exactly the same issue posted in 2020. Really hope it will be dealt with in a future version. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:152,modifiability,version,version,152,"I am surprised, it's year 2023 with scanpy==1.9.3, and I am facing exactly the same issue posted in 2020. Really hope it will be dealt with in a future version. Thanks!",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:263,availability,ERROR,ERROR,263,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:153,deployability,log,logging,153,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:239,deployability,log,logger,239,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:255,deployability,log,logging,255,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:263,performance,ERROR,ERROR,263,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:153,safety,log,logging,153,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:239,safety,log,logger,239,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:255,safety,log,logging,255,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:263,safety,ERROR,ERROR,263,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:153,security,log,logging,153,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:239,security,log,logger,239,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:255,security,log,logging,255,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:153,testability,log,logging,153,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:239,testability,log,logger,239,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:255,testability,log,logging,255,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1258:263,usability,ERROR,ERROR,263,"I had some issue with `io.BytesIO()` from the fix proposed above. . So, I used `R` to generate scatter plots as below:. ```py. import anndata2ri. import logging. import rpy2.rinterface_lib.callbacks as rcb. import rpy2.robjects as ro. rcb.logger.setLevel(logging.ERROR). ro.pandas2ri.activate(). anndata2ri.activate(). %load_ext rpy2.ipython. ```. Convert adata_p and adata_g to R objects. ```r. ro.globalenv['r_adata_p'] = adata_p. ro.globalenv['r_adata_g'] = adata_g. ```. ```r. %%R -w 800 -h 400 -u px. library(Seurat). library(viridis). library(viridisLite). library(ggplot2). library(cowplot). df_poor= data.frame(. total_counts = colData(r_adata_p)$total_counts,. n_genes_by_counts = colData(r_adata_p)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_p)$pct_counts_mt. ). df_good= data.frame(. total_counts = colData(r_adata_g)$total_counts,. n_genes_by_counts = colData(r_adata_g)$n_genes_by_counts,. pct_counts_mt = colData(r_adata_g)$pct_counts_mt. ). #head(df). # Create a scatter plot using ggplot2. p2 <- ggplot(data = df_poor, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""poor (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). g2 <- ggplot(data = df_good, aes(x = total_counts, y = n_genes_by_counts, color = pct_counts_mt)) +. geom_point() +. scale_color_viridis() +. labs(title = ""good (after outlier and mitochrondrial gene removal)"") +. theme_minimal(). p2 + g2. ```. ![Screenshot from 2023-12-13 11-25-03](https://github.com/scverse/scanpy/assets/3212461/f016798e-aa7a-4601-9fad-f85d54877c2d).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1258
https://github.com/scverse/scanpy/issues/1259:158,deployability,version,versions,158,"Thanks for the report. Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:226,deployability,contain,contained,226,"Thanks for the report. Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:84,integrability,filter,filtering,84,"Thanks for the report. Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:158,integrability,version,versions,158,"Thanks for the report. Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:158,modifiability,version,versions,158,"Thanks for the report. Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine?",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,deployability,version,versions,166,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:234,deployability,contain,contained,234,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:449,deployability,version,version,449,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:627,deployability,contain,contained,627,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:92,integrability,filter,filtering,92,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,integrability,version,versions,166,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:449,integrability,version,version,449,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,modifiability,version,versions,166,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:449,modifiability,version,version,449,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:549,usability,learn,learn,549,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:697,usability,user,user-images,697,"> Thanks for the report. > . > Do you have NaN values in your expression matrix? If so, try filtering them out and seeing if that works. If not, could you report the versions of the library you're working with, and try to make a self contained example that I could run on my machine? Hi, . Thank you for your reply. I think there is no NaN data in the matrix of the mito genes. Because I have already plotted the mitochondrial genes as follows. The version is scanpy==1.5.1 anndata==0.7.3 umap==0.4.3 numpy==1.18.1 scipy==1.4.1 pandas==1.0.1 scikit-learn==0.22.1 statsmodels==0.11.0. I am sorry I don't know how to make a self-contained example. The plot is: . ![highest_expre_genes_BHCF](https://user-images.githubusercontent.com/49381637/83712829-3ea3ab80-a5ec-11ea-8497-cc70a95a216e.png). Thank you. Best wishes,. Shangyu.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:193,availability,error,error,193,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:482,availability,error,error,482,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:23,deployability,contain,contained,23,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:562,interoperability,share,share,562,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:193,performance,error,error,193,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:482,performance,error,error,482,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:193,safety,error,error,193,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:482,safety,error,error,482,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:193,usability,error,error,193,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:288,usability,minim,minimal,288,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:421,usability,minim,minimal-bug-reports,421,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:482,usability,error,error,482,"The idea behind a self contained example is to give me something that I can run on my machine. Ideally you'd be able to put something together with randomly generated data that still gave this error. If that's difficult, you could keep removing elements from your data until you find the minimal object that can reproduce this. [Here is a good blog post on how to do this](https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports). Right now, I'm unable to reproduce the error you're seeing. Do you think you could try and create an example you could share with me? This could even be sharing your data as an `h5ad` file.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:649,availability,error,error,649,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:951,availability,error,error,951,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:473,deployability,contain,contained,473,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:56,energy efficiency,load,load,56,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:1034,interoperability,share,share,1034,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:56,performance,load,load,56,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:326,performance,cach,cache,326,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:649,performance,error,error,649,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:951,performance,error,error,951,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:649,safety,error,error,649,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:951,safety,error,error,951,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:1151,security,auth,authored,1151,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:1365,security,auth,auth,1365,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:649,usability,error,error,649,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:747,usability,minim,minimal,747,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:885,usability,minim,minimal-bug-reports,885,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:951,usability,error,error,951,"Hi, Isaac,. Thank you for your reply. The matrix that I load is the output of. cellranger, we use 10X generate the library. Follow your. recommended tutorial, I can't small size it. Do you have any other. suggestions? The code is: adata = sc.read_10x_mtx(. 'D:/.../.../filtered_feature_bc_matrix/', var_names='gene_symbols',. cache=True) . Thank you so much. Best regards,. Shangyu. Isaac Virshup <notifications@github.com> 202065 2:31. > The idea behind a self contained example is to give me something that I. > can run on my machine. Ideally you'd be able to put something together with. > randomly generated data that still gave this error. If that's difficult,. > you could keep removing elements from your data until you find the minimal. > object that can reproduce this. Here is a good blog post on how to do this. > <https://matthewrocklin.com/blog/work/2018/02/28/minimal-bug-reports>. >. > Right now, I'm unable to reproduce the error you're seeing. Do you think. > you could try and create an example you could share with me? This could. > even be sharing your data as an h5ad file. >. > . > You are receiving this because you authored the thread. > Reply to this email directly, view it on GitHub. > <https://github.com/theislab/scanpy/issues/1259#issuecomment-639309900>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/ALYYCBLMIG7FAT7MMJIDC2DRVCNM3ANCNFSM4NOZJRCQ>. > . >.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,deployability,log,log,166,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:801,deployability,version,versions,801,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:801,integrability,version,versions,801,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:639,interoperability,specif,specifically,639,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:801,modifiability,version,versions,801,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:110,safety,except,exception,110,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,safety,log,log,166,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,security,log,log,166,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:659,security,ident,identify,659,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:166,testability,log,log,166,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:91,usability,prefer,prefers,91,"NaN is a special floating point sentinel value, meaning ""Not a Number."" In general, Python prefers raising an exception to returning NaN, so things like sqrt(-1) and log(0.0) will generally raise instead of returning NaN. However, you may get this value back from some other library. From v0.24, you actually can. [Pandas](http://net-informations.com/ds/pd/default.htm) introduces Nullable Integer Data Types which allows integers to coexist with NaNs. You need to say what you want to do with nans. You can either drop those rows (df.dropna()) or replace nans with something else (0 for instance: df.fillna(0)). My suggestion would be to specifically try to identify this problem (why are you getting this particular NaN), and then write some code to provide a replacement. Also, even at the lastest versions of pandas if the column is object type you would have to convert into float first, something like:. `df['column_name'].astype(np.float).astype(""Int32"")`. NB: You have to go through numpy float first and then to nullable Int32, for some reason.",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:168,availability,error,error,168,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:319,deployability,log,lognormalize,319,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:342,deployability,log,log,342,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:460,deployability,contain,contain,460,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:67,performance,perform,performing,67,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:168,performance,error,error,168,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:50,safety,prevent,prevents,50,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:168,safety,error,error,168,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:319,safety,log,lognormalize,319,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:342,safety,log,log,342,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:50,security,preven,prevents,50,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:319,security,log,lognormalize,319,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
https://github.com/scverse/scanpy/issues/1259:342,security,log,log,342,"HI everyone, . I have the excat same issue, which prevents me from performing further analysis. . What I did : . - dropna(), still boolean values, which poses the same error again (boolean values are NANs appearently). - fillna(0) : replaced all NAN values with 0, but this poses a problem later in the analysis when i lognormalize the data (log(0) = inf). How do you guys deal with these sorts of problems with your data ? . I don't think the mt colum should contain boolean values... (cf. screeshot). Please correct me if i am wrong, and thank you in advance for your help. ![Screenshot from 2021-12-13 17-17-56](https://user-images.githubusercontent.com/45742503/145848639-6d7c6ee6-a38f-4c48-b38a-c8339984e360.png).",MatchSource.ISSUE_COMMENT,scverse,scanpy,1.10.2,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/issues/1259
