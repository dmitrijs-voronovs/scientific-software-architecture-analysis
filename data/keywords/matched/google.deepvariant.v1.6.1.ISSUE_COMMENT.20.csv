id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/google/deepvariant/issues/514:1384,integrability,version,versions,1384,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1350,interoperability,share,shared,1350,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:44,modifiability,version,version,44,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:950,modifiability,interm,intermediate,950,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1010,modifiability,version,versions,1010,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1082,modifiability,variab,variables,1082,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1384,modifiability,version,versions,1384,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1221,performance,error,error,1221,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1238,reliability,cloud deploy,cloud deployment,1238,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1221,safety,error,error,1221,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1221,usability,error,error,1221,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/514:1267,usability,close,closed,1267,"I was able to get around this issue with my version of singularity (3.4.2) by cleaning the environment, limiting what's passed to singularity from the environment, and setting the tmp dir explicitly in the working directory on the NFS. here's my code chunk:. ```. WORKING_DIR=/mnt/scratch/Precision/Hub/PROCESS/DH4749/. export SINGULARITY_CACHEDIR=$WORKING_DIR. export SINGULARITY_TMPDIR=$WORKING_DIR/tmp/. mkdir -p $WORKING_DIR/tmp/. singularity exec \. 	-e \. 	-c \. 	-H $WORKING_DIR \. 	-B $WORKING_DIR/tmp:/tmp \. 	-B /usr/lib/locale/:/usr/lib/locale/ \. 	-B ""${BAM_DIR}"":""/bamdir"" \. 	-B ""${FASTA_DIR}"":""/genomedir"" \. 	-B ""${OUTPUT_DIR}"":""/output"" \. 	docker://google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WES \. --ref=""/genomedir/$FASTA_FILE"" \. --reads=""/bamdir/$PROBAND_BAM"" \. --output_vcf=""/output/$PROBAND_VCF"" \. --output_gvcf=""/output/$PROBAND_GVCF"" \. --intermediate_results_dir=""/output/intermediate"" \. --num_shards=$NSLOTS . ```. With the newer versions of singularity I think they do less inclusion of environmental variables, which includes the PYTHONPATH among other things in home directory and /usr/local/src...which is why you couldn't reproduce the error on a fresh cloud deployment. . Can keep closed just figured it out on my end...may be useful to someone with same issue on shared HPC with older singularity versions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/514
https://github.com/google/deepvariant/issues/515:21,interoperability,bind,bind,21,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:303,interoperability,bind,binding,303,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:21,modifiability,bind,bind,21,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:303,modifiability,bind,binding,303,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:251,safety,input,input-files-eg-could-not-open,251,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:97,security,access,accessible,97,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:57,usability,command,command,57,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:251,usability,input,input-files-eg-could-not-open,251,I see that you don't bind a /scicore directory in docker command. Your local directories are not accessible from a docker. Please take a look at the FAQ [section](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open) that explains docker binding.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:60,usability,help,helpful,60,"Hi @priyambial123 , . hopefully @akolesnikov 's pointer was helpful. I'll close this, but feel free to reopen if it didn't help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:74,usability,close,close,74,"Hi @priyambial123 , . hopefully @akolesnikov 's pointer was helpful. I'll close this, but feel free to reopen if it didn't help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/515:123,usability,help,help,123,"Hi @priyambial123 , . hopefully @akolesnikov 's pointer was helpful. I'll close this, but feel free to reopen if it didn't help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/515
https://github.com/google/deepvariant/issues/516:420,interoperability,specif,specific,420,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:67,performance,perform,performs,67,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:310,reliability,doe,does-it-work,310,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:582,reliability,doe,does,582,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:67,usability,perform,performs,67,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:789,usability,help,help,789,"Hi Josh,. There are multiple possible explanations. 1. DeepVariant performs a local realignment which may change how reads are aligned. There is a section in FAQ which describes how to output a realigned BAM file [here](https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work). For that you can run make_examples.py with --region flag that would generate examples for your specific region. I recommend to set the region to 1000 bases interval (for example chr1:2001-3000). Then you may examine a realigned BAM with IGV. 2. DeepVariant does not take into account positions with base quality lower than the threshold. What can happen is that certain positions are low quality and therefore not counted towards allele depth. Hopefully this will help.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/516:57,usability,close,close,57,"Given that there has been no responses for a while, I'll close this issue. Please feel free to reopen as needed.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/516
https://github.com/google/deepvariant/issues/517:108,availability,error,error,108,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:177,availability,sli,slice,177,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:449,availability,error,error,449,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:114,integrability,messag,message,114,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:114,interoperability,messag,message,114,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:138,interoperability,share,share,138,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:108,performance,error,error,108,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:449,performance,error,error,449,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:177,reliability,sli,slice,177,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:108,safety,error,error,108,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:449,safety,error,error,449,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:473,safety,input,input,473,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:52,usability,clear,clear,52,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:108,usability,error,error,108,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:449,usability,error,error,449,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:473,usability,input,input,473,"Hi @NagaComBio. Sorry for the delay! I don't have a clear solution to this problem just from looking at the error message, but if you can share the data, e.g. with just a small slice of the bam, then I can try to reproduce the issue. If that's possible, you can email me at marianattestad@google.com. For now I can tell you that `--group_variants=false` is only applicable when using `vcf_candidate_importer`, which is the most common way that this error occurs, since the input VCF for that can have multiple candidate variants in the same position, which isn't supposed to be possible when the candidates are generated by make_examples without `vcf_candidate_importer`. Thanks,. Maria",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:285,availability,error,errors,285,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:652,availability,error,error,652,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:72,interoperability,share,share,72,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:196,interoperability,coordinat,coordinates,196,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:285,performance,error,errors,285,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:652,performance,error,error,652,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:231,safety,compl,complete,231,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:255,safety,test,tests,255,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:285,safety,error,errors,285,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:652,safety,error,error,652,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:231,security,compl,complete,231,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:255,testability,test,tests,255,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:132,usability,workflow,workflow,132,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:285,usability,error,errors,285,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:595,usability,close,close,595,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/517:652,usability,error,error,652,"Hi @MariaNattestad . Thanks for the offer, but it would be difficult to share the data without a DTA. So, I went back and reran the workflow (`--num_shards=5`) for a short region around the above coordinates and then again for the complete chr1, both the tests ran through without any errors. And some of the candidate variants called earlier are not present here. ```. 1 160351251 . T <*> 0 . END=160351253 GT:GQ:MIN_DP:PL 0/0:50:80:0,261,2609. 1 160351254 . GTTTT G,<*> 9.1 PASS . GT:GQ:DP:AD:VAF:PL 0/1:9:79:18,33,0:0.417722,0:8,0,26,990,990,990. ```. Not sure how it's resolved. But, I will close this issue for now and will reopen it if a similar error pops up during the rerun of all the chrs. Thank you for looking into the issue,. Naga",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/517
https://github.com/google/deepvariant/issues/518:622,availability,state,statement,622,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2765,availability,avail,available,2765,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1066,deployability,contain,contain,1066,"at the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:118,energy efficiency,current,currently,118,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:135,energy efficiency,optim,optimal,135,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1453,energy efficiency,measur,measured,1453,"unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1969,energy efficiency,reduc,reduced,1969,"the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2500,energy efficiency,model,model,2500,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2985,energy efficiency,model,models,2985,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:131,integrability,sub,sub-optimal,131,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:622,integrability,state,statement,622,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1707,integrability,sub,substantial,1707,"recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1853,modifiability,inherit,inherited,1853,"nd for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1235,performance,perform,perform,1235,". In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1883,performance,perform,performed,1883,"ther and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2275,performance,perform,performed,2275,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2765,reliability,availab,available,2765,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2765,safety,avail,available,2765,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2775,safety,compl,complete,2775,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1367,security,assess,assess,1367,"ample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromos",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2500,security,model,model,2500,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2765,security,availab,available,2765,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2775,security,compl,complete,2775,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2985,security,model,models,2985,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2550,testability,coverag,coverage,2550,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:77,usability,behavi,behavior,77,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:572,usability,document,documentation,572,"Hi @Phillip-a-richmond . Thank you for the report. You are correct, that the behavior out-of-the box for DeepTrio can currently be sub-optimal for the sex chromosomes in male samples. We've benchmarked some strategies for dealing with this. In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1235,usability,perform,perform,1235,". In the short term, our recommendation is to run separate calling on the non-PAR regions of ChrX and ChrY, where only the mother sample is provided as the parent for calling of the son, and (less importantly as it is unclear whether this is an issue with chrY) only the father sample is provided for calling chrY on the son. In the documentation, this is expressed in the following statement: ""Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1883,usability,perform,performed,1883,"ther and son samples)."". The DeepTrio manuscript has benchmarks for this strategy in the following section (near the end of results):. > The Genome in a Bottle truth sets do not contain chromosomeX or chromosomeY variants in a. > male individual. As a result, DeepTrio has never been trained with hemizygous sites. Because we. > train DeepTrio to perform duo calling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2275,usability,perform,performed,2275,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2472,usability,indicat,indicates,2472,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:3063,usability,feedback,feedback,3063,"lling, it is likely that DeepTrio would call variants on. > chromosomeX similar to how it would call a duo sample. To assess this, we ran DeepVariant and. > DeepTrio on chromosomeX of the son (HG002) and measured the number of heterozygous. > variant calls in the non-PAR regions of chromosomeX. > . > For DeepVariant, 4.45% (455/101866) of calls in non-PAR regions of chromosomeX are. > heterozygous. In DeepTrio, 24.5% (21633/88314) are heterozygous. This substantial difference. > suggests that applying DeepTrio directly to chromosomeX in male samples is problematic. > Since chromosomeX in males is inherited from the mother, we performed calling on. > chromosomeX with only the mother provided as the parent. This reduced heterozygous calls to. > 3.37% (3518/104427), which is better than in the DeepVariant case. For male samples, this. > recommends that variant calling should be run with both parents on the autosomal and PAR. > regions using a BED file to restrict location, and additional variant calling should be performed. > using only the mother’s file provided as parent for the non-PAR regions of chromosomeX, and. > only the father’s provided for the non-PAR regions of chromosomeY. > . > This experiment indicates that allowing the model to infer a hemizygous chromosome through. > coverage and explicitly training for hemizygous variants is an opportunity for improvement,. > both for DeepVariant and DeepTrio. Over the long term:. We anticipate that the T2T consortium will be shortly be making available complete assemblies of ChrX and ChrY for the HG002 sample. This should allow us to make training labels for ChrX and ChrY in the hemizygous case, and we have a few internal ideas around how to use this to make models that will generally take this into account. I would be curious in your feedback about whether the short term solution is acceptable, whether you find it insufficient, or if you would recommend other approaches for us to address the issue. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:470,energy efficiency,model,model,470,"Hi @Phillip-a-richmond . As an additional follow-up, I am wondering if my answer is off the mark, that I have discussed this with respect of accuracy of calling, while you would prefer fixes to the VCF representation. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. . It's our anticipation that the sex-aware model would call these variants as 1/1 (since we will use that output class for hemizygous variants). It's also our anticipation that providing only the mother ChrX will result in a 1/1 call. However, we won't represent this specifically as hemizygous. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:695,interoperability,specif,specifically,695,"Hi @Phillip-a-richmond . As an additional follow-up, I am wondering if my answer is off the mark, that I have discussed this with respect of accuracy of calling, while you would prefer fixes to the VCF representation. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. . It's our anticipation that the sex-aware model would call these variants as 1/1 (since we will use that output class for hemizygous variants). It's also our anticipation that providing only the mother ChrX will result in a 1/1 call. However, we won't represent this specifically as hemizygous. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:814,interoperability,specif,specifically,814,"Hi @Phillip-a-richmond . As an additional follow-up, I am wondering if my answer is off the mark, that I have discussed this with respect of accuracy of calling, while you would prefer fixes to the VCF representation. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. . It's our anticipation that the sex-aware model would call these variants as 1/1 (since we will use that output class for hemizygous variants). It's also our anticipation that providing only the mother ChrX will result in a 1/1 call. However, we won't represent this specifically as hemizygous. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:470,security,model,model,470,"Hi @Phillip-a-richmond . As an additional follow-up, I am wondering if my answer is off the mark, that I have discussed this with respect of accuracy of calling, while you would prefer fixes to the VCF representation. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. . It's our anticipation that the sex-aware model would call these variants as 1/1 (since we will use that output class for hemizygous variants). It's also our anticipation that providing only the mother ChrX will result in a 1/1 call. However, we won't represent this specifically as hemizygous. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:178,usability,prefer,prefer,178,"Hi @Phillip-a-richmond . As an additional follow-up, I am wondering if my answer is off the mark, that I have discussed this with respect of accuracy of calling, while you would prefer fixes to the VCF representation. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. . It's our anticipation that the sex-aware model would call these variants as 1/1 (since we will use that output class for hemizygous variants). It's also our anticipation that providing only the mother ChrX will result in a 1/1 call. However, we won't represent this specifically as hemizygous. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:386,availability,down,downstream,386,"Hi Andrew,. Thanks for your response. There are a few items here which I'll address. 1. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. Yes proper representation on X chromosome is important, and it's caused this problem for downstream analyses of pathogenic hemizygous variants. Likely would be true for de novo hemizygous variants on male non-PAR chromosome X. If this were fixed sooner than later that would increase confidence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1022,availability,down,downstream,1022," response. There are a few items here which I'll address. 1. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. Yes proper representation on X chromosome is important, and it's caused this problem for downstream analyses of pathogenic hemizygous variants. Likely would be true for de novo hemizygous variants on male non-PAR chromosome X. If this were fixed sooner than later that would increase confidence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs toget",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2577,deployability,configurat,configuration,2577,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2577,integrability,configur,configuration,2577,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:805,interoperability,specif,specifically,805,"Hi Andrew,. Thanks for your response. There are a few items here which I'll address. 1. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. Yes proper representation on X chromosome is important, and it's caused this problem for downstream analyses of pathogenic hemizygous variants. Likely would be true for de novo hemizygous variants on male non-PAR chromosome X. If this were fixed sooner than later that would increase confidence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2255,modifiability,paramet,parameterized,2255,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2577,modifiability,configur,configuration,2577,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2086,performance,time,times,2086,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2341,reliability,pra,practice,2341,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2640,safety,test,test,2640,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2577,security,configur,configuration,2577,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2640,testability,test,test,2640,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1033,usability,tool,tools,1033,". There are a few items here which I'll address. 1. Is your main request that we have the ability to output a hemizygous representation of the VCF? This is something we are starting to think about for VCF and gVCF as we prepare to work with the T2T assemblies. Yes proper representation on X chromosome is important, and it's caused this problem for downstream analyses of pathogenic hemizygous variants. Likely would be true for de novo hemizygous variants on male non-PAR chromosome X. If this were fixed sooner than later that would increase confidence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Esse",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1583,usability,user,user,1583,"idence in DeepTrio. Until that's fixed, I'll be shifting back to DeepVariant GVCF->GLNexus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configur",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2062,usability,user,user,2062,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2175,usability,user,user,2175,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2296,usability,command,command,2296,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2448,usability,user,user,2448,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2460,usability,prefer,prefer,2460,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2478,usability,command,commands,2478,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:2565,usability,tool,tool,2565,"xus for all rare disease trio samples. 2. In order to resolve your issue, do we need to solve this hemizygous representation problem specifically, or will producing more 1/1 calls in the manner described in my prior comment be sufficient? If a variant is present in 100% of the reads, representing as 1/1 would be ideal as this is what's expected by downstream tools. The expectation for a male is to have majority variants on X as 1/1. It would be dangerous if a female had majority 1/1. 3. Also please note: for the non-PAR regions of the sex chromosomes (X and Y), we recommend running these providing only the parent who contributed the child's chromosome (e.g. for chromosomeX, only the mother and son samples and for chromosomeY only the father and son samples). Sounds like this involves a lot of mangling of samples and VCF cutting/manipulation...and no I'm not thrilled about having this pushed on the user. You're recommendation would be:. 1. Run DeepTrio on trio. 2. BCFtools to cut-out chrX + Y. 3. Rerun DeepTrio on duo, once with mother and once with father, keeping the Y variants from paternal analysis, and X from maternal analysis. (?What happens with female child, no change?). 4. Now you've got VCFs with improper columns (mom-proband, dad-proband, mom-dad-proband)so you can't just concat them together... 5. Mangle the 2-3 VCFs together. Essentially you're asking the user to run DeepTrio >2 times for it to work on a trio with a male proband, including manual VCF mangling on the user side. It would be much appreciated if this process can be internalized and parameterized within the run deepvariant command. Alternatively, if this is your best practice then providing code chunks to this effect would be appreciated. . At the end of the day, me, as a user, would prefer to run 1-2 commands to get a trio merged VCF. If you provided that code chunk to run the existing tool in the configuration you describe, then I'd be happy to insert it and test on my cases. Thanks,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:716,deployability,updat,update,716,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:339,energy efficiency,model,model,339,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:461,energy efficiency,model,model,461,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:754,energy efficiency,estimat,estimate,754,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:790,energy efficiency,model,model,790,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:661,performance,time,time,661,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:576,reliability,doe,does,576,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:431,safety,test,test,431,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:716,safety,updat,update,716,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:339,security,model,model,339,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:461,security,model,model,461,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:716,security,updat,update,716,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:790,security,model,model,790,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:27,testability,understand,understand,27,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:431,testability,test,test,431,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:674,testability,plan,plan,674,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:54,usability,workflow,workflow,54,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:479,usability,feedback,feedback,479,"Hi @Phillip-a-richmond . I understand agree that this workflow is cumbersome and far from ideal. Here is the course of action that we'll propose to take:. Within the next 2 weeks, we anticipate that we'll likely to have GIAB labels for X and Y. The first course of action that we'll take is to incorporate those and attempt to train a new model with this. Based on whether this looks promising, we may ask if you are interested to test a Docker image with this model and provide feedback on it. I can't guarantee that this will work, but I think it has reasonable odds. If it does not, we do have other ideas for X and Y calling, but they would take a bit more time. I will plan to reach back out in 2 weeks with an update about the labels and a refined estimate for when we might have the model. Thank you,. Andrew.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:69,deployability,version,version,69,"Yes this sounds like a great plan. Happy to try out your docker beta version too see if it fixes this hemizygous issue. Have a good weekend,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:69,integrability,version,version,69,"Yes this sounds like a great plan. Happy to try out your docker beta version too see if it fixes this hemizygous issue. Have a good weekend,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:69,modifiability,version,version,69,"Yes this sounds like a great plan. Happy to try out your docker beta version too see if it fixes this hemizygous issue. Have a good weekend,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:29,testability,plan,plan,29,"Yes this sounds like a great plan. Happy to try out your docker beta version too see if it fixes this hemizygous issue. Have a good weekend,. Phil.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:36,deployability,updat,update,36,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:116,energy efficiency,model,models,116,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:169,energy efficiency,model,models,169,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:272,performance,time,time,272,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:36,safety,updat,update,36,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:36,security,updat,update,36,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:116,security,model,models,116,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:169,security,model,models,169,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:233,usability,progress,progress,233,"Hi @Phillip-a-richmond . Just as an update on this issue, we have the truth sets and have trained some experimental models. We're still in the process of refining these models, as well as how to use the T2T truth sets. So we do have progress, but it's still going to take time before we're ready with something for you to look at.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:42,deployability,version,version,42,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:42,integrability,version,version,42,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:42,modifiability,version,version,42,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:32,safety,test,test,32,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:32,testability,test,test,32,Thanks @AndrewCarroll! Happy to test beta version when you produce them.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:44,deployability,updat,update,44,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:287,energy efficiency,model,model,287,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:44,safety,updat,update,44,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:304,safety,test,test,304,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:44,security,updat,update,44,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:287,security,model,model,287,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:304,testability,test,test,304,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:153,usability,progress,progress,153,"Hi @Phillip-a-richmond ,. I want to give an update on this issue:. As part of working on v1.4.0, we did some experiments on this, which is still work in progress. If you can reach out to me and @AndrewCarroll (you can email me at pichuan@google.com), we can follow up on an experimental model for you to test, if you're still interested.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:82,deployability,updat,update,82,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:556,deployability,build,building,556,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:708,deployability,build,build,708,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:534,energy efficiency,current,currently,534,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:738,energy efficiency,model,modeling,738,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:162,interoperability,distribut,distribution,162,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:82,safety,updat,update,82,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:82,security,updat,update,82,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:526,security,team,team,526,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:738,security,model,modeling,738,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:380,testability,verif,verified,380,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:941,usability,close,close,941,"Hi @Phillip-a-richmond and everyone else who might be following this thread,. One update:. one post-processing trick that you can do now is: take the probability distribution, and ignore the 0/1 one, and just renormalize the other two. From there, you can decide whether it should be a 0/0 or 1/1. (This idea came from our collaborator @doron-st at Ultima Genomics. They actually verified this on a dataset and showed good precision. They did this on DeepVariant, not DeepTrio. But I think the same trick can be applied). Our team is currently considering building this into an option in `postprocess_variants`, so that we can do this re-normalization ourselves. (Another more principled approach will be to build this knowledge into the modeling part. We're also considering that, but that will be an even longer-term solution.). Thanks @Phillip-a-richmond again for reporting this. We have filed an internal issue to track this work. I'll close this bug for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:170,deployability,pipelin,pipelines,170,"Follow up from my previous comment, @doron-st has shared his script here:. https://github.com/Ultimagen/VariantCalling/blob/c2634d8c08db4473e61b786eed06afc2bb8fccd1/ugvc/pipelines/convert_haploid_regions.py. (Thanks Doron!)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:170,integrability,pipelin,pipelines,170,"Follow up from my previous comment, @doron-st has shared his script here:. https://github.com/Ultimagen/VariantCalling/blob/c2634d8c08db4473e61b786eed06afc2bb8fccd1/ugvc/pipelines/convert_haploid_regions.py. (Thanks Doron!)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:50,interoperability,share,shared,50,"Follow up from my previous comment, @doron-st has shared his script here:. https://github.com/Ultimagen/VariantCalling/blob/c2634d8c08db4473e61b786eed06afc2bb8fccd1/ugvc/pipelines/convert_haploid_regions.py. (Thanks Doron!)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:4,deployability,updat,updates,4,Any updates on this? The link for the script is broken now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:4,safety,updat,updates,4,Any updates on this? The link for the script is broken now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:4,security,updat,updates,4,Any updates on this? The link for the script is broken now.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:62,deployability,releas,release,62,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:115,deployability,releas,releases,115,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:219,deployability,log,logic,219,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:383,deployability,pipelin,pipelines,383,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:383,integrability,pipelin,pipelines,383,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:219,safety,log,logic,219,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:219,security,log,logic,219,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:219,testability,log,logic,219,"@nurmians Still looking through the code - and looked at the [release notes](https://github.com/google/deepvariant/releases) - though still reasoning through it in case it might have been implemented via some alternate logic. In any case, here's a link to the script for converting genotypes of regions to haploid calls:. https://github.com/Ultimagen/VariantCalling/blob/master/ugvc/pipelines/convert_haploid_regions.py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:171,deployability,version,version,171,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:203,deployability,releas,release,203,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:533,deployability,releas,release,533,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:171,integrability,version,version,171,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:171,modifiability,version,version,171,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:87,security,team,team,87,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:422,usability,support,support,422,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:480,usability,document,documentation,480,"Hi @nurmians ,. The link the @pgrosu link to seems like the right one from Ultima! Our team is working on incorporating this as part of postprocess_variants. The official version will be out in the next release (before end of 2023). . You can get a preview of these 2 flags that we'll be adding:. https://github.com/google/deepvariant/blob/dev/deepvariant/postprocess_variants.py#L170-L188. (Note that we don't officially support the code in ""dev"" branch. If you want an official documentation and usage of this, please wait for the release later. But please feel free to take a look at the code if you like)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:147,modifiability,paramet,parameter,147,"Hi Pi-Chuan,. I was thinking about the nice upcoming changes a bit. It will probably be easier to consolidate the two proposed flags into only one parameter such as `--non_recombinant_regions` (or `--hemizygous_regions`), since all the other regions go through recombination. The PAR regions is already the default behavior of DeepVariant as it assumes diploid recombinant behavior, so you don't need the `--par_regions_bed` flag. . ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:315,usability,behavi,behavior,315,"Hi Pi-Chuan,. I was thinking about the nice upcoming changes a bit. It will probably be easier to consolidate the two proposed flags into only one parameter such as `--non_recombinant_regions` (or `--hemizygous_regions`), since all the other regions go through recombination. The PAR regions is already the default behavior of DeepVariant as it assumes diploid recombinant behavior, so you don't need the `--par_regions_bed` flag. . ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:373,usability,behavi,behavior,373,"Hi Pi-Chuan,. I was thinking about the nice upcoming changes a bit. It will probably be easier to consolidate the two proposed flags into only one parameter such as `--non_recombinant_regions` (or `--hemizygous_regions`), since all the other regions go through recombination. The PAR regions is already the default behavior of DeepVariant as it assumes diploid recombinant behavior, so you don't need the `--par_regions_bed` flag. . ~p.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:723,energy efficiency,current,currently,723,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:935,energy efficiency,current,current,935,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1182,energy efficiency,current,current,1182,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:506,integrability,sub,subtract,506,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:602,integrability,pub,publish,602,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:348,interoperability,format,format,348,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:641,interoperability,standard,standard,641,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:971,interoperability,specif,specify,971,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:991,interoperability,standard,standard,991,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:192,modifiability,paramet,parameter,192,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:533,reliability,doe,does,533,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:515,usability,command,command,515,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:570,usability,user,users,570,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:590,usability,document,document,590,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:851,usability,user,user,851,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1053,usability,user,user,1053,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1083,usability,prefer,preference,1083,"Hi @pgrosu . Thank you for the suggestion. The exact way to manifest the flags came up in internal discussion. I actually proposed basically the approach you detail here (I wanted to call the parameter --haploid_regions). The counter-argument was that people who have BED files for what they want to call more often have these files already in the format of the chromosome and a separate file of the PAR regions. So it is possible to generate the --haploid_regions or --hemizygous_regions using a bedtools subtract command, but that does require one other step and then users who wanted to document or publish what they have done have a non-standard file. I was persuaded to drop my suggestion and endorse the solution you currently see in L170-L188 by this argument. However, I also did not see a large relative advantage with either approach from a user perspective, so I did not advocate particularly forcefully. I do like that the current arrangement will be able to specify some pretty standard community files. . If you think the difference for a user will be more strongly in preference of the single flag, we'd be open to the discussion, but hopefully the rationale for the current flag choice makes a bit more sense.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:374,availability,operat,operation,374,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1752,availability,avail,available,1752,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:758,deployability,updat,updating,758,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1304,deployability,automat,automatically,1304,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1625,deployability,automat,automatic,1625,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:169,energy efficiency,reduc,reduction,169,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:369,energy efficiency,core,core,369,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:804,energy efficiency,model,model,804,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:810,energy efficiency,optim,optimization,810,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:950,energy efficiency,model,model,950,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:956,energy efficiency,optim,optimize,956,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1099,energy efficiency,optim,optimized,1099,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1109,energy efficiency,model,model,1109,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1141,energy efficiency,model,model,1141,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1268,energy efficiency,model,model,1268,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1340,energy efficiency,model,model,1340,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1745,energy efficiency,model,models,1745,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1871,energy efficiency,adapt,adapting,1871,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1884,energy efficiency,model,models,1884,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1956,energy efficiency,model,models,1956,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:582,integrability,transform,transformations,582,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1871,integrability,adapt,adapting,1871,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:582,interoperability,transform,transformations,582,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1871,interoperability,adapt,adapting,1871,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:305,modifiability,paramet,parameter,305,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:398,modifiability,paramet,parameter,398,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:618,modifiability,paramet,parameter,618,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:729,modifiability,paramet,parameter,729,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:989,modifiability,paramet,parameter,989,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1236,modifiability,paramet,parameters,1236,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1447,modifiability,paramet,parameters,1447,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1544,modifiability,paramet,parameters,1544,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1871,modifiability,adapt,adapting,1871,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:157,performance,perform,performed,157,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:668,performance,time,time,668,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:810,performance,optimiz,optimization,810,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:956,performance,optimiz,optimize,956,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1018,performance,perform,performs,1018,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1099,performance,optimiz,optimized,1099,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1844,performance,time,time,1844,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1752,reliability,availab,available,1752,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:288,safety,input,inputs,288,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:758,safety,updat,updating,758,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1385,safety,valid,validation,1385,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1752,safety,avail,available,1752,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:477,security,team,team,477,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:521,security,team,team,521,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:606,security,sign,signals,606,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:758,security,updat,updating,758,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:804,security,model,model,804,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:930,security,team,team,930,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:950,security,model,model,950,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1109,security,model,model,1109,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1141,security,model,model,1141,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1268,security,model,model,1268,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1340,security,model,model,1340,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1385,security,validat,validation,1385,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1745,security,model,models,1745,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1752,security,availab,available,1752,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1884,security,model,models,1884,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1956,security,model,models,1956,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:793,testability,simpl,simplified,793,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1304,testability,automat,automatically,1304,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1625,testability,automat,automatic,1625,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:49,usability,Support,Supporting,49,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:91,usability,prefer,preferred,91,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:157,usability,perform,performed,157,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:288,usability,input,inputs,288,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:331,usability,help,help,331,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:793,usability,simpl,simplified,793,"Hi Andrew,. I think we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1018,usability,perform,performs,1018,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1121,usability,user,users,1121,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1492,usability,user,users,1492,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1512,usability,user,users,1512,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1537,usability,custom,custom,1537,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1716,usability,user,users,1716,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/518:1791,usability,help,helping,1791,"k we are in perfect agreement. Supporting what the community wants is my preferred approach as well. I was only suggesting it after having performed a reduction upon the functional set of DeepVariant's design. Just in case the community requires more variety of labeled inputs, having a parameter processor might help in mapping between DeepVariant's core operation and different parameter sets. This would create flexibility for both the goals of the design team and community. For example, the design team might want flexibility in playing around with different transformations of read signals and parameter search spaces - which might change over time or with different data sets - without worrying that the parameter list might require updating. Let's take the following simplified model optimization:. ![image](https://github.com/google/deepvariant/assets/6555937/f7c33960-59fc-45c9-9cdd-0f015ebd1aae). The team would let this model optimize itself to determine the parameter set under which it performs ideally. Then metadata about the training would be saved along with the optimized model. Then users can query the model's metadata via some program, which would provide information about the training data and parameters limits for different model types. Such metadata would be automatically populated through the model training step (where I'm including the validation and tuning steps). Based on that, a default set of parameters can be auto-generated for general users, and advanced users can then map their custom parameters however they want. It basically makes the training turn-key and usage automatic. Such training could even be remotely initiated through a browser, and different users can make some of their models available to others if they want, thus helping out the community and growing it at the same time. This would also make adapting new models much faster, including where a large set of specialized ensemble models might be required to check against. Best regards,. Paul",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/518
https://github.com/google/deepvariant/issues/519:264,energy efficiency,model,models,264,"The main obstacle is getting good data for training. We use GIAB truth sets for human, but we would need similar quality true variants along with sequencing data in polyploid genomes, and even then to support various ploidy levels you might need to train multiple models. We also don't have enough bandwidth to prioritize this work within the team for the foreseeable future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:264,security,model,models,264,"The main obstacle is getting good data for training. We use GIAB truth sets for human, but we would need similar quality true variants along with sequencing data in polyploid genomes, and even then to support various ploidy levels you might need to train multiple models. We also don't have enough bandwidth to prioritize this work within the team for the foreseeable future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:343,security,team,team,343,"The main obstacle is getting good data for training. We use GIAB truth sets for human, but we would need similar quality true variants along with sequencing data in polyploid genomes, and even then to support various ploidy levels you might need to train multiple models. We also don't have enough bandwidth to prioritize this work within the team for the foreseeable future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:201,usability,support,support,201,"The main obstacle is getting good data for training. We use GIAB truth sets for human, but we would need similar quality true variants along with sequencing data in polyploid genomes, and even then to support various ploidy levels you might need to train multiple models. We also don't have enough bandwidth to prioritize this work within the team for the foreseeable future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:118,energy efficiency,model,models,118,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:439,energy efficiency,model,models,439,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:454,energy efficiency,model,model,454,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:294,interoperability,specif,specific,294,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:41,security,access,access,41,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:118,security,model,models,118,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:439,security,model,models,439,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:454,security,model,model,454,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:395,testability,understand,understand,395,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:177,usability,experien,experience,177,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:282,usability,feedback,feedback,282,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:386,usability,person,person,386,"Hey, thanks for the response! I may have access to a high-quality dataset in the near future. Also, training multiple models for each level of ploidy makes sense. I've got some experience with TF and programming in general (Python and Rust, lately), so curious if you can give some feedback on specific areas that may need to be adjusted for ploidy? Or, if it would be too much for one person I understand too. I've done re-training of DV models for non-model species and have seen great improvements so far, so I'm familiar with that as well. Thanks again!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:551,energy efficiency,adapt,adapt,551,"I consulted with the team to get an idea of the effort required, and we came to the conclusion that the DeepVariant code is full of diploid assumptions, so this would likely take a lot of effort, and unfortunately it isn't something that we have enough bandwidth to advise anyone else through either. You're of course welcome to fork DeepVariant and play around with it, but it will likely require many changes to the code to make it work. It is definitely possible though. You could also consider whether other ML-based variant callers are easier to adapt to polyploid, or if any polyploid callers exist already, which could be fun to add ML on top of as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:551,integrability,adapt,adapt,551,"I consulted with the team to get an idea of the effort required, and we came to the conclusion that the DeepVariant code is full of diploid assumptions, so this would likely take a lot of effort, and unfortunately it isn't something that we have enough bandwidth to advise anyone else through either. You're of course welcome to fork DeepVariant and play around with it, but it will likely require many changes to the code to make it work. It is definitely possible though. You could also consider whether other ML-based variant callers are easier to adapt to polyploid, or if any polyploid callers exist already, which could be fun to add ML on top of as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:551,interoperability,adapt,adapt,551,"I consulted with the team to get an idea of the effort required, and we came to the conclusion that the DeepVariant code is full of diploid assumptions, so this would likely take a lot of effort, and unfortunately it isn't something that we have enough bandwidth to advise anyone else through either. You're of course welcome to fork DeepVariant and play around with it, but it will likely require many changes to the code to make it work. It is definitely possible though. You could also consider whether other ML-based variant callers are easier to adapt to polyploid, or if any polyploid callers exist already, which could be fun to add ML on top of as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:551,modifiability,adapt,adapt,551,"I consulted with the team to get an idea of the effort required, and we came to the conclusion that the DeepVariant code is full of diploid assumptions, so this would likely take a lot of effort, and unfortunately it isn't something that we have enough bandwidth to advise anyone else through either. You're of course welcome to fork DeepVariant and play around with it, but it will likely require many changes to the code to make it work. It is definitely possible though. You could also consider whether other ML-based variant callers are easier to adapt to polyploid, or if any polyploid callers exist already, which could be fun to add ML on top of as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:21,security,team,team,21,"I consulted with the team to get an idea of the effort required, and we came to the conclusion that the DeepVariant code is full of diploid assumptions, so this would likely take a lot of effort, and unfortunately it isn't something that we have enough bandwidth to advise anyone else through either. You're of course welcome to fork DeepVariant and play around with it, but it will likely require many changes to the code to make it work. It is definitely possible though. You could also consider whether other ML-based variant callers are easier to adapt to polyploid, or if any polyploid callers exist already, which could be fun to add ML on top of as well.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/519:45,usability,guidanc,guidance,45,"Ah, understood, and thanks very much for the guidance.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/519
https://github.com/google/deepvariant/issues/520:112,energy efficiency,current,currently,112,"Hi @marchoeppner , thanks for reporting this. Because the way we designed the candidate generation, deepvariant currently can't call MNPs, but will call them as separate SNPs. This is a known area for improvement, but unfortunately we haven't been able to get to it yet.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:262,deployability,updat,update,262,"Thanks for clarifying! Hopefully this can be addressed soon. The particular example I have shown here actually has fairly severe consequences for interpretation (MNP = stop gained). So this is not a minor issue. Closing this for now, but will keep an eye on the update notes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:262,safety,updat,update,262,"Thanks for clarifying! Hopefully this can be addressed soon. The particular example I have shown here actually has fairly severe consequences for interpretation (MNP = stop gained). So this is not a minor issue. Closing this for now, but will keep an eye on the update notes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:262,security,updat,update,262,"Thanks for clarifying! Hopefully this can be addressed soon. The particular example I have shown here actually has fairly severe consequences for interpretation (MNP = stop gained). So this is not a minor issue. Closing this for now, but will keep an eye on the update notes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:168,usability,stop,stop,168,"Thanks for clarifying! Hopefully this can be addressed soon. The particular example I have shown here actually has fairly severe consequences for interpretation (MNP = stop gained). So this is not a minor issue. Closing this for now, but will keep an eye on the update notes.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:41,deployability,updat,update,41,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:233,reliability,doe,does,233,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:41,safety,updat,update,41,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:41,security,updat,update,41,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:78,usability,support,support,78,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:218,usability,support,support,218,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:469,usability,prefer,preferably,469,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:490,usability,support,support,490,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:542,usability,tool,tool,542,"Hi,. I am re-opening in hope to get some update on this issue. I think adding support for MNP calling has been a community request dating back to at least 2019. And as this particular issue highlights, the lack of MNP support really does have implications for how the data can be used. . I found in several discussions that people are entirely unaware of this particular limitation in Deepvariant. . So please, at the very least make this a very visible disclaimer, or preferably implement support for MNP calling in your otherwise excellent tool.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:149,deployability,stage,stage,149,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:26,energy efficiency,current,currently,26,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:185,energy efficiency,estimat,estimate,185,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:136,modifiability,interm,intermediate,136,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:102,safety,compl,complex,102,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:220,safety,compl,complete,220,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:102,security,compl,complex,102,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:220,security,compl,complete,220,"Hi @marchoeppner . We are currently working on some approaches to better call MNPs and locations with complex variants. Those are in an intermediate stage of investigation, and I can't estimate at present when they will complete (nor give with certainty a guarantee that it will improve accuracy). For now, I will generate some benchmarks for MNP calls which might ground discussions in some quantifiable numbers.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1346,deployability,observ,observations,1346,"ich preserve sequence length, not indels), taking the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:2118,energy efficiency,current,current,2118,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:656,integrability,Filter,Filter,656,"Hello @marchoeppner . I have started to look into the MNP sites in Genome in a Bottle samples. I am taking 30x coverage PCR-Free WGS for HG001, HG002, and HG003. I am using the variant calls from DeepVariant v1.0 and GATK4 from [This sequence dataset](https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1). Looking only at MNP (and just those which preserve sequence length, not indels), taking the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other poss",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:2366,interoperability,specif,specifically,2366,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:276,performance,content,content,276,"Hello @marchoeppner . I have started to look into the MNP sites in Genome in a Bottle samples. I am taking 30x coverage PCR-Free WGS for HG001, HG002, and HG003. I am using the variant calls from DeepVariant v1.0 and GATK4 from [This sequence dataset](https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1). Looking only at MNP (and just those which preserve sequence length, not indels), taking the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other poss",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:111,testability,coverag,coverage,111,"Hello @marchoeppner . I have started to look into the MNP sites in Genome in a Bottle samples. I am taking 30x coverage PCR-Free WGS for HG001, HG002, and HG003. I am using the variant calls from DeepVariant v1.0 and GATK4 from [This sequence dataset](https://www.biorxiv.org/content/10.1101/2020.12.11.422022v1). Looking only at MNP (and just those which preserve sequence length, not indels), taking the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other poss",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1346,testability,observ,observations,1346,"ich preserve sequence length, not indels), taking the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:2144,testability,plan,plan,2144,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:2267,testability,understand,understand,2267,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1860,usability,learn,learned,1860,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:2235,usability,support,support,2235,"ing the union of the Truth Set with any MNP variant called in either GATK or DeepVariant, here is the Hap.py that I see:. <google-sheets-html-origin><style type=""text/css""><!--td {border: 1px solid #cccccc;}br {mso-data-placement:same-cell;}--></style>.   | Filter | TRUTH.TOTAL | TRUTH.TP | TRUTH.FN | QUERY.FP | FP.gt | FP.al | METRIC.Recall | METRIC.Precision | METRIC.F1_Score. -- | -- | -- | -- | -- | -- | -- | -- | -- | -- | --. HG001-DV | PASS | 27307 | 26199 | 1108 | 510 | 95 | 10 | 0.9594 | 0.9809 | 0.9700. HG001-GATK | PASS | 27307 | 26258 | 1049 | 1746 | 153 | 17 | 0.9616 | 0.9377 | 0.9495. HG002-DV | PASS | 28662 | 27505 | 1157 | 613 | 77 | 3 | 0.9596 | 0.9782 | 0.9688. HG002-GATK | PASS | 28662 | 27539 | 1123 | 2073 | 133 | 7 | 0.9608 | 0.9300 | 0.9452. HG003-DV | PASS | 28274 | 27234 | 1040 | 588 | 73 | 7 | 0.9632 | 0.9789 | 0.9710. HG003-GATK | PASS | 28274 | 27188 | 1086 | 2060 | 156 | 8 | 0.9616 | 0.9296 | 0.9453. A few observations from these metrics:. 1. For both GATK and DeepVariant, MNPs are notably harder to call. F1 is 0.945-0.97, while we expect F1 of around 0.9945 for DeepVariant at 30x with Illumina. 2. DeepVariant and GATK4 have fairly similar recall, with DeepVariant being higher in recall in 1 sample and GATK in the other 2. 3. DeepVariant has noticeably higher precision (0.98 vs 0.93). From this, I suspect that there is at least a few factors that make MNPs more difficult to call. I suspect that DeepVariant has learned some of those factors and is more conservative to call MNPs, even when they might look like real calls. There are several other possible explanations (e.g. that hap.py has trouble in the comparison process correctly annotating sites). Following this current set of metrics, I plan to inspect several of the correctly and incorrectly called variants in IGV with their support and see if I can better understand what factors are making MNPs more difficult to call, and if it seems like there are any specifically addressable issues.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:331,availability,reliab,reliably,331,"Thanks for looking into this. I was under the impression that Deepvariant cannot call MNPs period. It sounded like a technical decision inside the code to look at each variant site independently and break potential MNPs up into individual SNPs. Did I get that wrong and would that mean that DV can infact call MNPs, but not always reliably?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:331,reliability,reliab,reliably,331,"Thanks for looking into this. I was under the impression that Deepvariant cannot call MNPs period. It sounded like a technical decision inside the code to look at each variant site independently and break potential MNPs up into individual SNPs. Did I get that wrong and would that mean that DV can infact call MNPs, but not always reliably?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:269,deployability,compos,compose,269,"DeepVariant calls the individual positions in an MNP separately. So at Position N it makes a decision whether it is a SNP or not. Then at Position N+1 it makes an independent decision. So it can call them, but it will express them in separate rows in the VCF. It won't compose them into a single event (and this would have to be done post-calling by phasing the VCF). In addition, it can occur that the decision made by the neural network at the different positions results in the sites getting called separately (e.g. if a call is very borderline at position N and N+1, it may get called a SNP and N but reference at N+1). We've thought this could be an issue, but haven't tried to quantify the effect. For F1 of 0.94-0.97, there is likely some other factor which is making calling harder here, because that is a fairly large effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:296,integrability,event,event,296,"DeepVariant calls the individual positions in an MNP separately. So at Position N it makes a decision whether it is a SNP or not. Then at Position N+1 it makes an independent decision. So it can call them, but it will express them in separate rows in the VCF. It won't compose them into a single event (and this would have to be done post-calling by phasing the VCF). In addition, it can occur that the decision made by the neural network at the different positions results in the sites getting called separately (e.g. if a call is very borderline at position N and N+1, it may get called a SNP and N but reference at N+1). We've thought this could be an issue, but haven't tried to quantify the effect. For F1 of 0.94-0.97, there is likely some other factor which is making calling harder here, because that is a fairly large effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:269,modifiability,compos,compose,269,"DeepVariant calls the individual positions in an MNP separately. So at Position N it makes a decision whether it is a SNP or not. Then at Position N+1 it makes an independent decision. So it can call them, but it will express them in separate rows in the VCF. It won't compose them into a single event (and this would have to be done post-calling by phasing the VCF). In addition, it can occur that the decision made by the neural network at the different positions results in the sites getting called separately (e.g. if a call is very borderline at position N and N+1, it may get called a SNP and N but reference at N+1). We've thought this could be an issue, but haven't tried to quantify the effect. For F1 of 0.94-0.97, there is likely some other factor which is making calling harder here, because that is a fairly large effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:431,performance,network,network,431,"DeepVariant calls the individual positions in an MNP separately. So at Position N it makes a decision whether it is a SNP or not. Then at Position N+1 it makes an independent decision. So it can call them, but it will express them in separate rows in the VCF. It won't compose them into a single event (and this would have to be done post-calling by phasing the VCF). In addition, it can occur that the decision made by the neural network at the different positions results in the sites getting called separately (e.g. if a call is very borderline at position N and N+1, it may get called a SNP and N but reference at N+1). We've thought this could be an issue, but haven't tried to quantify the effect. For F1 of 0.94-0.97, there is likely some other factor which is making calling harder here, because that is a fairly large effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:431,security,network,network,431,"DeepVariant calls the individual positions in an MNP separately. So at Position N it makes a decision whether it is a SNP or not. Then at Position N+1 it makes an independent decision. So it can call them, but it will express them in separate rows in the VCF. It won't compose them into a single event (and this would have to be done post-calling by phasing the VCF). In addition, it can occur that the decision made by the neural network at the different positions results in the sites getting called separately (e.g. if a call is very borderline at position N and N+1, it may get called a SNP and N but reference at N+1). We've thought this could be an issue, but haven't tried to quantify the effect. For F1 of 0.94-0.97, there is likely some other factor which is making calling harder here, because that is a fairly large effect.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:136,availability,operat,operate,136,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:339,availability,avail,available,339,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:114,energy efficiency,predict,prediction,114,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:233,energy efficiency,predict,predictions,233,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:339,reliability,availab,available,339,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:114,safety,predict,prediction,114,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:233,safety,predict,predictions,233,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:339,safety,avail,available,339,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:339,security,availab,available,339,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:349,usability,tool,tools,349,"Gottcha. Basically, my wish would be for DV to emit MNPs as single VCF line. This is because basically all effect prediction algorithms operate that way. It is technically possible to analyse phased VCFs and get protein-level effect predictions that will look at in-phase SNPs within a coding sequence (Haplosaurus, Bcftools CSQ), but the available tools for that are very limited in what they can annotate and report back. And they are generally not used (much) in (clinical) variant interpretation for that reason. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:244,availability,error,errors,244,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:345,availability,error,errors,345,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:394,availability,error,errors,394,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:413,energy efficiency,reduc,reduced,413,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:79,integrability,event,events,79,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:244,performance,error,errors,244,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:345,performance,error,errors,345,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:394,performance,error,errors,394,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:244,safety,error,errors,244,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:345,safety,error,errors,345,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:394,safety,error,errors,394,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:244,usability,error,errors,244,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:329,usability,help,help,329,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:345,usability,error,errors,345,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:394,usability,error,errors,394,"Hi @marchoeppner . Converting the representation from adjacent lines to single events is something we will look at. It won't necessarily be an easy change. I think the next thing I will do is to look at why both DeepVariant and GATK are making errors on this set and see if it looks like changing the representation is likely to help with those errors, or if something else is going on. If the errors can also be reduced, then this looks more interesting as something to do sooner rather than later.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:87,availability,sli,slicing,87,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:706,deployability,contain,contain,706,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:757,energy efficiency,current,currently,757,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:779,energy efficiency,model,models,779,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1021,energy efficiency,model,models,1021,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1191,energy efficiency,model,model,1191,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:985,integrability,filter,filters,985,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1038,integrability,filter,filters,1038,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:314,interoperability,architectur,architecture,314,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1049,interoperability,specif,specific,1049,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:260,modifiability,layer,layers,260,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:474,performance,network,networks,474,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:610,performance,network,network,610,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1079,performance,network,network,1079,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:87,reliability,sli,slicing,87,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:246,safety,input,inputs,246,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:443,safety,input,inputs,443,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:664,safety,input,input,664,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:474,security,network,networks,474,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:610,security,network,network,610,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:779,security,model,models,779,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1021,security,model,models,1021,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1079,security,network,network,1079,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1191,security,model,model,1191,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:246,usability,input,inputs,246,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:443,usability,input,inputs,443,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:664,usability,input,input,664,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/520:1031,usability,custom,custom,1031,"The thing is that InceptionV3 works on one combined tensor (using all channels), while slicing them together across different convolutions. Spatial information and cross-channel information can be important if you want to train on those types of inputs, where layers of [depthwise separable convolutions (Xception architecture)](https://openaccess.thecvf.com/content_cvpr_2017/papers/Chollet_Xception_Deep_Learning_CVPR_2017_paper.pdf) across inputs and [squeeze-excitation networks (SEnet) ](https://arxiv.org/pdf/1709.01507.pdf) become useful in boosting features that travel together. The thing is that the network would need to be tweaked by applying separate input convolutions for only channels that contain the spatial information and not others, as currently DeepVariant models are trained with a collection of channels of which some are only binary possibly only having some effect with more data as the other channels normalize -- though they might become more purposeful as filters. Using additional attention models or custom filters at specific locations across the network can highlight features of interest like variants that possibly travel together, that trigger a separate model flow for the resultant output of interest.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/520
https://github.com/google/deepvariant/issues/521:177,deployability,scale,scaled,177,"@GuillaumeHolley responding to your comment 2 above, I believe the corresponding DEEPVARIANT_OUTPUT.vcf.gz is malformatted -- it should have 3 PL values (corresponding to Phred-scaled likelihoods of 0/0, 0/1, 1/1 genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:177,energy efficiency,scale,scaled,177,"@GuillaumeHolley responding to your comment 2 above, I believe the corresponding DEEPVARIANT_OUTPUT.vcf.gz is malformatted -- it should have 3 PL values (corresponding to Phred-scaled likelihoods of 0/0, 0/1, 1/1 genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:177,modifiability,scal,scaled,177,"@GuillaumeHolley responding to your comment 2 above, I believe the corresponding DEEPVARIANT_OUTPUT.vcf.gz is malformatted -- it should have 3 PL values (corresponding to Phred-scaled likelihoods of 0/0, 0/1, 1/1 genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:177,performance,scale,scaled,177,"@GuillaumeHolley responding to your comment 2 above, I believe the corresponding DEEPVARIANT_OUTPUT.vcf.gz is malformatted -- it should have 3 PL values (corresponding to Phred-scaled likelihoods of 0/0, 0/1, 1/1 genotypes).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:164,interoperability,share,share,164,"Hi @GuillaumeHolley , thanks for reporting this. We'll need to look into our data and see if we can find an example like this as well. If it possible for to you to share a small, reproducible setting (with commands), that will also help us a lot in debugging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:206,usability,command,commands,206,"Hi @GuillaumeHolley , thanks for reporting this. We'll need to look into our data and see if we can find an example like this as well. If it possible for to you to share a small, reproducible setting (with commands), that will also help us a lot in debugging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:232,usability,help,help,232,"Hi @GuillaumeHolley , thanks for reporting this. We'll need to look into our data and see if we can find an example like this as well. If it possible for to you to share a small, reproducible setting (with commands), that will also help us a lot in debugging.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:70,interoperability,share,share,70,"Hi @GuillaumeHolley , checking again:. If you have an easy example to share for reproducing this, that will be great. . If not, I can also go through some of our existing VCF files and look for this pattern. It might take me a while to get to this. I can keep this open until when we have time to take a look.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:289,performance,time,time,289,"Hi @GuillaumeHolley , checking again:. If you have an easy example to share for reproducing this, that will be great. . If not, I can also go through some of our existing VCF files and look for this pattern. It might take me a while to get to this. I can keep this open until when we have time to take a look.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:38,deployability,updat,update,38,"Hi @GuillaumeHolley ,. to give you an update, I haven't had time to go search for an example. But I'll keep this open in case you want to share an example (or when I have a chance to find one). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:138,interoperability,share,share,138,"Hi @GuillaumeHolley ,. to give you an update, I haven't had time to go search for an example. But I'll keep this open in case you want to share an example (or when I have a chance to find one). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:60,performance,time,time,60,"Hi @GuillaumeHolley ,. to give you an update, I haven't had time to go search for an example. But I'll keep this open in case you want to share an example (or when I have a chance to find one). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:38,safety,updat,update,38,"Hi @GuillaumeHolley ,. to give you an update, I haven't had time to go search for an example. But I'll keep this open in case you want to share an example (or when I have a chance to find one). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:38,security,updat,update,38,"Hi @GuillaumeHolley ,. to give you an update, I haven't had time to go search for an example. But I'll keep this open in case you want to share an example (or when I have a chance to find one). Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:128,interoperability,share,share,128,"Hi @pichuan,. I apologize for the delay. I'll try to get a small BAM with which the issue can be reproduced. I would rather not share the BAM file here, is there an email address I can use to share the information? Thanks,. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:192,interoperability,share,share,192,"Hi @pichuan,. I apologize for the delay. I'll try to get a small BAM with which the issue can be reproduced. I would rather not share the BAM file here, is there an email address I can use to share the information? Thanks,. Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:85,usability,close,close,85,"Hi @GuillaumeHolley ,. This issue needs to be taken care of from PEPPER's side. I'll close this issue from here and open up on PEPPER's github. Sorry that it's taking a bit longer than expected, PEPPER is going through a transition but someone is actively looking into this issue to fix it.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:267,availability,error,error,267,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:131,integrability,filter,filtering,131,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:276,integrability,filter,filtering,276,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:267,performance,error,error,267,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:267,safety,error,error,267,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:223,usability,help,helps,223,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:267,usability,error,error,267,"@GuillaumeHolley ,. After working on this for a while, it looks like the solution isn't that easy. On your end, can you please try filtering all the `NoCall` variants from the gvcf file as a post-processing and see if that helps? I was able to get rid of the GLNexus error by filtering `NoCall` variants with `bcftools`.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:111,integrability,filter,filtered,111,"Hi @kishwarshafin,. Thanks for the feedback, I actually forgot to get back to you about this but I have indeed filtered out the `NoCall` for the small cohort I have after your early feedback and it indeed solved this issue. Good luck with solving this! Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:35,usability,feedback,feedback,35,"Hi @kishwarshafin,. Thanks for the feedback, I actually forgot to get back to you about this but I have indeed filtered out the `NoCall` for the small cohort I have after your early feedback and it indeed solved this issue. Good luck with solving this! Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/521:182,usability,feedback,feedback,182,"Hi @kishwarshafin,. Thanks for the feedback, I actually forgot to get back to you about this but I have indeed filtered out the `NoCall` for the small cohort I have after your early feedback and it indeed solved this issue. Good luck with solving this! Guillaume",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/521
https://github.com/google/deepvariant/issues/522:32,availability,error,error,32,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:106,availability,error,error,106,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:258,availability,down,download,258,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:318,availability,down,download,318,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:365,deployability,log,login,365,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:112,integrability,messag,message,112,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:112,interoperability,messag,message,112,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:220,modifiability,concern,concerns,220,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:32,performance,error,error,32,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:106,performance,error,error,106,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:130,performance,network,network,130,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:32,safety,error,error,32,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:106,safety,error,error,106,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:213,safety,safe,safety,213,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:340,safety,input,input,340,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:365,safety,log,login,365,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:7,security,team,team,7,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:130,security,network,network,130,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:365,security,log,login,365,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:220,testability,concern,concerns,220,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:365,testability,log,login,365,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:12,usability,help,helped,12,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:32,usability,error,error,32,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:106,usability,error,error,106,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:189,usability,close,closed,189,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/issues/522:340,usability,input,input,340,"My HPC team helped me with this error, just thought I'd add it here in case future people do this: . ""The error message ""connect: network is unreachable "" is due to the compute nodes being closed to the internet (safety concerns). This means that you cannot download files while on the compute nodes. Our advice is to download any required input files first on the login nodes and then point to them in the job script.""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/522
https://github.com/google/deepvariant/pull/523:53,deployability,Updat,Update,53,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:96,deployability,updat,updated,96,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:256,deployability,instal,install,256,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:273,deployability,version,versions,273,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:307,deployability,instal,installation,307,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:325,deployability,instal,install,325,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:369,deployability,continu,continue,369,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:273,integrability,version,versions,273,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:285,integrability,compon,components,285,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:285,interoperability,compon,components,285,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:273,modifiability,version,versions,273,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:285,modifiability,compon,components,285,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:53,safety,Updat,Update,53,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:96,safety,updat,updated,96,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:53,security,Updat,Update,53,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:96,security,updat,updated,96,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:199,usability,confirm,confirm,199,"Hi @dkurt , sorry it took me a while to get to this. Update: I've run internally once with your updated code. So far I've only run on one WES example so I don't have full timing stats yet. I want to confirm that it's expected that I'm seeing:. ```. Please install required versions of components or run pip installation. pip install openvino-dev[tensorflow]. ```. I'll continue to look into the runtime and let you know.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:83,deployability,version,version,83,"@pichuan, thank you! I also seen this warning locally but it just about TensorFlow version. If the conversion finished with `[SUCCESS]` - everything is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:83,integrability,version,version,83,"@pichuan, thank you! I also seen this warning locally but it just about TensorFlow version. If the conversion finished with `[SUCCESS]` - everything is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:99,interoperability,convers,conversion,99,"@pichuan, thank you! I also seen this warning locally but it just about TensorFlow version. If the conversion finished with `[SUCCESS]` - everything is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:83,modifiability,version,version,83,"@pichuan, thank you! I also seen this warning locally but it just about TensorFlow version. If the conversion finished with `[SUCCESS]` - everything is fine.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:17,safety,test,test,17,Got it. My first test run did finish successfully and the hap.py numbers are the same as before. I'm now running a few bigger runs to take a look at the runtime.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/pull/523:17,testability,test,test,17,Got it. My first test run did finish successfully and the hap.py numbers are the same as before. I'm now running a few bigger runs to take a look at the runtime.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/pull/523
https://github.com/google/deepvariant/issues/524:279,availability,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:380,availability,cluster,cluster,380,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:279,deployability,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:330,deployability,fail,fails,330,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:350,deployability,stage,stage,350,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:380,deployability,cluster,cluster,380,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:279,energy efficiency,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:363,integrability,sub,submit,363,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:279,reliability,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:330,reliability,fail,fails,330,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:279,safety,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:279,testability,monitor,monitor,279,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:503,usability,support,support,503,"Hi,. As reported above I can see a bunch of small files (30-40 Mb total) written in TMPDIR. If I look in the folder when deepvariant is running I can see files like these. `Bazel.runfiles_6nvtcv_j __pycache__ tmp8rz89h3g.py tmpglc9d5x3.py tmph9ntzkbx`. I will try another run to monitor when exactly they are created, but the job fails at very early stage when I submit it to the cluster, so I assume these are written during make_examples which is the first step in run deepvariant I think. Thanks for support!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:52,integrability,messag,message,52,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:52,interoperability,messag,message,52,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:547,interoperability,share,share,547,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:224,modifiability,interm,intermediate,224,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:76,testability,understand,understand,76,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:294,usability,user,users,294,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:558,usability,command,command,558,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:597,usability,document,documentation,597,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:637,usability,user,users,637,"Ah I see. Sorry I missed that part in your original message. And, I think I understand your question better now. . --intermediate_results_dir isn't designed to capture all temp files from DeepVariant. It's for capturing the intermediate outputs (from make_examples, call_variants) in case that users need to re-use them later on. In your case, using your workaround of setting TMPDIR actually makes sense to me. From your description, it also seems like it's related to your system setting. If you think this is going to be a common issue, please share your command and I'm happy to add it to our documentation as a workaround for other users.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:1101,availability,operat,operation,1101,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:88,deployability,contain,container,88,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:125,deployability,automat,automatically,125,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:251,deployability,stage,staged,251,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:446,deployability,log,login,446,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:658,deployability,contain,container,658,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:700,deployability,configurat,configuration,700,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:139,integrability,configur,configures,139,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:555,integrability,sub,submitted,555,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:700,integrability,configur,configuration,700,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:1005,integrability,sub,subfolder,1005,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:38,interoperability,specif,specific,38,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:161,interoperability,bind,bindings,161,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:396,interoperability,standard,standard,396,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:499,interoperability,specif,specific,499,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:139,modifiability,configur,configures,139,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:161,modifiability,bind,bindings,161,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:700,modifiability,configur,configuration,700,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:972,modifiability,variab,variable,972,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:1159,reliability,doe,does,1159,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:278,safety,input,inputs,278,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:446,safety,log,login,446,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:139,security,configur,configures,139,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:446,security,log,login,446,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:700,security,configur,configuration,700,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:125,testability,automat,automatically,125,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:446,testability,log,login,446,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:1063,testability,context,context,1063,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:278,usability,input,inputs,278,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:302,usability,indicat,indicated,302,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:854,usability,command,command,854,"I agree this issue is probably system specific. . This creates a problem when using the container in nextflow since nextflow automatically configures few folder bindings when it prepares the run, namely the working directory, the directories of files staged into the process as inputs and the temp dir indicated by $TMPDIR. Since it prepares all the scripts in advance, the $TMPDIR points to the standard /tmp location if I start nextflow from a login node, while in my system this is set to a node specific scratch space (/local scratch) when the job is submitted to a computing node by SLURM. Thus, I end up having the tmp dir not correctly mounted in the container. I'm not sure how common such a configuration is, so maybe it's a problem affecting just me and few others. What I've done is to add a line like this before the actual `run_deepvariant` command in my `script` section in the Nextflow process:. `export TMPDIR=""$PWD/tmp_dir""`. This overwrites the original variable and set the TMPDIR to a subfolder in the working directory. It works fine in this context since deepvariant is the only operation running in the process and thus changing TMPDIR does not interfere with anything else.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:377,deployability,releas,release,377,"Thank you @edg1983 . I will plan to add this section to our FAQ.md:. ---. ## Singularity related questions:. ### `TMPDIR`. If your run with Singularity is having issues with `TMPDIR`, try adding this to your command:. ```bash. export TMPDIR=""$PWD/tmp_dir"". ```. See https://github.com/google/deepvariant/issues/524#issuecomment-1067597987. ---. This should show up in our next release. Thanks for providing this information! If you have more suggestions, let me know. I'll close this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:28,testability,plan,plan,28,"Thank you @edg1983 . I will plan to add this section to our FAQ.md:. ---. ## Singularity related questions:. ### `TMPDIR`. If your run with Singularity is having issues with `TMPDIR`, try adding this to your command:. ```bash. export TMPDIR=""$PWD/tmp_dir"". ```. See https://github.com/google/deepvariant/issues/524#issuecomment-1067597987. ---. This should show up in our next release. Thanks for providing this information! If you have more suggestions, let me know. I'll close this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:208,usability,command,command,208,"Thank you @edg1983 . I will plan to add this section to our FAQ.md:. ---. ## Singularity related questions:. ### `TMPDIR`. If your run with Singularity is having issues with `TMPDIR`, try adding this to your command:. ```bash. export TMPDIR=""$PWD/tmp_dir"". ```. See https://github.com/google/deepvariant/issues/524#issuecomment-1067597987. ---. This should show up in our next release. Thanks for providing this information! If you have more suggestions, let me know. I'll close this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:473,usability,close,close,473,"Thank you @edg1983 . I will plan to add this section to our FAQ.md:. ---. ## Singularity related questions:. ### `TMPDIR`. If your run with Singularity is having issues with `TMPDIR`, try adding this to your command:. ```bash. export TMPDIR=""$PWD/tmp_dir"". ```. See https://github.com/google/deepvariant/issues/524#issuecomment-1067597987. ---. This should show up in our next release. Thanks for providing this information! If you have more suggestions, let me know. I'll close this issue for now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:73,energy efficiency,current,current,73,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:346,energy efficiency,current,current,346,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:498,safety,input,input,498,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:629,safety,input,input,629,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:638,safety,input,input,638,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:816,safety,input,input,816,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:871,safety,input,input,871,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:58,usability,command,command,58,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:354,usability,command,command,354,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:498,usability,input,input,498,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:629,usability,input,input,629,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:638,usability,input,input,638,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:816,usability,input,input,816,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:871,usability,input,input,871,"about this tmp_dir location, when running the docker demo command in the current folder. do I set TMPDIR to a host physical folder that I create? `export TMPDIR=""$PWD/tmp_dir""`. or to a docker internal folder mount obtained after create a folder on the host side and mounting it as /tmp_dir with -v as shown below. `export TMPDIR=""/tmp_dir""`. my current command includes `--intermediate_results_dir /temp_dir` which is apparently not yet working:. ```. export TMPDIR=<chose from above>. for bam in input/*_rawmappings_recal.bam; do. pfx=$(basename ${bam%_rawmappings_recal.bam}). BIN_VERSION=""1.3.0"". sudo docker run \. -v ""$PWD/input"":""/input"" \. -v ""$PWD/output"":""/output"" \. -v ""$PWD/tmp_dir"":""/tmp_dir"" \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --model_type=WGS \. --ref=/input/Gallus_gallus.GRCg6a.dna.toplevel.fa \. --reads=/input/""${pfx}""_rawmappings_recal.bam \. --output_vcf=/output/""${pfx}"".vcf \. --output_gvcf=/output/""${pfx}"".g.vcf \. --num_shards=""${nthr}"" \. --intermediate_results_dir /temp_dir \. --logging_dir=/output/""${pfx}""_logs \. --dry_run=false. done. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:191,performance,content,content,191,"Hi @splaisan . Your question is using docker, which is a bit different from the discussion earlier, I believe. To use --intermediate_results_dir, it indicates you probably want to access the content there later. So, I'd recommend that you write it to an output file that you mounted with `-v`. For example, given that you have `-v ""$PWD/tmp_dir"":""/tmp_dir""`, maybe try seeting:. ` --intermediate_results_dir /tmp_dir`, which should write output to `$PWD/tmp_dir` once you're done? (I noticed you wrote `--intermediate_results_dir /temp_dir`, which was not actually mounted. Not sure if that's a typo or not.). Hope this helps. I'm going to close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:180,security,access,access,180,"Hi @splaisan . Your question is using docker, which is a bit different from the discussion earlier, I believe. To use --intermediate_results_dir, it indicates you probably want to access the content there later. So, I'd recommend that you write it to an output file that you mounted with `-v`. For example, given that you have `-v ""$PWD/tmp_dir"":""/tmp_dir""`, maybe try seeting:. ` --intermediate_results_dir /tmp_dir`, which should write output to `$PWD/tmp_dir` once you're done? (I noticed you wrote `--intermediate_results_dir /temp_dir`, which was not actually mounted. Not sure if that's a typo or not.). Hope this helps. I'm going to close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:149,usability,indicat,indicates,149,"Hi @splaisan . Your question is using docker, which is a bit different from the discussion earlier, I believe. To use --intermediate_results_dir, it indicates you probably want to access the content there later. So, I'd recommend that you write it to an output file that you mounted with `-v`. For example, given that you have `-v ""$PWD/tmp_dir"":""/tmp_dir""`, maybe try seeting:. ` --intermediate_results_dir /tmp_dir`, which should write output to `$PWD/tmp_dir` once you're done? (I noticed you wrote `--intermediate_results_dir /temp_dir`, which was not actually mounted. Not sure if that's a typo or not.). Hope this helps. I'm going to close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:620,usability,help,helps,620,"Hi @splaisan . Your question is using docker, which is a bit different from the discussion earlier, I believe. To use --intermediate_results_dir, it indicates you probably want to access the content there later. So, I'd recommend that you write it to an output file that you mounted with `-v`. For example, given that you have `-v ""$PWD/tmp_dir"":""/tmp_dir""`, maybe try seeting:. ` --intermediate_results_dir /tmp_dir`, which should write output to `$PWD/tmp_dir` once you're done? (I noticed you wrote `--intermediate_results_dir /temp_dir`, which was not actually mounted. Not sure if that's a typo or not.). Hope this helps. I'm going to close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:640,usability,close,close,640,"Hi @splaisan . Your question is using docker, which is a bit different from the discussion earlier, I believe. To use --intermediate_results_dir, it indicates you probably want to access the content there later. So, I'd recommend that you write it to an output file that you mounted with `-v`. For example, given that you have `-v ""$PWD/tmp_dir"":""/tmp_dir""`, maybe try seeting:. ` --intermediate_results_dir /tmp_dir`, which should write output to `$PWD/tmp_dir` once you're done? (I noticed you wrote `--intermediate_results_dir /temp_dir`, which was not actually mounted. Not sure if that's a typo or not.). Hope this helps. I'm going to close this issue now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/524:93,usability,help,help,93,"Thanks @pichuan, it is a typo indeed, I meant /tmp_dir. nice catch! and thanks for your kind help",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/524
https://github.com/google/deepvariant/issues/526:829,availability,servic,service,829,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:608,deployability,resourc,resources,608,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:829,deployability,servic,service,829,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:594,energy efficiency,cloud,cloud,594,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:608,energy efficiency,resourc,resources,608,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:708,energy efficiency,Cloud,Cloud,708,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:738,energy efficiency,cloud,cloud,738,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:823,energy efficiency,cloud,cloud,823,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1189,energy efficiency,core,cores,1189,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1239,energy efficiency,core,cores,1239,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1437,energy efficiency,CPU,CPU,1437,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:829,integrability,servic,service,829,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:988,integrability,batch,batch,988,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:714,interoperability,Platform,Platform,714,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:829,modifiability,servic,service,829,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1288,modifiability,paramet,parameter,1288,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:555,performance,parallel,parallelize,555,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:600,performance,compute resourc,compute resources,600,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:988,performance,batch,batch,988,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1061,performance,parallel,parallelizing,1061,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1437,performance,CPU,CPU,1437,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:79,reliability,Pra,Practices,79,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:173,reliability,pra,practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration,173,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:608,safety,resourc,resources,608,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:630,security,access,access,630,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1255,security,control,controlled,1255,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:608,testability,resourc,resources,608,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1255,testability,control,controlled,1255,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1391,testability,simpl,simple,1391,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1391,usability,simpl,simple,1391,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/526:1524,usability,help,helps,1524,"Hi Aman,. Thank you for reaching out to us. As you've read in our [Cohort Best Practices](https://github.com/google/deepvariant/blob/r1.3/docs/trio-merge-case-study.md#best-practices-for-multi-sample-variant-calling-with-deepvariant-wes-trio-demonstration), generating a cohort variant callset using DeepVariant includes two separate steps:. 1. Running DeepVariant on all sample reads to generate gVCF files, one per each sample. 2. Running GLnexus on the gVCFs using the provided `DeepVariantWGS` or `DeepVariantWES`. For the first step, the best way to parallelize computation would be using cloud compute resources if you have access to them. You can find instructions on how to run DeepVariant on Google Cloud Platform [here](https://cloud.google.com/life-sciences/docs/tutorials/deepvariant), or you can use any other cloud service providers using our DeepVariant docker [images](https://github.com/google/deepvariant#how-to-run-deepvariant), to run DeepVariant on each sample (or a batch of samples) separately in multiple machines. I would not recommend parallelizing DeepVariant runs over samples in a single machine though, since a single run of DeepVariant already uses multiple cores in the `make_examples` step - the number of cores to use is controlled by the `--num_shards` parameter. Once you've generated all ~200 gVCFs, one for each sample, the second step should be pretty simple. A single machine with relatively good CPU/RAM capacity should be able to handle merging 200 gVCFs using GLnexus. I hope this helps. Best,. Ted",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/526
https://github.com/google/deepvariant/issues/527:174,availability,slo,slower,174,"Hi @amyhouseman . It is not required that you provide a BED file, but then you'll end up having to process a lot more data if you don't filter with a BED file (and it's much slower). For WES, I recommend that you use a BED file for the capture regions. If you want to pad the BED file a bit before using, you can. Closing this issue. Feel free to open again if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:136,integrability,filter,filter,136,"Hi @amyhouseman . It is not required that you provide a BED file, but then you'll end up having to process a lot more data if you don't filter with a BED file (and it's much slower). For WES, I recommend that you use a BED file for the capture regions. If you want to pad the BED file a bit before using, you can. Closing this issue. Feel free to open again if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:174,reliability,slo,slower,174,"Hi @amyhouseman . It is not required that you provide a BED file, but then you'll end up having to process a lot more data if you don't filter with a BED file (and it's much slower). For WES, I recommend that you use a BED file for the capture regions. If you want to pad the BED file a bit before using, you can. Closing this issue. Feel free to open again if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:155,availability,slo,slop,155,"@amyhouseman Sometimes people decide to extend the regions in the BED files a bit, something like: https://bedtools.readthedocs.io/en/latest/content/tools/slop.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:40,modifiability,exten,extend,40,"@amyhouseman Sometimes people decide to extend the regions in the BED files a bit, something like: https://bedtools.readthedocs.io/en/latest/content/tools/slop.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:141,performance,content,content,141,"@amyhouseman Sometimes people decide to extend the regions in the BED files a bit, something like: https://bedtools.readthedocs.io/en/latest/content/tools/slop.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:155,reliability,slo,slop,155,"@amyhouseman Sometimes people decide to extend the regions in the BED files a bit, something like: https://bedtools.readthedocs.io/en/latest/content/tools/slop.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:149,usability,tool,tools,149,"@amyhouseman Sometimes people decide to extend the regions in the BED files a bit, something like: https://bedtools.readthedocs.io/en/latest/content/tools/slop.html",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:95,availability,down,download,95,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:680,availability,error,error,680,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:712,availability,error,error,712,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1604,availability,error,error,1604," module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2699,availability,error,error,2699,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:197,deployability,log,login,197,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:455,deployability,FAIL,FAIL,455,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:608,deployability,modul,module,608,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:622,deployability,modul,module,622,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:644,deployability,modul,module,644,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:925,deployability,contain,containers,925,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1980,deployability,fail,failed,1980,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:598,energy efficiency,cpu,cpu,598,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:629,energy efficiency,load,load,629,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:651,energy efficiency,load,load,651,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:429,integrability,event,events,429,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:608,modifiability,modul,module,608,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:622,modifiability,modul,module,622,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:644,modifiability,modul,module,644,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1540,modifiability,interm,intermediateresults,1540,"-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_ou",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2330,modifiability,interm,intermediateresults,2330,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2485,modifiability,interm,intermediateresults,2485,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:565,performance,time,time,565,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:598,performance,cpu,cpu,598,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:629,performance,load,load,629,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:634,performance,parallel,parallel,634,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:651,performance,load,load,651,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:680,performance,error,error,680,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:712,performance,error,error,712,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:857,performance,parallel,parallel,857,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1604,performance,error,error,1604," module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1961,performance,parallel,parallel,1961,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2699,performance,error,error,2699,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:455,reliability,FAIL,FAIL,455,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1980,reliability,fail,failed,1980,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:197,safety,log,login,197,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:608,safety,modul,module,608,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:622,safety,modul,module,622,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:644,safety,modul,module,644,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:680,safety,error,error,680,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:712,safety,error,error,712,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1604,safety,error,error,1604," module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2699,safety,error,error,2699,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:197,security,log,login,197,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:197,testability,log,login,197,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:482,usability,user,user,482,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:680,usability,error,error,680,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:712,usability,error,error,712,"**Thank you!** . **Once adding in the location of the bed file, which is definitely not empty (download link for bed file here: https://we.tl/t-7EXAoGz8RT). using this code:** . ```. #!/bin/bash --login. #SBATCH -J AmyHouseman_deepvariant. #SBATCH -o %x.stdout.%J.%N. #SBATCH -e %x.stderr.%J.%N. #SBATCH --ntasks=1. #SBATCH --ntasks-per-node=1. #SBATCH -p c_compute_wgp. #SBATCH --account=scw1581. #SBATCH --mail-type=ALL # Mail events (NONE, BEGIN, END, FAIL, ALL). #SBATCH --mail-user=HousemanA@cardiff.ac.uk # Where to send mail. #SBATCH --array=1-33. #SBATCH --time=72:00:00. #SBATCH --mem-per-cpu=64GB. module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepva",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:1604,usability,error,error,1604," module purge. module load parallel. module load singularity. # Set bash error trapping to exit on first error. set -eu. cd /scratch/c.c21087028/. sed -n ""${SLURM_ARRAY_TASK_ID}p"" Polyposis_Exome_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2699,usability,error,error,2699,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:2792,usability,help,help,2792,"_Analysis/fastp/All_fastp_input/List_of_33_exome_IDs | parallel -j 1 ""singularity run -B /usr/lib/locale/:/usr/lib/locale/ containers/deepvariant_1.3.0.sif /opt/deepvariant/bin/run_deepvariant --model_type=WES \. --ref=Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz \. --reads=Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/{}PE_markedduplicates.bam \. --regions=Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed \. --output_vcf=Polyposis_Exome_Analysis/deepvariant/vcf/{}PE_output.vcf.gz \. --output_gvcf=Polyposis_Exome_Analysis/deepvariant/gvcf/{}PE_output.vcf.gz \. --intermediate_results_dir=Polyposis_Exome_Analysis/deepvariant/intermediateresults/{}PE_output_intermediate"". ```. **I get the error:** . . ```. raise ValueError('The regions to call is empty. Check your --regions and '. ValueError: The regions to call is empty. Check your --regions and --exclude_regions flags to make sure they are not resulting in set of empty region to process. This also happens if you use ""chr20"" for a BAM where contig names don't have ""chr""s (or vice versa). parallel: This job failed:. /opt/deepvariant/bin/make_examples --mode calling --ref Polyposis_Exome_Analysis/bwa/index/indexhumanrefseq_output/samtools_faidx/GRCh38_latest_genomic.fa.gz --reads Polyposis_Exome_Analysis/picard/markduplicate/markedduplicates/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_markedduplicates.bam --examples Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/make_examples.tfrecord@1.gz --gvcf Polyposis_Exome_Analysis/deepvariant/intermediateresults/NG0921010_EKDN210018950-1A_HN2MGDSX2_L2_PE_output_intermediate/gvcf.tfrecord@1.gz --regions Polyposis_Exome_Analysis/deepvariant/agilent_bedfile/agilent_human_region.hg38.bed --task 0. ```. The error is quite descriptive, but I'm not sure how my file would be empty? Thanks for all your help! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:199,interoperability,coordinat,coordinate,199,"Okay so just taking one sequence:. > .the .sam file first line is (after doing head -1): @SQ SN:NC_000001.11 LN:248956422. > the .bam file first line is (after doing samtools view -H): @HD VN:1.6 SO:coordinate. and that same .bam's second line is: @SQ SN:NC_000001.11 LN:248956422. > the reference fasta file first line is: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. > The .bed first line is chr1 12080 12251. Thank you for all your help, I really appreciate it. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:460,usability,help,help,460,"Okay so just taking one sequence:. > .the .sam file first line is (after doing head -1): @SQ SN:NC_000001.11 LN:248956422. > the .bam file first line is (after doing samtools view -H): @HD VN:1.6 SO:coordinate. and that same .bam's second line is: @SQ SN:NC_000001.11 LN:248956422. > the reference fasta file first line is: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. > The .bed first line is chr1 12080 12251. Thank you for all your help, I really appreciate it. .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:42,reliability,doe,does,42,"Can you confirm that your BAM file header does have `chr1`, and that your FASTA file also have `chr1`?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:8,usability,confirm,confirm,8,"Can you confirm that your BAM file header does have `chr1`, and that your FASTA file also have `chr1`?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:387,interoperability,coordinat,coordinate,387,"Hi sorry for the delay,. I reran my sequences with a new copy of the human reference genome from https://www.ncbi.nlm.nih.gov/genome/guide/human/ up until running deepvariant. . I get the same headers as above, it doesn't seem like the bam, sam or even the reference start with the word 'chr1':. sam file header: @SQ	SN:NC_000001.11	LN:248956422. bam file (sorted picard): @HD	VN:1.6	SO:coordinate. @SQ	SN:NC_000001.11	LN:248956422. Original fasta reference file header: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. Bed file: chr1	12080	12251. All the code and steps I've done before are on my page under Exome_Pipeline/PE read analysis. I'm not sure! Ah, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:214,reliability,doe,doesn,214,"Hi sorry for the delay,. I reran my sequences with a new copy of the human reference genome from https://www.ncbi.nlm.nih.gov/genome/guide/human/ up until running deepvariant. . I get the same headers as above, it doesn't seem like the bam, sam or even the reference start with the word 'chr1':. sam file header: @SQ	SN:NC_000001.11	LN:248956422. bam file (sorted picard): @HD	VN:1.6	SO:coordinate. @SQ	SN:NC_000001.11	LN:248956422. Original fasta reference file header: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. Bed file: chr1	12080	12251. All the code and steps I've done before are on my page under Exome_Pipeline/PE read analysis. I'm not sure! Ah, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:133,usability,guid,guide,133,"Hi sorry for the delay,. I reran my sequences with a new copy of the human reference genome from https://www.ncbi.nlm.nih.gov/genome/guide/human/ up until running deepvariant. . I get the same headers as above, it doesn't seem like the bam, sam or even the reference start with the word 'chr1':. sam file header: @SQ	SN:NC_000001.11	LN:248956422. bam file (sorted picard): @HD	VN:1.6	SO:coordinate. @SQ	SN:NC_000001.11	LN:248956422. Original fasta reference file header: >NC_000001.11 Homo sapiens chromosome 1, GRCh38.p13 Primary Assembly. Bed file: chr1	12080	12251. All the code and steps I've done before are on my page under Exome_Pipeline/PE read analysis. I'm not sure! Ah, thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:104,security,access,accession,104,For anyone with the same problem: my bed file had the IDs labelled as chr1 whereas other files used the accession number (e.g NC_000001.11) - I used dplyr on R to recode the IDs to the accession number and then deepvariant worked :) Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/527:185,security,access,accession,185,For anyone with the same problem: my bed file had the IDs labelled as chr1 whereas other files used the accession number (e.g NC_000001.11) - I used dplyr on R to recode the IDs to the accession number and then deepvariant worked :) Thanks!,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/527
https://github.com/google/deepvariant/issues/528:84,deployability,releas,release,84,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:92,energy efficiency,model,models,92,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:812,energy efficiency,predict,prediction,812,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:427,interoperability,specif,specific-variant-in-my-data,427,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:550,interoperability,distribut,distribution,550,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:213,reliability,doe,does,213,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:399,reliability,doe,does-deepvariant-not-call-a-specific-variant-in-my-data,399,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:812,safety,predict,prediction,812,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:92,security,model,models,92,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:476,security,ident,identified,476,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:837,usability,intuit,intuitive,837,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:894,usability,help,helps,894,"Hi @Qianwangwoo ,. First of all, DeepVariant is a germline variant caller - all our release models are trained for germline variant calling. But if I read your question correctly, your question is more about ""why does DeepVariant call this image as HET rather than HOM-ALT"". To answer that question, it'll be similar to this FAQ here: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. Once a candidate is identified, DeepVariant uses a classifier on it to generate a probability distribution for the 3 classes (0: HOM-REF, 1: HET, 2: HOM-ALT). . . From the `PL` field, it would look like HOM-ALT has lower probability than HET, but not necessarily by much `33,0,1`. And, the classifier takes into account many factors here, which is why the prediction is not always intuitive (and, not always right). . Let me know if this helps and if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:240,integrability,filter,filtering,240,"> . Hi @pichuan , thanks so much for your reply! Yes, I think I want to understand why this variant was called as HET instead of HOM-ALT. I got the idea of PL for this variant call, I'm wondering if there is a parameter for `VAF` to do the filtering? Thanks!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:210,modifiability,paramet,parameter,210,"> . Hi @pichuan , thanks so much for your reply! Yes, I think I want to understand why this variant was called as HET instead of HOM-ALT. I got the idea of PL for this variant call, I'm wondering if there is a parameter for `VAF` to do the filtering? Thanks!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:72,testability,understand,understand,72,"> . Hi @pichuan , thanks so much for your reply! Yes, I think I want to understand why this variant was called as HET instead of HOM-ALT. I got the idea of PL for this variant call, I'm wondering if there is a parameter for `VAF` to do the filtering? Thanks!!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:701,availability,error,error,701,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:850,availability,error,error,850,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:41,integrability,filter,filtering,41,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:959,integrability,filter,filter,959,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:716,modifiability,Pac,PacBio,716,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:701,performance,error,error,701,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:850,performance,error,error,850,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:123,reliability,doe,does,123,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:701,safety,error,error,701,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:850,safety,error,error,850,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:777,security,assess,assess,777,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:701,usability,error,error,701,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:850,usability,error,error,850,"Hi @Qianwangwoo . We don't do additional filtering beyond the probabilities from the classifier. In this case, DeepVariant does not have a high confidence in the correct genotype between HET and HOM-ALT (a GQ of 4 corresponds to a ~60% confidence in a correct genotype call). The QUAL value of 36.1 suggests that DeepVariant is at least pretty confident that the position is not REF. A few other points to keep in mind - first, are you using the two-pass DeepVariant-WhatsHap-DeepVariant method? If so, then DeepVariant may be using additional information about the phasing from longer range. Second, this variant is at a junction between homopolymers (poly-T and poly-G) This represents the dominant error mode for PacBio HiFi, so it may nit be straightforward for a human to assess the probability of a G->T variant here as opposed to a sequencing error of Insertion T and deletion G. . If you want to for sure have a higher precision, you can additionally filter for GQ value (e.g. 10 for a 90% confidence in the genotype call). However, if you do so, you will lose variant positions like this which are very likely not reference, but difficult to genotype.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:153,modifiability,Pac,Pacbio,153,"Thanks @AndrewCarroll , I didn't use two pass method for this variant calling. Do you think it's proper to apply this method to small variant calling of Pacbio HiFi reads?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:220,deployability,releas,release,220,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:414,deployability,version,version,414,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:440,deployability,updat,updating,440,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:379,energy efficiency,current,current,379,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:414,integrability,version,version,414,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:76,modifiability,Pac,PacBio,76,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:247,modifiability,Pac,PacBio,247,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:414,modifiability,version,version,414,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:440,safety,updat,updating,440,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:440,security,updat,updating,440,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:359,usability,prefer,prefer,359,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/528:387,usability,workflow,workflow,387,"Hi @Qianwangwoo . Yes, the two-pass method generally improves accuracy with PacBio small variant calling, especially for Indels. Whether it is likely to improve this call, I am not sure. Note that we anticipate a future release of DeepVariant for PacBio in the near future which will have comparable accuracy with a single pass of variant calling, so you may prefer to keep your current workflow and wait for that version if you don't mind updating.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/528
https://github.com/google/deepvariant/issues/529:378,interoperability,specif,specific,378,"Hi @leedchou ,. usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:268,reliability,doe,does-it-work,268,"Hi @leedchou ,. usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:533,testability,understand,understand,533,"Hi @leedchou ,. usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:1745,energy efficiency,current,currently,1745,"re 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main function. std::unique_ptr<ImageRow>. PileupImageEncoderNative::EncodeRead(const DeepVariantCall& dv_call,. const string& ref_bases,. const std::vector<::nucleus::genomics::v1::Read>& reads,. int image_start_pos,. const vector<string>& alt_alleles) {. const int ref_supporting_reads_1 = 0;. ref_supporting_reads_1 = dv_call.variant().calls()[0].info().find(""AD"")->second.values()[0].int_value();. int ref_supporting_reads_2 = 0;. for (const Read& read : reads) {. const int supports_alt = ReadSupportsAlt(dv_call, read, alt_alleles);. if (supports_alt == 0) {. ref_supporting_reads_2 += 1;. }. }. }. ```. Reads are from AlleleCounter as you did. I did not change any other code. **However, ref_supporting_reads_1 is not equals to ref_supporting_reads_2.** W",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:387,interoperability,specif,specific,387,"``> Hi @leedchou , usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. > . > If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you! Thanks for your reply @pichuan. In the step of making examples, I'd like to get the reference supporting reads count when encoding pileup image for one variant. There are 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main functi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:271,reliability,doe,does-it-work,271,"``> Hi @leedchou , usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. > . > If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you! Thanks for your reply @pichuan. In the step of making examples, I'd like to get the reference supporting reads count when encoding pileup image for one variant. There are 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main functi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:542,testability,understand,understand,542,"``> Hi @leedchou , usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. > . > If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you! Thanks for your reply @pichuan. In the step of making examples, I'd like to get the reference supporting reads count when encoding pileup image for one variant. There are 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main functi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:676,usability,support,supporting,676,"``> Hi @leedchou , usually when there's a question about reads count, it can be related to related to the fact that DeepVariant runs a realigner first. See this section of the FAQ: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#what-is-the-realigner-and-how-does-it-work. > . > If you think this something more than that, can you give a small reproducible example, and give specific description of which position you're looking at, and what count you're getting (and what you're expecting)? Without that, it's a bit difficult to understand the details here. Thank you! Thanks for your reply @pichuan. In the step of making examples, I'd like to get the reference supporting reads count when encoding pileup image for one variant. There are 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main functi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:1723,usability,support,support,1723,"or one variant. There are 2 ways to get the count, one is to get it from **Allele Depth (AD)** straightforward, the other is to traverse all reads of this variant through an iteration. The related code is as follows:. ```. inline int ReadSupportsAlt(const DeepVariantCall& dv_call, const Read& read,. const std::vector<string>& alt_alleles) {. string key = (read.fragment_name() + ""/"" +. std::to_string(read.read_number()));. // Iterate over all alts, not just alt_alleles. for (const string& alt_allele : dv_call.variant().alternate_bases()) {. const auto& allele_support = dv_call.allele_support();. const bool alt_allele_present_in_call =. allele_support.find(alt_allele) != allele_support.cend();. . if (alt_allele_present_in_call) {. const auto& supp_read_names = allele_support.at(alt_allele).read_names();. for (const string& read_name : supp_read_names) {. const bool alt_in_alt_alleles =. std::find(alt_alleles.begin(), alt_alleles.end(), alt_allele) !=. alt_alleles.end();. // Read can support an alt we are currently considering (1), a different. // alt not present in alt_alleles (2), or ref (0). if (read_name == key && alt_in_alt_alleles) {. return 1;. } else if (read_name == key && !alt_in_alt_alleles) {. return 2;. }. }. }. }. return 0;. }. // main function. std::unique_ptr<ImageRow>. PileupImageEncoderNative::EncodeRead(const DeepVariantCall& dv_call,. const string& ref_bases,. const std::vector<::nucleus::genomics::v1::Read>& reads,. int image_start_pos,. const vector<string>& alt_alleles) {. const int ref_supporting_reads_1 = 0;. ref_supporting_reads_1 = dv_call.variant().calls()[0].info().find(""AD"")->second.values()[0].int_value();. int ref_supporting_reads_2 = 0;. for (const Read& read : reads) {. const int supports_alt = ReadSupportsAlt(dv_call, read, alt_alleles);. if (supports_alt == 0) {. ref_supporting_reads_2 += 1;. }. }. }. ```. Reads are from AlleleCounter as you did. I did not change any other code. **However, ref_supporting_reads_1 is not equals to ref_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:28,security,team,teammate,28,"Hi @leedchou ,. I'll ask my teammate @akolesnikov to take a look, maybe sometime next week.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:246,interoperability,specif,specifics,246,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:371,interoperability,share,share,371,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:138,reliability,doe,does,138,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:177,reliability,doe,doesn,177,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:147,usability,support,support,147,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:205,usability,support,supports,205,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:338,usability,support,supporting,338,"Hi @leedchou,. Using ```ReadSupportsAlt``` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. . If you could share some details on what are you trying to achieve we will be able to provide a better suggestion.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:29,security,team,teammate,29,"> Hi @leedchou , I'll ask my teammate @akolesnikov to take a look, maybe sometime next week. Thank you very much for your help @pichuan .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:122,usability,help,help,122,"> Hi @leedchou , I'll ask my teammate @akolesnikov to take a look, maybe sometime next week. Thank you very much for your help @pichuan .",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:250,interoperability,specif,specifics,250,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:373,interoperability,share,share,373,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:142,reliability,doe,does,142,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:181,reliability,doe,doesn,181,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:501,safety,compl,completely,501,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:501,security,compl,completely,501,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:512,testability,understand,understand,512,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:151,usability,support,support,151,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:209,usability,support,supports,209,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/529:342,usability,support,supporting,342,"> Hi @leedchou,. > . > Using `ReadSupportsAlt` function from pileup_image_native.cc to count ref sporting reads is incorrect. If a given read does not support any of the alleles it doesn't mean that this read supports a reference (this is due to the specifics of the DeepVariant implementation). AD value should be used for the number of ref supporting reads. If you could share some details on what are you trying to achieve we will be able to provide a better suggestion. Thank you @akolesnikov , I completely understand now.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/529
https://github.com/google/deepvariant/issues/530:1510,deployability,updat,updated,1510,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1530,deployability,releas,release,1530,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1510,safety,updat,updated,1510,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1510,security,updat,updated,1510,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:35,testability,understand,understand,35,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1456,usability,feedback,feedback,1456,"Hi @japhill ,. Just to make sure I understand this - are you saying that the Docker image has /mnt in it, and as result was causing problem with Singularity? I do see a /mnt directory:. ```. $ sudo docker run google/deepvariant:1.3.0 ls -lh /. total 48K. lrwxrwxrwx 1 root root 7 Oct 6 16:47 bin -> usr/bin. drwxr-xr-x 2 root root 4.0K Apr 15 2020 boot. drwxr-xr-x 5 root root 340 Mar 23 23:34 dev. drwxr-xr-x 1 root root 4.0K Mar 23 23:34 etc. drwxr-xr-x 2 root root 4.0K Apr 15 2020 home. lrwxrwxrwx 1 root root 7 Oct 6 16:47 lib -> usr/lib. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib32 -> usr/lib32. lrwxrwxrwx 1 root root 9 Oct 6 16:47 lib64 -> usr/lib64. lrwxrwxrwx 1 root root 10 Oct 6 16:47 libx32 -> usr/libx32. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 media. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 mnt. drwxr-xr-x 1 root root 4.0K Dec 6 23:17 opt. dr-xr-xr-x 525 root root 0 Mar 23 23:34 proc. drwx------ 1 root root 4.0K Dec 6 23:15 root. drwxr-xr-x 5 root root 4.0K Oct 6 16:58 run. lrwxrwxrwx 1 root root 8 Oct 6 16:47 sbin -> usr/sbin. drwxr-xr-x 2 root root 4.0K Oct 6 16:47 srv. dr-xr-xr-x 13 root root 0 Mar 23 23:34 sys. drwxrwxrwt 1 root root 4.0K Dec 6 23:19 tmp. drwxr-xr-x 1 root root 4.0K Oct 6 16:47 usr. drwxr-xr-x 1 root root 4.0K Oct 6 16:58 var. ```. which is empty, so I think your suggestion of something like ""RUN rm -rf /mnt/"" makes sense. I'll also do a quick search to see if there are better approaches here. Thanks for the feedback. I'll track internally and make sure this is updated in the next release.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:163,interoperability,bind,bind-paths,163,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity? https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths. Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:163,modifiability,bind,bind-paths,163,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity? https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths. Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:101,usability,guid,guides,101,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity? https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths. Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:112,usability,user,user-guide,112,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity? https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths. Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:150,usability,user,user-defined-bind-paths,150,"@japhill But for now, I also wonder if you can use the `-B` option in Singularity? https://sylabs.io/guides/3.1/user-guide/bind_paths_and_mounts.html#user-defined-bind-paths. Can you try it and let me know if it works for you?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:78,deployability,contain,container,78,Just to add to the previous post. Your file system is not accessible from the container. Using -B option you may map (mount) some directories from your file system to be accessible from within the container. . There is a similar issue with the similar content. https://github.com/google/deepvariant/issues/506#issuecomment-1017088492.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:197,deployability,contain,container,197,Just to add to the previous post. Your file system is not accessible from the container. Using -B option you may map (mount) some directories from your file system to be accessible from within the container. . There is a similar issue with the similar content. https://github.com/google/deepvariant/issues/506#issuecomment-1017088492.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:252,performance,content,content,252,Just to add to the previous post. Your file system is not accessible from the container. Using -B option you may map (mount) some directories from your file system to be accessible from within the container. . There is a similar issue with the similar content. https://github.com/google/deepvariant/issues/506#issuecomment-1017088492.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:58,security,access,accessible,58,Just to add to the previous post. Your file system is not accessible from the container. Using -B option you may map (mount) some directories from your file system to be accessible from within the container. . There is a similar issue with the similar content. https://github.com/google/deepvariant/issues/506#issuecomment-1017088492.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:170,security,access,accessible,170,Just to add to the previous post. Your file system is not accessible from the container. Using -B option you may map (mount) some directories from your file system to be accessible from within the container. . There is a similar issue with the similar content. https://github.com/google/deepvariant/issues/506#issuecomment-1017088492.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:18,usability,help,help,18,"Thank you for the help. I'm somewhat new to Singularity and how it works, so this has been helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:91,usability,help,helpful,91,"Thank you for the help. I'm somewhat new to Singularity and how it works, so this has been helpful.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:29,deployability,updat,update,29,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:87,deployability,releas,release,87,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:455,interoperability,standard,standard,455,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:29,safety,updat,update,29,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:294,safety,avoid,avoid,294,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:29,security,updat,update,29,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:39,testability,plan,plan,39,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:490,testability,plan,plan,490,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:127,usability,User,User,127,"Hi @japhill , to give you an update, I plan to add this section to our FAQ in the next release:. ---. ### Issues with `/mnt/`. User reported that sometimes their setup uses `/mnt/`, which exists in our Docker image, and it has caused an issue in Singularity. You can use `-B` in Singularity to avoid this issue. See:. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302 for more details. ---. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:374,availability,error,errors,374,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:452,deployability,updat,update,452,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:510,deployability,releas,release,510,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:292,integrability,Sub,Subject,292,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1323,integrability,Messag,Message,1323,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:942,interoperability,standard,standard,942,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1323,interoperability,Messag,Message,1323,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:374,performance,error,errors,374,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:374,safety,error,errors,374,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:452,safety,updat,update,452,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:736,safety,avoid,avoid,736,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:452,security,updat,update,452,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:1221,security,auth,auth,1221,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:462,testability,plan,plan,462,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:977,testability,plan,plan,977,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:31,usability,help,help,31,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:374,usability,error,errors,374,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/530:573,usability,User,User,573,"Thank you very much. That will help out the folks new to docker/singularity. After using the -B option, we are good to go now! From: Pi-Chuan Chang ***@***.***>. Sent: Friday, March 25, 2022 7:19 PM. To: google/deepvariant ***@***.***>. Cc: Jason Phillips ***@***.***>; Mention ***@***.***>. Subject: Re: [google/deepvariant] Image /mnt overriding my machine's /mnt causing errors (Issue #530). Hi @japhill<https://github.com/japhill> , to give you an update, I plan to add this section to our FAQ in the next release:. ________________________________. Issues with /mnt/. User reported that sometimes their setup uses /mnt/, which exists in our Docker image, and it has caused an issue in Singularity. You can use -B in Singularity to avoid this issue. See:. #530 (comment)<https://github.com/google/deepvariant/issues/530#issuecomment-1076923302> for more details. ________________________________. Given that this solution works, and is a standard Singularity flag, I won't plan to remove /mnt from our Docker images in the future. —. Reply to this email directly, view it on GitHub<https://github.com/google/deepvariant/issues/530#issuecomment-1079509951>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AHAS6GHJOPUE7DQPYAT264TVBZCWLANCNFSM5Q7A6FXQ>. You are receiving this because you were mentioned.Message ID: ***@***.******@***.***>>.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/530
https://github.com/google/deepvariant/issues/531:91,usability,guid,guidelines,91,"thanks for the great piece of software! I agree with Jordi and would add that some general guidelines on how to use the numerous INFO fields would be nice, do they live somewhere? it is a pity to have so many metrics and ignore how to put them to good use",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:860,integrability,sub,subset,860,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:357,interoperability,specif,specific-variant-in-my-data,357,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:555,interoperability,specif,specificity,555,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:729,interoperability,standard,standard,729,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:909,interoperability,specif,specific,909,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:329,reliability,doe,does-deepvariant-not-call-a-specific-variant-in-my-data,329,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:119,usability,learn,learning,119,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:930,usability,clear,clear,930,"Hi @jordimaggi . For anything that is `RefCall`, that means: even though a candidate variant was proposed, our machine learning classifier decided the most likely class is 0 (which means reference). . You can read this section to get a bit more background on this: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-does-deepvariant-not-call-a-specific-variant-in-my-data. You could potentially take the finer-grained information (like `PL`) and try to adjust your own threshold. This could increase the sensitivity, but will likely hurt the specificity of DeepVariant's results. I'll ask @AndrewCarroll to add his thoughts here as well. Hi @splaisan , for the existing fields we have in our VCF file, we follow the standard definitions you can find on https://en.wikipedia.org/wiki/Variant_Call_Format#Common_FORMAT_fields (and we only fill in a subset of them). Let us know if there's anything specific that is not clear to you. Happy to explain more.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:120,availability,consist,consistently,120,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:613,energy efficiency,predict,predictive,613,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:780,energy efficiency,predict,predictive,780,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:87,integrability,filter,filtering,87,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:678,integrability,sub,subset,678,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:566,interoperability,standard,standard,566,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:584,interoperability,FORMAT,FORMAT,584,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:1247,interoperability,specif,specificity,1247,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:360,performance,content,content,360,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:1218,performance,tune,tune,1218,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:613,safety,predict,predictive,613,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:780,safety,predict,predictive,780,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:1091,safety,input,input,1091,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:540,security,ident,identify,540,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:833,security,ident,identify,833,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:688,testability,context,contexts,688,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:120,usability,consist,consistently,120,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:1091,usability,input,input,1091,"Hi @jordimaggi @splaisan . I will add on a little to Pi-Chuan's answer with respect to filtering and quality scores. We consistently find that the genotype quality (GQ and PL fields) are extremely well-calibrated with the empirical probability of a call being correct. This is quantified in Figure 2 of the [original DeepVariant paper](https://www.biorxiv.org/content/10.1101/092890v6). This value is the best to use when determining whether a call is likely correct. Both ourselves and other external groups who we work with have tried to identify other metrics of standard INFO and FORMAT fields which are more predictive of call quality or even additionally informative in a subset of contexts and cases. For basically everything we and these groups have looked at, GQ is more predictive of call correctness. . If you are able to identify an annotation which is additionally informative beyond GQ (and also not already perfectly captured in the GQ field), it would be quite interesting to know, and we could consider incorporating it as an output field, or providing the annotation as an input during calling. . In general, I'd encourage you to look at GQ and PL as the most informative fields if you would like to tune between sensitivity and specificity.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:99,interoperability,distribut,distribution,99,"Dear @AndrewCarroll, thanks a lot, this is exactly the answer I was looking for. . I will plot the distribution of these metrics and see if I can cut the tail somewhere to increase the overall truth of my data. Best regards. Stephane",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/531:106,integrability,filter,filter,106,"Dear @pichuan and @AndrewCarroll,. thansk for the replies! I will exclude `RefCall` calls and use `GQ` to filter out lower quality calls. Thanks for the clarification! Also, great work on the amazing piece of software! Best,. Jordi Maggi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/531
https://github.com/google/deepvariant/issues/532:46,energy efficiency,model,model,46,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:148,energy efficiency,schedul,scheduler,148,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:301,energy efficiency,model,model,301,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:410,energy efficiency,model,model,410,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:468,energy efficiency,model,model,468,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:148,performance,schedul,scheduler,148,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:46,security,model,model,46,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:301,security,model,model,301,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:410,security,model,model,410,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:468,security,model,model,468,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:576,security,ident,identical,576,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:112,testability,coverag,coverages,112,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:358,usability,document,document,358,"Hello jessieshen97,. In order to train a good model you need to run make_examples on multiple sets on different coverages. Internally we use Google scheduler with thousands of hosts. You may try to do it on one machine but it may be challenging. . To answer you question, yes you can train a DeepTrio model of the diploid organism. Although, we don't have a document with detailed steps on training a DeepTrio model you can try following the steps for DeepVariant toy model training. The only difference is that you need to use DeepTrio make_examples. All other sets would be identical.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/532:5,usability,close,close,5,"I'll close this issue now @jessieshen97 . Feel free to reopen, or open a new issue if you have more questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/532
https://github.com/google/deepvariant/issues/533:221,usability,help,help,221,"Hi @RhettRautsaw ,. Can you take a look at . https://github.com/google/deepvariant/issues/524#issuecomment-1079508369. or. https://github.com/google/deepvariant/issues/530#issuecomment-1076923302. and see if either those help with your situation? Let me know. Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:139,availability,Error,Error,139,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:908,availability,Error,Error,908,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1296,availability,error,error,1296,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1346,deployability,fail,failed,1346,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1385,deployability,fail,failed,1385,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:480,integrability,buffer,buffer,480,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1258,interoperability,bind,bind,1258,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:281,modifiability,interm,intermediate,281,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:329,modifiability,Interm,Intermediate,329,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1258,modifiability,bind,bind,1258,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:139,performance,Error,Error,139,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:175,performance,cach,cached,175,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:436,performance,time,time,436,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:452,performance,parallel,parallel,452,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:908,performance,Error,Error,908,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1090,performance,parallel,parallel,1090,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1296,performance,error,error,1296,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1321,performance,cach,cached,1321,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1063,reliability,doe,does,1063,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1346,reliability,fail,failed,1346,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1385,reliability,fail,failed,1385,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:139,safety,Error,Error,139,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:597,safety,input,input,597,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:908,safety,Error,Error,908,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1264,safety,input,input,1264,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1296,safety,error,error,1296,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1179,testability,understand,understand,1179,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:139,usability,Error,Error,139,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:421,usability,command,command,421,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:597,usability,input,input,597,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:908,usability,Error,Error,908,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1125,usability,user,user,1125,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1264,usability,input,input,1264,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:1296,usability,error,error,1296,"Hi @pichuan,. Thanks for replying so quickly. I have tried both of those things. Doing `export TMPDIR=""$PWD/tmp_dir""` causes the same as **Error 1** above. . ```. INFO: Using cached SIF image. I0404 17:45:45.958600 23016861075264 run_deepvariant.py:345] Re-using the directory for intermediate results in /tmp/tmp_ui_t3bd. ***** Intermediate results will be written to /tmp/tmp_ui_t3bd in docker. ****. ***** Running the command:*****. time seq 0 15 | parallel -q --halt 2 --line-buffer /opt/deepvariant/bin/make_examples --mode calling --ref ""reference/GRCh38_no_alt_analysis_set.fasta"" --reads ""input/HG003.GRCh38.chr20.pFDA_truthv2.bam"" --examples ""/tmp/tmp_ui_t3bd/make_examples.tfrecord@16.gz"" --add_hp_channel --alt_aligned_pileup ""diff_channels"" --noparse_sam_aux_fields --pileup_image_width ""199"" --norealign_reads --regions ""chr20"" --nosort_by_haplotypes --vsc_min_fraction_indels ""0.12"" --task {}. Error in tempfile() using template /scratch1/rrautsa/deepvariant_test/tmp_dir/parXXXXX.par: Parent directory (/scratch1/rrautsa/deepvariant_test/tmp_dir/) does not exist at /usr/bin/parallel line 3889. real	0m0.257s. user	0m0.121s. sys	0m0.125s. ```. And perhaps I don't understand singularity enough, but it seems that no matter how I change the `--bind` input it gives me the following error:. ```. INFO: Using cached SIF image. FATAL: failed to open /bin/sh for inspection: failed to open elf binary /bin/sh: open /bin/sh: no such file or directory. ```.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:22,interoperability,share,share,22,@RhettRautsaw Can you share the command you ran when you use `--bind`?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:64,interoperability,bind,bind,64,@RhettRautsaw Can you share the command you ran when you use `--bind`?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:64,modifiability,bind,bind,64,@RhettRautsaw Can you share the command you ran when you use `--bind`?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:32,usability,command,command,32,@RhettRautsaw Can you share the command you ran when you use `--bind`?,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/533:66,usability,close,close,66,"Hi @RhettRautsaw , we haven't heard from you for a while, so I'll close this now. Feel free to reopen.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/533
https://github.com/google/deepvariant/issues/534:2577,availability,avail,available,2577,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:614,energy efficiency,model,model,614,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1811,energy efficiency,model,model,1811,"re better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2098,energy efficiency,current,current,2098,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2441,energy efficiency,model,model,2441,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2648,energy efficiency,current,current,2648,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:397,interoperability,specif,specifically,397,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2577,reliability,availab,available,2577,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2621,reliability,pra,practical,2621,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:88,safety,compl,complicated,88,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:439,safety,compl,completeness,439,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2257,safety,compl,complete,2257,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2546,safety,compl,complete,2546,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2577,safety,avail,available,2577,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:88,security,compl,complicated,88,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:439,security,compl,completeness,439,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:614,security,model,model,614,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1811,security,model,model,1811,"re better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2257,security,compl,complete,2257,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2441,security,model,model,2441,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2546,security,compl,complete,2546,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2577,security,availab,available,2577,"eature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together. Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1725,testability,coverag,coverage,1725,"rginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:620,usability,behavi,behaving,620,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:972,usability,learn,learned,972,"Hi @SHuang-Broad . This is a good question and the best answer I can give to it is both complicated and not conclusive. TL;DR - for long reads, retraining will (probably) not change things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to lea",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1177,usability,help,help,1177,"ge things much, but there might be other future opportunities to use T2T truth in training strategies regardless of the reference used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1299,usability,statu,status,1299,"erence used. . Generally, I think DeepVariant will give good results on T2T without retraining specifically for it, and given the better completeness of the T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1454,usability,minim,minimal,1454," T2T reference, probably just using this will give generally better results. In the past, we have trained with both GRCh37 and GRCh38, and we don't see the model behaving very differently with either reference. It's possible that re-training with the T2T could lead to marginally better accuracy in some areas, especially in segmental duplications, which are better resolved in T2T. At present, GRCh38 will have some segmental duplications that are collapsed, or where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1919,usability,help,help,1919,"where a copy is missing. DeepVariant seems to have learned some of the patterns for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1997,usability,learn,learn,1997," for this, and is can sometimes reject variants in regions that look like segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested i",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:2068,usability,help,help,2068,"ike segdups. This feature is not necessarily bad, but both using and training with the T2T reference might help it adjust its priors for how likely this is in the T2T reference (we had a [poster](https://twitter.com/acarroll_ATG/status/1231655024213856256) discussing this phenomenon and how DeepVariant reacts to it). . However, I think the effects of retraining here will be fairly minimal and restricted to either segmental duplication regions or structural variants. In addition, it's unclear to me whether this would occur only for short-reads. Right now, the quality of the truth sets is limited by long-read mappability to the reference. With good coverage of HiFi reads, we expect SNP F1 of more than 0.999. It seems likely that the model already knows enough to accurately call variants if the reference can be resolved, and though T2T may help the mapping resolve the remainder, it's unclear whether there is more to learn in further training. This highlights one key point where T2T may help with training - that the current training is limited by the truth set. Training with v4.2.1 truth sets is still constrained by the confident regions of the genome. If we can get fully complete, 100% accurate truth sets covering the genome, this will provide more training examples of difficult regions in the training process, and I think this could further improve a model (whether it's on the T2T reference or on GRCh38). I think there will be an opportunity for this as complete T2T assemblies become available for more samples. Finally, from a practical perspective, the current v4.2.1 truth sets are relative to GRCh38, so in order to train we'd need to first be able to generate truth variants and confident regions for some sample on T2T. That's certainly doable, but it is tricky to do correctly. Hopefully this has answered more questions than it has opened. If this is an area you have ideas about or are interested in collaborating on, we'd certainly be happy to explore those together.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:24,usability,close,close,24,"Hi @SHuang-Broad , I'll close this issue now. Feel free to reopen or ask another question. Or directly reach out via email if you want to have more discussions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:312,availability,sli,slide-of-the-week-,312,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:132,energy efficiency,current,currently,132,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:540,integrability,pub,published,540,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:961,integrability,protocol,protocol,961,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:961,interoperability,protocol,protocol,961,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1018,performance,content,content,1018,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:312,reliability,sli,slide-of-the-week-,312,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:142,usability,document,documenting,142,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:359,usability,Document,Documenting,359,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:806,usability,person,personalized,806,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:889,usability,person,personalized,889,"I'm working on a project related to T2T variant calling. @AndrewCarroll, has your group examined this question in more detail? I am currently documenting the impact of T2T vs GRCh38 alignment on variant calling. I can tell you already that it has a [large effect](https://www.waisman.wisc.edu/2024/06/07/werling-slide-of-the-week-2024/) on alignment quality. Documenting the impact is one thing, but retraining DeepVariant is another. I *could* do it, but I don't look forward to it. If interested, I can provide my cram files. I have your published HG002-HG007 illumina reads at 20X and 30X depth aligned to:. - GRCh38 (w/ BWA-mem). - T2Tv2.0 (w/ BWA-mem. - GRCh38 (aligned to HPRCv1.1 w/ vg giraffe, surjected to GRCh38). - T2T (aligned to HPRCv1.1 w/ vg giraffe, surjected to T2T). - GRCh38 (aligned to personalized graph* created from HPRCv1.1, surjected to GRCh38). - T2T (aligned to personalized graph* created from HPRCv1.1, surjected to T2T). * per the protocol outlined in this paper: https://www.biorxiv.org/content/10.1101/2023.12.13.571553v2.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:109,availability,avail,available,109,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:186,availability,avail,available,186,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:500,availability,avail,available,500,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:59,deployability,depend,depends,59,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:200,deployability,releas,released,200,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:486,deployability,resourc,resources,486,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:20,energy efficiency,current,current,20,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:212,energy efficiency,current,currently,212,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:256,energy efficiency,model,models,256,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:486,energy efficiency,resourc,resources,486,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:28,integrability,schema,schema,28,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:59,integrability,depend,depends,59,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:59,modifiability,depend,depends,59,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:358,modifiability,exten,extend,358,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:486,performance,resourc,resources,486,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:109,reliability,availab,available,109,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:186,reliability,availab,available,186,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:350,reliability,doe,doesn,350,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:500,reliability,availab,available,500,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:59,safety,depend,depends,59,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:109,safety,avail,available,109,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:186,safety,avail,available,186,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:486,safety,resourc,resources,486,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:500,safety,avail,available,500,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:109,security,availab,available,109,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:186,security,availab,available,186,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:256,security,model,models,256,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:471,security,team,team,471,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:500,security,availab,available,500,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:59,testability,depend,depends,59,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:343,testability,simpl,simply,343,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:486,testability,resourc,resources,486,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:343,usability,simpl,simply,343,"@JosephLalli ,. The current schema of DeepVariant training depends on having GIAB calls that we use as truth available against the reference. The GIAB truth set against T2T is still not available and released so currently we are not using T2T to train our models. Lifting the calls over to the T2T reference would not add too much value as it simply doesn't extend the truth set rather transfers it from one reference to the other. We are connected with the GIAB and T2T team. Once the resources are available, we will add those to our training scheme. Let us know if you have any further questions.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:397,deployability,updat,updates,397,"Thanks! I don't know if I agree that a lifted over variant set would not provide value - after all, even if the variants themselves are the same, we'd expect there to be fewer pileup regions due to differences in how off-target reads align. Even if you're right, there's only one way to know for sure - try it out and see! That being said, your reasoning makes sense. I'll keep an eye out for any updates. PS - I wonder if someone has begun working with the HG002 Q100 assembly? That can be aligned to GRCh38 or T2T reference and, in theory, used as a ground truth variant set for HG002 reads. (Although, I believe that Zook is still evaluating the viability of that option.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:397,safety,updat,updates,397,"Thanks! I don't know if I agree that a lifted over variant set would not provide value - after all, even if the variants themselves are the same, we'd expect there to be fewer pileup regions due to differences in how off-target reads align. Even if you're right, there's only one way to know for sure - try it out and see! That being said, your reasoning makes sense. I'll keep an eye out for any updates. PS - I wonder if someone has begun working with the HG002 Q100 assembly? That can be aligned to GRCh38 or T2T reference and, in theory, used as a ground truth variant set for HG002 reads. (Although, I believe that Zook is still evaluating the viability of that option.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:397,security,updat,updates,397,"Thanks! I don't know if I agree that a lifted over variant set would not provide value - after all, even if the variants themselves are the same, we'd expect there to be fewer pileup regions due to differences in how off-target reads align. Even if you're right, there's only one way to know for sure - try it out and see! That being said, your reasoning makes sense. I'll keep an eye out for any updates. PS - I wonder if someone has begun working with the HG002 Q100 assembly? That can be aligned to GRCh38 or T2T reference and, in theory, used as a ground truth variant set for HG002 reads. (Although, I believe that Zook is still evaluating the viability of that option.)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:334,availability,error,errors,334,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:788,availability,avail,available,788,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:193,deployability,observ,observed,193,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:202,deployability,artifact,artifacts,202,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:766,deployability,resourc,resources,766,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:766,energy efficiency,resourc,resources,766,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:736,integrability,event,eventually,736,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:334,performance,error,errors,334,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:766,performance,resourc,resources,766,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:811,performance,time,timeframe,811,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:788,reliability,availab,available,788,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:334,safety,error,errors,334,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:766,safety,resourc,resources,766,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:788,safety,avail,available,788,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:788,security,availab,available,788,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:193,testability,observ,observed,193,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:543,testability,understand,understanding,543,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:766,testability,resourc,resources,766,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:334,usability,error,errors,334,"Hi @JosephLalli . It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. What timeframe do you think is required for your purposes? Thank you,. Andrew",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:350,availability,error,errors,350,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:832,availability,avail,available,832,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:209,deployability,observ,observed,209,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:218,deployability,artifact,artifacts,218,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:810,deployability,resourc,resources,810,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:810,energy efficiency,resourc,resources,810,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:780,integrability,event,eventually,780,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1104,integrability,sub,submit,1104,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1115,integrability,pub,publication,1115,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:350,performance,error,errors,350,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:810,performance,resourc,resources,810,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:869,performance,time,timeframe,869,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:1045,performance,time,timeframe,1045,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:832,reliability,availab,available,832,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:350,safety,error,errors,350,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:810,safety,resourc,resources,810,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:832,safety,avail,available,832,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:832,security,availab,available,832,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:209,testability,observ,observed,209,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:573,testability,understand,understanding,573,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:810,testability,resourc,resources,810,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/534:350,usability,error,errors,350,"> Hi @JosephLalli . > . > . > . > It's a good question. Overall, I agree with what Kishar said about liftover. With historical truth sets (e.g. v3.3.2 which had GRCh38 variants lifted over from GRCh37), which observed artifacts from the liftover process. One factor to keep in mind is that the truth sets have such high label quality that even a few errors makes a big difference. . > . > . > . > We've been talking with Justin Zook about the T2T Q100 assembly. My expectation is that this will represent the highest quality mechanism to get labels on the T2T assembly. My understanding is that a GRCh38 investigation of this assembly will come first. > . > . > . > So we haven't yet worked on it, and I think it won't be very imminent, but I believe it is something that we will eventually investigate as the resources become more available for it. > . > . > . > What timeframe do you think is required for your purposes? > . > . > . > Thank you,. > . > Andrew. I agree re: lifting over. I think waiting for HG002-Q100 makes sense. . As far as timeframe goes, that's really up to Justin Zook. I hope to submit for publication by the end of the year, but we'll see... Thanks for reaching out,. Joe",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/534
https://github.com/google/deepvariant/issues/535:33,energy efficiency,model,model,33,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:301,energy efficiency,model,model,301,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:33,security,model,model,33,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:301,security,model,model,301,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:102,testability,coverag,coverage,102,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:321,usability,confirm,confirm,321,"Short answer: Yes, try the ""WES"" model. Long answer: DeepVariant isn't designed to work on super high coverage, so amplicon sequencing sometimes will produce way too many reads in each region. DeepVariant will only be able to show a random sample of the 95 reads at each putative variant locus to the model. Also just to confirm this is still germline sequencing, right? Not somatic or trying to capture variants present in less than about half the reads -- these don't work with DeepVariant.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:61,safety,test,testing,61,"Hi @MariaNattestad , thanks so much for your reply! Yes, I'm testing for germline variation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:61,testability,test,testing,61,"Hi @MariaNattestad , thanks so much for your reply! Yes, I'm testing for germline variation.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:95,energy efficiency,model,model,95,"Okay, great! I'll close this, but feel free to reopen if you run into problems running the WES model on your panel data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:95,security,model,model,95,"Okay, great! I'll close this, but feel free to reopen if you run into problems running the WES model on your panel data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/535:18,usability,close,close,18,"Okay, great! I'll close this, but feel free to reopen if you run into problems running the WES model on your panel data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/535
https://github.com/google/deepvariant/issues/536:300,availability,down,downsampling,300,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:374,deployability,version,version,374,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:413,deployability,updat,updated,413,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:48,energy efficiency,model,model,48,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:67,integrability,standardiz,standardized,67,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:134,integrability,Standardiz,Standardization,134,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:374,integrability,version,version,374,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:67,interoperability,standard,standardized,67,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:134,interoperability,Standard,Standardization,134,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:374,modifiability,version,version,374,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:200,reliability,doe,does,200,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:413,safety,updat,updated,413,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:48,security,model,model,48,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:413,security,updat,updated,413,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:191,testability,Coverag,Coverage,191,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:283,testability,coverag,coverage,283,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:181,usability,learn,learning,181,"The images all have to be the same size for the model, so they are standardized to a height of 100 (5 rows for reference + 95 reads). Standardization like this is common in machine learning. Coverage does actually get that high for many of our training datasets when we use the full coverage without downsampling. By the way, where did you find that link? It's a pretty old version of the notebook. We have since updated it here: https://github.com/google/deepvariant/blob/r1.3/docs/visualizing_examples.ipynb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:263,deployability,releas,release,263,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:271,energy efficiency,model,models,271,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:422,energy efficiency,model,model,422,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:271,security,model,models,271,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:422,security,model,model,422,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:19,usability,close,close,19,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/536:434,usability,close,close,434,"Hi @paupaiz , I'll close this issue now. Hopefully Maria's response answered your question. One thing I'll add is that when you use make_examples, you can use the `pileup_image_height` to change the height of images you create. . But, be careful that our default release models won't work directly if you change the pileup_image_height, so if you create images of different heights, you'll likely need to retrain your own model. I'll close this issue now. Feel free to reopen or ask another question.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/536
https://github.com/google/deepvariant/issues/537:5,deployability,Fail,Failed,5,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:42,energy efficiency,model,models,42,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:53,energy efficiency,model,model,53,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:138,energy efficiency,model,models,138,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:149,energy efficiency,model,model,149,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:195,energy efficiency,model,model,195,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:208,energy efficiency,cloud,cloud,208,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:260,energy efficiency,model,model,260,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5,reliability,Fail,Failed,5,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:42,security,model,models,42,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:53,security,model,model,53,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:138,security,model,models,138,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:149,security,model,model,149,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:195,security,model,model,195,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:260,security,model,model,260,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:273,security,access,accessible,273,```. Failed to get matching files on /opt/models/wgs/model.ckpt: UNIMPLEMENTED: File system scheme '[local]' not implemented (file: '/opt/models/wgs/model.ckpt'). ``` . Could you try to save the model on the cloud (path should start with gs://)? It looks that model is not accessible from the TPU host.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:448,availability,error,error,448,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:187,deployability,contain,container,187,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:481,deployability,version,version,481,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:41,energy efficiency,model,model,41,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:66,energy efficiency,model,model,66,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:79,energy efficiency,cloud,cloud,79,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:199,energy efficiency,model,models,199,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:279,energy efficiency,model,models,279,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:292,energy efficiency,model,model,292,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:323,energy efficiency,model,model,323,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:340,energy efficiency,model,model,340,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:363,energy efficiency,model,model,363,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:477,energy efficiency,GPU,GPU,477,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:511,energy efficiency,model,model,511,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:481,integrability,version,version,481,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:481,modifiability,version,version,481,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:448,performance,error,error,448,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:477,performance,GPU,GPU,477,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:448,safety,error,error,448,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:41,security,model,model,41,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:66,security,model,model,66,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:199,security,model,models,199,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:279,security,model,models,279,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:292,security,model,model,292,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:323,security,model,model,323,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:340,security,model,model,340,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:363,security,model,model,363,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:511,security,model,model,511,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:448,usability,error,error,448,"Sure, I am trying to use the default WGS model. After hosting the model on the cloud, how do I point deepvariant to it through the Docker solution? This is what I see in the local docker container's models directory when running the image:. ```bash. root@8368b35e9c34:/# ls /opt/models/wgs/. model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.input_shape model.ckpt.meta. ```. I am using the google/deepvariant:1.3.0 docker image. The same error occurs for me with the GPU version. Is there a different model expected for the TPU implementation?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:208,deployability,version,version,208,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:23,energy efficiency,model,models,23,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:372,energy efficiency,cloud,cloud-tpu,372,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:425,energy efficiency,cloud,cloud,425,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:208,integrability,version,version,208,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:208,modifiability,version,version,208,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:56,performance,content,content,56,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:23,security,model,models,23,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:111,security,access,accessible,111,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:528,security,access,accessible,528,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:167,usability,support,support,167,"When you do ```ls /opt/models/wgs/``` you see the local content of the mounted directory which is probably not accessible from TPU host. Although, we don't officially support running on TPU there is an older version case study that shows how to run training on TPU [here](https://github.com/google/deepvariant/blob/r0.9/docs/deepvariant-tpu-training-case-study.md#start-a-cloud-tpu). In particular, there is a [link](https://cloud.google.com/tpu/docs/storage-buckets#storage_access) with instructions how to make storage bucket accessible from the docker.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1098,availability,error,error,1098,"necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_st",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2326,availability,error,error,2326,"epvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4432,availability,error,error,4432,"2, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4457,availability,checkpoint,checkpoint,4457,"args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5553,availability,Restor,Restoring,5553," docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5735,availability,Restor,Restoring,5735,"er-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6051,availability,error,error,6051,"_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Tra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6138,availability,error,error,6138,"ut/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6747,availability,replic,replica,6747,"ters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7184,availability,restor,restore,7184,"usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7952,availability,replic,replica,7952,"ode save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,availability,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,availability,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12015,availability,sli,slices,12015,".8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12505,availability,Operat,Operation,12505,"sor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12919,availability,Checkpoint,CheckpointReader,12919,"/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13025,availability,checkpoint,checkpoint,13025,". File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13239,availability,restor,restore,13239,"nsorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tenso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13931,availability,checkpoint,checkpoint,13931,"CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,availability,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,availability,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17222,availability,restor,restore,17222,"onitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17340,availability,restor,restore,17340,"python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=ar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17441,availability,Restor,Restoring,17441," self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17456,availability,checkpoint,checkpoint,17456," self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17562,availability,checkpoint,checkpoint,17562,"aining/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17646,availability,checkpoint,checkpoint,17646,"manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17667,availability,error,error,17667,"ession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17696,availability,replic,replica,17696,"python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,availability,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,availability,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21759,availability,sli,slices,21759,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22249,availability,Operat,Operation,22249,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1358,deployability,modul,module,1358,"nception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3345,deployability,modul,module,3345," model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4403,deployability,continu,continues,4403,"kages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_w",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6810,deployability,Fail,Failed,6810,"t-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8015,deployability,Fail,Failed,8015,"on, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8299,deployability,stack,stack,8299,"nt/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8447,deployability,modul,module,8447,"/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,deployability,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,deployability,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10982,deployability,build,build,10982,"create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.resto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11086,deployability,build,build,11086,"ion.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14160,deployability,modul,module,14160,"python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. si",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,deployability,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,deployability,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17467,deployability,fail,failed,17467,"ssion_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17759,deployability,Fail,Failed,17759,"ager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18043,deployability,stack,stack,18043,"rs(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(T",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18191,deployability,modul,module,18191,"d_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,deployability,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,deployability,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20726,deployability,build,build,20726,"create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.resto",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20830,deployability,build,build,20830,"ion.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:73,energy efficiency,model,model,73,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:184,energy efficiency,model,model,184,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:204,energy efficiency,cloud,cloud,204,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:234,energy efficiency,model,model,234,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:297,energy efficiency,model,model,297,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:323,energy efficiency,model,models,323,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:397,energy efficiency,model,model,397,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:695,energy efficiency,model,models,695,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:769,energy efficiency,model,model,769,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1942,energy efficiency,model,model,1942,"${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPU",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2005,energy efficiency,model,model,2005,"--intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2034,energy efficiency,model,models,2034,"utput/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2108,energy efficiency,model,model,2108,"sh. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2349,energy efficiency,model,model,2349,", in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2364,energy efficiency,model,model,2364,"app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2822,energy efficiency,model,model,2822,"es. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_fla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3929,energy efficiency,model,model,3929,"utput/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3992,energy efficiency,model,model,3992,". --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4081,energy efficiency,model,model,4081,"iate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4285,energy efficiency,model,model,4285,"""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4323,energy efficiency,model,model,4323,"py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_work",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4357,energy efficiency,model,model,4357,"n(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 13992614",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4512,energy efficiency,model,model,4512,"bsl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4816,energy efficiency,model,models,4816,"ck_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-ince",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4890,energy efficiency,model,model,4890,"heck_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5247,energy efficiency,estimat,estimator,5247,". ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5596,energy efficiency,model,models,5596," google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. retu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5670,energy efficiency,model,model,5670,"nt \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5778,energy efficiency,model,models,5778,"customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful Te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5852,energy efficiency,model,model,5852,"ception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6865,energy efficiency,model,models,6865,":tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, me",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6939,energy efficiency,model,model,6939,"26144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8070,energy efficiency,model,models,8070," call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8144,energy efficiency,model,model,8144,"on/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predicti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8258,energy efficiency,estimat,estimator,8258,".8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8268,energy efficiency,estimat,estimator,8268,"ckages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9121,energy efficiency,predict,prediction,9121,"data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_sessio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9139,energy efficiency,predict,predictions,9139,"odel.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._ses",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9225,energy efficiency,estimat,estimator,9225,"tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9272,energy efficiency,predict,predict,9272,"r.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9321,energy efficiency,predict,predict,9321,"storeV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9403,energy efficiency,estimat,estimator,9403,"riant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9413,energy efficiency,estimat,estimator,9413,"_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/train",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9441,energy efficiency,predict,predict,9441," <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,energy efficiency,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,energy efficiency,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14839,energy efficiency,predict,prediction,14839,"hon.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14857,energy efficiency,predict,predictions,14857,"s_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14944,energy efficiency,estimat,estimator,14944," handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14991,energy efficiency,predict,predict,14991,"ption occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15100,energy efficiency,estimat,estimator,15100,"epvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _Wrapped",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15370,energy efficiency,estimat,estimator,15370,"el.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15417,energy efficiency,predict,predict,15417,".py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15466,energy efficiency,predict,predict,15466,"le ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._se",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15549,energy efficiency,estimat,estimator,15549,"in. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorf",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15559,energy efficiency,estimat,estimator,15559,"it(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15587,energy efficiency,predict,predict,15587,"Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,energy efficiency,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,energy efficiency,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17814,energy efficiency,model,models,17814,"_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17888,energy efficiency,model,model,17888,".8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predicti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18002,energy efficiency,estimat,estimator,18002,"nt_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18012,energy efficiency,estimat,estimator,18012,"be_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18865,energy efficiency,predict,prediction,18865,"data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_sessio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18883,energy efficiency,predict,predictions,18883,"odel.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._ses",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18969,energy efficiency,estimat,estimator,18969,"tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19016,energy efficiency,predict,predict,19016,"r.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19065,energy efficiency,predict,predict,19065,"storeV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19147,energy efficiency,estimat,estimator,19147,"riant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/py",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19157,energy efficiency,estimat,estimator,19157,"_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/train",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19185,energy efficiency,predict,predict,19185," <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,energy efficiency,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,energy efficiency,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7866,integrability,messag,message,7866,"s/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File """,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7866,interoperability,messag,message,7866,"s/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File """,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8542,interoperability,platform,platform,8542,"nal_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14256,interoperability,platform,platform,14256,"s = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18286,interoperability,platform,platform,18286,"nsorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1202,modifiability,interm,intermediate,1202,"d. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1358,modifiability,modul,module,1358,"nception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1418,modifiability,pac,packages,1418,"00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the st",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1518,modifiability,pac,packages,1518,"/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3189,modifiability,interm,intermediate,3189,"b.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3345,modifiability,modul,module,3345," model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3405,modifiability,pac,packages,3405,"e made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing contin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3505,modifiability,pac,packages,3505,"er run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the na",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5563,modifiability,paramet,parameters,5563,"n \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 145",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5745,modifiability,paramet,parameters,5745,"tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/rep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6217,modifiability,pac,packages,6217,"10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.rest",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6342,modifiability,pac,packages,6342,"15715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6513,modifiability,pac,packages,6513,"raph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7123,modifiability,pac,packages,7123,"g captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7271,modifiability,pac,packages,7271,"in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimat",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7431,modifiability,pac,packages,7431,"ssionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", li",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7596,modifiability,pac,packages,7596,"n tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=ar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7767,modifiability,pac,packages,7767,"cessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.ru",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8221,modifiability,pac,packages,8221,"op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8447,modifiability,modul,module,8447,"/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8515,modifiability,pac,packages,8515,"n(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9188,modifiability,pac,packages,9188,"usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9366,modifiability,pac,packages,9366,"runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9528,modifiability,pac,packages,9528,"ow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9687,modifiability,pac,packages,9687,"bsl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9865,modifiability,pac,packages,9865,"""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10039,modifiability,pac,packages,10039,"google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorfl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10208,modifiability,pac,packages,10208,"mator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10386,modifiability,pac,packages,10386,"mator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10536,modifiability,pac,packages,10536,"sorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10742,modifiability,pac,packages,10742,"line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10907,modifiability,pac,packages,10907,"session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11026,modifiability,pac,packages,11026,"3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11194,modifiability,pac,packages,11194,"n3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11381,modifiability,pac,packages,11381,"-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11563,modifiability,pac,packages,11563,"ning/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11703,modifiability,pac,packages,11703,"File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11892,modifiability,pac,packages,11892,"on3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12067,modifiability,pac,packages,12067,", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above excep",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12232,modifiability,pac,packages,12232,"py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12418,modifiability,pac,packages,12418,".py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12552,modifiability,pac,packages,12552,"8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12826,modifiability,pac,packages,12826,"veables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13178,modifiability,pac,packages,13178,"ly_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13337,modifiability,pac,packages,13337,"ernal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_fla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13535,modifiability,pac,packages,13535,"thon3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13678,modifiability,pac,packages,13678,"). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14160,modifiability,modul,module,14160,"python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. si",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14229,modifiability,pac,packages,14229,"4, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14907,modifiability,pac,packages,14907,"_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __in",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15063,modifiability,pac,packages,15063,"nfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15333,modifiability,pac,packages,15333,"_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/loc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15512,modifiability,pac,packages,15512,"_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/loc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15675,modifiability,pac,packages,15675,"ine 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15835,modifiability,pac,packages,15835,"prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = sel",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16014,modifiability,pac,packages,16014,"rrors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_mayb",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16189,modifiability,pac,packages,16189,"k). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_sav",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16359,modifiability,pac,packages,16359,"python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16538,modifiability,pac,packages,16538,"python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16715,modifiability,pac,packages,16715,"d_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:16899,modifiability,pac,packages,16899," in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[n",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17087,modifiability,pac,packages,17087,"it__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17279,modifiability,pac,packages,17279,"rn self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/pyth",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17504,modifiability,Variab,Variable,17504,"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/B",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17965,modifiability,pac,packages,17965,"_restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18191,modifiability,modul,module,18191,"d_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18259,modifiability,pac,packages,18259,"/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18932,modifiability,pac,packages,18932,"usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19110,modifiability,pac,packages,19110,"runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19272,modifiability,pac,packages,19272,"ow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/d",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19431,modifiability,pac,packages,19431,"bsl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=pr",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19609,modifiability,pac,packages,19609,"""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19783,modifiability,pac,packages,19783,"google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorfl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19952,modifiability,pac,packages,19952,"mator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20130,modifiability,pac,packages,20130,"mator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20280,modifiability,pac,packages,20280,"sorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20486,modifiability,pac,packages,20486,"line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20651,modifiability,pac,packages,20651,"session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20770,modifiability,pac,packages,20770,"3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20938,modifiability,pac,packages,20938,"n3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21125,modifiability,pac,packages,21125,"-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21307,modifiability,pac,packages,21307,"ning/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensor",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21447,modifiability,pac,packages,21447,"File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there somethin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21636,modifiability,pac,packages,21636,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21811,modifiability,pac,packages,21811,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21976,modifiability,pac,packages,21976,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22162,modifiability,pac,packages,22162,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22296,modifiability,pac,packages,22296,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1098,performance,error,error,1098,"necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_st",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2326,performance,error,error,2326,"epvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4432,performance,error,error,4432,"2, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6051,performance,error,error,6051,"_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Tra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6138,performance,error,error,6138,"ut/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15000,performance,rendezv,rendezvous,15000,"rred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17667,performance,error,error,17667,"ession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4457,reliability,checkpoint,checkpoint,4457,"args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:3",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4473,reliability,doe,does,4473,"/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 1",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5553,reliability,Restor,Restoring,5553," docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5735,reliability,Restor,Restoring,5735,"er-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6810,reliability,Fail,Failed,6810,"t-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"",",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7184,reliability,restor,restore,7184,"usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8015,reliability,Fail,Failed,8015,"on, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,reliability,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,reliability,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12015,reliability,sli,slices,12015,".8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not fo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12919,reliability,Checkpoint,CheckpointReader,12919,"/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13025,reliability,checkpoint,checkpoint,13025,". File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13239,reliability,restor,restore,13239,"nsorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tenso",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13931,reliability,checkpoint,checkpoint,13931,"CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,reliability,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,reliability,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17222,reliability,restor,restore,17222,"onitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17340,reliability,restor,restore,17340,"python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=ar",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17441,reliability,Restor,Restoring,17441," self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17456,reliability,checkpoint,checkpoint,17456," self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17467,reliability,fail,failed,17467,"ssion_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in r",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17562,reliability,checkpoint,checkpoint,17562,"aining/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17646,reliability,checkpoint,checkpoint,17646,"manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17759,reliability,Fail,Failed,17759,"ager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,reliability,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,reliability,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21759,reliability,sli,slices,21759,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:831,safety,input,input,831,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:862,safety,input,input,862,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1098,safety,error,error,1098,"necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_st",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1358,safety,modul,module,1358,"nception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renam",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2270,safety,input,input-files-eg-could-not-open,2270,"ll last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2326,safety,error,error,2326,"epvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2864,safety,input,input,2864,"bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2895,safety,input,input,2895,"57, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3345,safety,modul,module,3345," model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4223,safety,input,input-files-eg-could-not-open,4223,"lts_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 1399261",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4432,safety,error,error,4432,"2, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4932,safety,input,input,4932,"files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.6621",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4963,safety,input,input,4963,"ally '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6051,safety,error,error,6051,"_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Tra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6138,safety,error,error,6138,"ut/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7011,safety,except,exception,7011,"NING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: F",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7030,safety,except,exception,7030,"aising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any m",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8447,safety,modul,module,8447,"/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9121,safety,predict,prediction,9121,"data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_sessio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9139,safety,predict,predictions,9139,"odel.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._ses",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9272,safety,predict,predict,9272,"r.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9321,safety,predict,predict,9321,"storeV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9441,safety,predict,predict,9441," <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,safety,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,safety,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12361,safety,input,inputs,12361,"b/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12714,safety,except,exception,12714,"low/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_ch",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12733,safety,except,exception,12733,"/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13066,safety,except,exception,13066,"ages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfil",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13085,safety,except,exception,13085,"hon/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfile",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13972,safety,except,exception,13972,": Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13991,safety,except,exception,13991,"LE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14160,safety,modul,module,14160,"python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. si",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14839,safety,predict,prediction,14839,"hon.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14857,safety,predict,predictions,14857,"s_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14991,safety,predict,predict,14991,"ption occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15417,safety,predict,predict,15417,".py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", lin",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15466,safety,predict,predict,15466,"le ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._se",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15587,safety,predict,predict,15587,"Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,safety,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,safety,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17667,safety,error,error,17667,"ession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18191,safety,modul,module,18191,"d_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18865,safety,predict,prediction,18865,"data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_sessio",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18883,safety,predict,predictions,18883,"odel.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._ses",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19016,safety,predict,predict,19016,"r.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19065,safety,predict,predict,19065,"storeV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19185,safety,predict,predict,19185," <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,safety,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,safety,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22105,safety,input,inputs,22105,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:73,security,model,model,73,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:184,security,model,model,184,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:234,security,model,model,234,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:297,security,model,model,297,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:323,security,model,models,323,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:397,security,model,model,397,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:695,security,model,models,695,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:769,security,model,model,769,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1942,security,model,model,1942,"${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPU",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2005,security,model,model,2005,"--intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions c",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2034,security,model,models,2034,"utput/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2108,security,model,model,2108,"sh. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2349,security,model,model,2349,", in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2364,security,model,model,2364,"app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main)",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2440,security,access,accessible,2440," 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2487,security,access,access,2487,"sr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2822,security,model,model,2822,"es. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_fla",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3929,security,model,model,3929,"utput/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3992,security,model,model,3992,". --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_v",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4081,security,model,model,4081,"iate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4285,security,model,model,4285,"""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4323,security,model,model,4323,"py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_work",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4357,security,model,model,4357,"n(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 13992614",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4512,security,model,model,4512,"bsl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247]",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4816,security,model,models,4816,"ck_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-ince",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4890,security,model,model,4890,"heck_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_lo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5596,security,model,models,5596," google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. retu",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5670,security,model,model,5670,"nt \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5778,security,model,models,5778,"customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful Te",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:5852,security,model,model,5852,"ception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://de",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6251,security,session,session,6251,"r.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6376,security,session,session,6376,"r.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6547,security,session,session,6547,"w:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_f",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6865,security,model,models,6865,":tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, me",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6939,security,model,model,6939,"26144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7305,security,session,session,7305,"e ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trac",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7465,security,session,session,7465,"_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7630,security,session,session,7630,"(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tole",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7801,security,session,session,7801,"tor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/a",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8070,security,model,models,8070," call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8144,security,model,model,8144,"on/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predicti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:10699,security,access,access,10699,"flow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:11338,security,access,access,11338,"ession(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_int",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17814,security,model,models,17814,"_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17888,security,model,model,17888,".8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predicti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:20443,security,access,access,20443,"flow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:21082,security,access,access,21082,"ession(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._saver = training_saver._get_saver_or_default() # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_int",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1260,testability,Trace,Traceback,1260," with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:3247,testability,Trace,Traceback,3247,"t-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6145,testability,Trace,Traceback,6145,"ediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:7051,testability,Trace,Traceback,7051,". W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1303, in restore. sess.run(self.saver_def.restore_op_name,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:8305,testability,trace,trace,8305,"sion.py"", line 967, in run. result = self._run(None, fetches, feed_dict, options_ptr,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1190, in _run. results = self._do_run(handle, final_targets, final_fetches,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1368, in _do_run. return self._do_call(_run_fn, feeds, fetches, targets, options,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1394, in _do_call. raise type(e)(node_def, op, message). tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEsti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9474,testability,Monitor,MonitoredSession,9474,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:9617,testability,Monitor,MonitoredSession,9617,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12754,testability,Trace,Traceback,12754," in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_t",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:13106,testability,Trace,Traceback,13106,""", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:14012,testability,Trace,Traceback,14012,"ound in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1632, in object_graph_key_mapping. object_graph_string = reader.get_tensor(trackable.OBJECT_GRAPH_PROTO_KEY). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 74, in get_tensor. error_translator(e). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 35, in error_translator. raise errors_impl.NotFoundError(None, None, error_message). tensorflow.python.framework.errors_impl.NotFoundError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15185,testability,trace,traceback,15185,"). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-p",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15620,testability,Monitor,MonitoredSession,15620,"google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. re",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:15764,testability,Monitor,MonitoredSession,15764,"variant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3153, in predict. rendezvous.raise_errors(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/error_handling.py"", line 150, in raise_errors. six.reraise(typ, value, traceback). File ""/tmp/Bazel.runfiles_2gnuyvf0/runfiles/six_archive/six.py"", line 703, in reraise. raise value. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 662, in create_session. return self._get_session_manager().prepare_session(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", ",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:18049,testability,trace,trace,18049,"ile ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEsti",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19218,testability,Monitor,MonitoredSession,19218,"le ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._sc",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:19361,testability,Monitor,MonitoredSession,19361,"lags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 474, in main. call_variants(. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 433, in call_variants. prediction = next(predictions). File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py"", line 3142, in predict. for result in super(TPUEstimator, self).predict(. File ""usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 623, in predict. with tf.compat.v1.train.MonitoredSession(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1035, in __init__. super(MonitoredSession, self).__init__(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 750, in __init__. self._sess = _RecoverableSession(self._coordinated_creator). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1232, in __init__. _WrappedSession.__init__(self, self._create_session()). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 1237, in _create_session. return self._sess_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 903, in create_session. self.tf_sess = self._session_creator.create_session(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 661, in create_session. self._scaffold.finalize(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/monitored_session.py"", line 236, in finalize. self._s",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22453,testability,simpl,simple,22453,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:285,usability,command,command,285,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:831,usability,input,input,831,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:862,usability,input,input,862,"Thanks, this makes perfect sense! I did not realize that the hosting the model in Google Storage was necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError:",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:1098,usability,error,error,1098,"necessary for the TPU Node. I am still having an issue pointing deepvariant to the model hosted in the cloud. . I have tried using a model in the deepvariant bucket with the following command and model: . gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. ```. But I get the following error:. ```bash. I0527 20:42:08.331003 139757477517120 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_st",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2270,usability,input,input-files-eg-could-not-open,2270,"ll last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. Fi",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2326,usability,error,error,2326,"epvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py""",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2382,usability,person,personal,2382," ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2458,usability,user,users,2458,"un_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main,",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2864,usability,input,input,2864,"bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepv",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:2895,usability,input,input,2895,"57, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt.data-00000-of-00001* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. I also get the same error when hosting the model (renamed model.ckpt) in my personal GS bucket -- I have made the storage bucket read accessible to all users so the TPU should have access:. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. I0527 21:26:03.381308 140127359940416 run_deepvariant.py:341] Creating a directory for intermediate results in /output/intermediate_results_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4223,usability,input,input-files-eg-could-not-open,4223,"lts_dir. Traceback (most recent call last):. File ""/opt/deepvariant/bin/run_deepvariant.py"", line 493, in <module>. app.run(main). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 1399261",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4432,usability,error,error,4432,"2, in run. _run_main(main, args). File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main. sys.exit(main(argv)). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 467, in main. commands_logfiles = create_all_commands_and_logfiles(intermediate_results_dir). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 382, in create_all_commands_and_logfiles. check_flags(). File ""/opt/deepvariant/bin/run_deepvariant.py"", line 357, in check_flags. raise RuntimeError('The model files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Grap",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4932,usability,input,input,4932,"files {}* do not exist. Potentially '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.6621",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:4963,usability,input,input,4963,"ally '. RuntimeError: The model files gs://tpu-bwb/analysis-files/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt* do not exist. Potentially relevant issue: https://github.com/google/deepvariant/blob/r1.3/docs/FAQ.md#why-cant-it-find-one-of-the-input-files-eg-could-not-open. ```. However, if I shorten the model name in the deepvariant bucket (model.ckpt.data-00000-of-00001 -> model.ckpt), the file is found and processing continues until the previous error is met because the checkpoint file does not actually exist under the name model.ckpt in the deepvariant bucket. ```bash. docker run \. -v `pwd`:`pwd` -w `pwd` \. google/deepvariant:""${BIN_VERSION}"" \. /opt/deepvariant/bin/run_deepvariant \. --call_variants_extra_args use_tpu=true,tpu_name=""variantcaller-node1"",tpu_zone=""europe-west4-a"" \. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. --model_type=WGS \. --ref=""input/data/${REF}"" \. --reads=""input/data/${BAM}"" \. --output_vcf=""output/${OUTPUT_VCF}"" \. --output_gvcf=""output/${OUTPUT_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handli",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6051,usability,error,error,6051,"_GVCF}"" \. --regions chr20 \. --num_shards=$(nproc) \. --intermediate_results_dir /output/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Tra",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6138,usability,error,error,6138,"ut/intermediate_results_dir. INFO:tensorflow:Done calling model_fn. I0527 21:33:10.817516 139926144051008 estimator.py:1164] Done calling model_fn. INFO:tensorflow:TPU job name tpu_worker. I0527 21:33:11.115715 139926144051008 tpu_estimator.py:514] TPU job name tpu_worker. INFO:tensorflow:Graph was finalized. I0527 21:33:11.664746 139926144051008 monitored_session.py:247] Graph was finalized. INFO:tensorflow:Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. I0527 21:33:11.801618 139926144051008 saver.py:1298] Restoring parameters from gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. INFO:tensorflow:prediction_loop marked as finished. I0527 21:33:13.662127 139926144051008 error_handling.py:115] prediction_loop marked as finished. WARNING:tensorflow:Reraising captured error. W0527 21:33:13.662372 139926144051008 error_handling.py:149] Reraising captured error. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1375, in _do_call. return fn(*args). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1359, in _run_fn. return self._call_tf_sessionrun(options, feed_dict, fetch_list,. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py"", line 1451, in _call_tf_sessionrun. return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,. tensorflow.python.framework.errors_impl.NotFoundError: From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[{{node save_1/RestoreV2}}]]. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflo",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:12361,usability,input,inputs,12361,"b/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/py_checkpoint_reader.py"", line 69, in get_tensor. return CheckpointReader.CheckpointReader_GetTensor(. RuntimeError: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint. During handling of the above exception, another exception occurred:. Traceback (most recent call last):. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1314, in restore. names_to_keys = object_graph_key_mapping(save_path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:17667,usability,error,error,17667,"ession(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 314, in prepare_session. sess, is_loaded_from_checkpoint = self._restore_checkpoint(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 233, in _restore_checkpoint. _restore_checkpoint_and_maybe_run_saved_model_initializers(. File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/session_manager.py"", line 71, in _restore_checkpoint_and_maybe_run_saved_model_initializers. saver.restore(sess, path). File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 1319, in restore. raise _wrap_restore_error_with_msg(. tensorflow.python.framework.errors_impl.NotFoundError: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:. From /job:tpu_worker/replica:0/task:0:. Unsuccessful TensorSliceReader constructor: Failed to find any matching files for gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt. [[node save_1/RestoreV2 (defined at usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/estimator.py:623) ]]. Original stack trace for 'save_1/RestoreV2':. File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvariant/deepvariant/call_variants.py"", line 493, in <module>. tf.compat.v1.app.run(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/platform/app.py"", line 40, in run. _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 299, in run. _run_main(main, args). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/absl_py/absl/app.py"", line 250, in _run_main. sys.exit(main(argv)). File ""tmp/Bazel.runfiles_2gnuyvf0/runfiles/com_google_deepvari",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22105,usability,input,inputs,22105,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22453,usability,simpl,simple,22453,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:22494,usability,support,support,22494,"low/python/training/saver.py"", line 607, in _get_saver_or_default. saver = Saver(sharded=True, allow_empty=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 836, in __init__. self.build(). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 848, in build. self._build(self._filename, build_save=True, build_restore=True). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 876, in _build. self.saver_def = self._builder._build_internal( # pylint: disable=protected-access. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 509, in _build_internal. restore_op = self._AddShardedRestoreOps(filename_tensor, per_device,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 383, in _AddShardedRestoreOps. self._AddRestoreOps(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 335, in _AddRestoreOps. all_tensors = self.bulk_restore(filename_tensor, saveables, preferred_shard,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/training/saver.py"", line 583, in bulk_restore. return io_ops.restore_v2(filename_tensor, names, slices, dtypes). File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 1490, in restore_v2. _, _, _op, _outputs = _op_def_library._apply_op_helper(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py"", line 748, in _apply_op_helper. op = g._create_op_internal(op_type_name, inputs, dtypes=None,. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 3557, in _create_op_internal. ret = Operation(. File ""usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 2045, in __init__. self._traceback = tf_stack.extract_stack_for_node(self._c_op). ```. Is there something simple I am missing here? Thanks for the support.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:70,energy efficiency,model,models,70,"@shishir-reddy . Try just:. ```. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:144,energy efficiency,model,model,144,"@shishir-reddy . Try just:. ```. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:70,security,model,models,70,"@shishir-reddy . Try just:. ```. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:144,security,model,model,144,"@shishir-reddy . Try just:. ```. --customized_model ""gs://deepvariant/models/DeepVariant/1.3.0/DeepVariant-inception_v3-1.3.0+data-wgs_standard/model.ckpt"" \. ```",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:100,availability,error,error,100,"Sorry, @akolesnikov pointed out that you tried both. I don't have an immediate answer to the second error then.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:100,performance,error,error,100,"Sorry, @akolesnikov pointed out that you tried both. I don't have an immediate answer to the second error then.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:100,safety,error,error,100,"Sorry, @akolesnikov pointed out that you tried both. I don't have an immediate answer to the second error then.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:100,usability,error,error,100,"Sorry, @akolesnikov pointed out that you tried both. I don't have an immediate answer to the second error then.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:54,deployability,updat,updates,54,"Hi, I just wanted to check in to see if there are any updates on this thread? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:54,safety,updat,updates,54,"Hi, I just wanted to check in to see if there are any updates on this thread? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:54,security,updat,updates,54,"Hi, I just wanted to check in to see if there are any updates on this thread? Thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6,energy efficiency,model,model,6,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:40,energy efficiency,model,model,40,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:81,energy efficiency,model,model,81,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:6,security,model,model,6,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:40,security,model,model,40,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:81,security,model,model,81,"Hi,. (model.ckpt.data-00000-of-00001 -> model.ckpt) is the right way to pass the model. . May I ask you a more general question? What is the reason you want to run inference on TPU? In general it is not advisable because TPU processing is way too fast for the inference. The infeed cannot supply examples fast enough.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:104,energy efficiency,GPU,GPU,104,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:104,performance,GPU,GPU,104,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:179,safety,test,test,179,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:69,security,sign,significant,69,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:179,testability,test,test,179,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:120,usability,support,supporting,120,"I am just benchmarking TPU usage on DeepVariant to see if there is a significant speedup as compared to GPU. There were supporting flags in the call_variants step, so I wanted to test with TPU. If TPU is not recommended for inference, then I will switch over to training and try from there, thanks!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:34,availability,error,error,34,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:67,energy efficiency,model,model,67,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:101,energy efficiency,model,model,101,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:34,performance,error,error,34,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:34,safety,error,error,34,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:67,security,model,model,67,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:101,security,model,model,101,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:34,usability,error,error,34,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:129,usability,support,supported,129,"Is there a solution to the second error that occurs when renaming (model.ckpt.data-00000-of-00001 -> model.ckpt), or is this not supported for TPU usage?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:212,deployability,contain,containing,212,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:111,energy efficiency,model,model,111,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:227,energy efficiency,model,model,227,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:111,security,model,model,111,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:152,security,access,access,152,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:159,security,control,control,159,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:191,security,access,access,191,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:227,security,model,model,227,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:159,testability,control,control,159,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/537:35,usability,support,support,35,"Unfortunately, we don't officially support running on TPU at the moment. The way you ran it when using a short model name looks correct. It could be an access control issue (there is no read access to the bucket containing the model from TPU host).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/537
https://github.com/google/deepvariant/issues/538:863,availability,avail,available,863,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:91,energy efficiency,model,model,91,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:119,energy efficiency,model,models,119,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:306,energy efficiency,model,models,306,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:581,energy efficiency,model,model,581,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:789,energy efficiency,model,model,789,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:73,interoperability,standard,standard,73,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:894,interoperability,platform,platforms,894,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:187,modifiability,evolv,evolved,187,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1010,modifiability,evolv,evolved,1010,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:200,performance,time,time,200,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:863,reliability,availab,available,863,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:141,safety,compl,complexity,141,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:863,safety,avail,available,863,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:91,security,model,model,91,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:119,security,model,models,119,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:141,security,compl,complexity,141,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:306,security,model,models,306,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:581,security,model,model,581,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:789,security,model,model,789,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:863,security,availab,available,863,"Hi @avilella . DeepVariant has been used on MGI datasets, both using the standard Illumina model, as well as retrained models. There is some complexity that the MGI/BGI technologies have evolved over time, so some demonstrations may not reflect the newest methods. The general finding is that the Illumina models tend to work well for MGI data, though we find examples of retraining for certain datasets improve further. Our [advanced training tutorial ](https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md) walks through retraining an Illumina model for data from BGISEQ 500 and [this comparison](https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/) was conducted several years ago using the out-of-the-box Illumina model. If you know of any genome in a bottle sequencing datasets that are available from more recent MGI platforms, I'd be interested in pointers to those locations. I would be quite curious to see how the technology has evolved over the last several years.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1047,availability,avail,available,1047,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:233,energy efficiency,model,model,233,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:261,energy efficiency,model,models,261,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:459,energy efficiency,model,models,459,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:749,energy efficiency,model,model,749,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:965,energy efficiency,model,model,965,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1549,integrability,Messag,Message,1549,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:212,interoperability,standard,standard,212,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1078,interoperability,platform,platforms,1078,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1549,interoperability,Messag,Message,1549,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:332,modifiability,evolv,evolved,332,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1200,modifiability,evolv,evolved,1200,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:345,performance,time,time,345,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1047,reliability,availab,available,1047,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:283,safety,compl,complexity,283,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1047,safety,avail,available,1047,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:233,security,model,model,233,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:261,security,model,models,261,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:283,security,compl,complexity,283,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:459,security,model,models,459,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:749,security,model,model,749,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:965,security,model,model,965,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1047,security,availab,available,1047,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:1441,security,auth,auth,1441,"Fantastic information, thank you. On Thu, May 26, 2022 at 9:01 AM Andrew Carroll ***@***.***>. wrote:. > Hi @avilella <https://github.com/avilella>. >. > DeepVariant has been used on MGI datasets, both using the standard. > Illumina model, as well as retrained models. There is some complexity that. > the MGI/BGI technologies have evolved over time, so some demonstrations may. > not reflect the newest methods. >. > The general finding is that the Illumina models tend to work well for MGI. > data, though we find examples of retraining for certain datasets improve. > further. >. > Our advanced training tutorial. > <https://github.com/google/deepvariant/blob/r1.3/docs/deepvariant-training-case-study.md>. > walks through retraining an Illumina model for data from BGISEQ 500 and this. > comparison. > <https://blog.dnanexus.com/2018-07-02-comparison-of-bgiseq-500-to-illumina-novaseq-data/>. > was conducted several years ago using the out-of-the-box Illumina model. >. > If you know of any genome in a bottle sequencing datasets that are. > available from more recent MGI platforms, I'd be interested in pointers to. > those locations. I would be quite curious to see how the technology has. > evolved over the last several years. >. > —. > Reply to this email directly, view it on GitHub. > <https://github.com/google/deepvariant/issues/538#issuecomment-1138272184>,. > or unsubscribe. > <https://github.com/notifications/unsubscribe-auth/AABGSN3EDTSIAXWBYLGQ3PDVL4VV7ANCNFSM5W4SRYCA>. > . > You are receiving this because you were mentioned.Message ID:. > ***@***.***>. >.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:27,energy efficiency,cool,cool,27,"@AndrewCarroll It would be cool to have the option `--model_type=MGI`. Now, unfortunately, there are a lot of variants being missed when working with MGI data.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:487,energy efficiency,model,models,487,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:101,safety,Compl,Complete,101,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:206,safety,compl,complete-,206,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:317,safety,compl,complete-,317,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:101,security,Compl,Complete,101,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:206,security,compl,complete-,206,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:317,security,compl,complete-,317,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:487,security,model,models,487,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:38,usability,document,documentation,38,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:452,usability,feedback,feedback,452,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/538:476,usability,custom,customized,476,"Hi @PlatonB ,. In v1.6, we have added documentation on how to run on MGI data. Please see the links ""Complete Genomics data: [T7 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-t7-case-study.md); [G400 case study](https://github.com/google/deepvariant/blob/r1.6/docs/deepvariant-complete-g400-case-study.md)"" which was also linked from our GitHub main page. And let us know if you encounter any issues or have any feedback. Hopefully the customized models will give you better results!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/538
https://github.com/google/deepvariant/issues/539:597,availability,error,errors,597,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:597,performance,error,errors,597,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:420,safety,input,input,420,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:451,safety,input,input,451,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:597,safety,error,errors,597,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:420,usability,input,input,420,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:451,usability,input,input,451,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:597,usability,error,errors,597,"@ziphra ,. Reads without any quality score provided to DeepVariant would cause this issue. One thing you can quickly see from your `samtools view` output is the flag of this read is `0x16`, you can go to this website: https://broadinstitute.github.io/picard/explain-flags.html and put in `0x16` and it'd say the read is unmapped. . A quick way to remove any improper reads would be to run this:. ```. INPUT_BAM=/path/to/input.bam. OUTPUT_BAM=/path/to/input.F0x904.bam. samtools view -@42 -F 0x904 ${INPUT_BAM} > ${OUTPUT_BAM}. ```. This will remove all non-primary reads and should get rid of the errors for you. You can put `0x904` on the explain-flags website to see which reads you will only keep.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:281,safety,except,except,281,"Hello @kishwarshafin, . Thank you for your response and for the useful tips! It appears that I have several types of flags for my reads presenting no quality score: . ```. 0. 16. 2048. 2064. 4. ```. All the above flags are also present in my reads having a quality score sequence, except for the flag `4` (= read unmapped), which is absent. Also, it seems that in this case flags should be written without the `0x` prefix, which converts them to hexadecimal when they are written in decimal in the sam file, as I understand. . `0x16` in https://broadinstitute.github.io/picard/explain-flags.html output a flag that cannot be set when read is not paired, and my read are not paired. However, it now seems clear that something went wrong with the alignment since I have all types of reads with no quality score sequence, not only `0x904` type reads (which are read unmapped `0x4`, not primary alignment `0x100`, and supplementary alignment `0x800`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:513,testability,understand,understand,513,"Hello @kishwarshafin, . Thank you for your response and for the useful tips! It appears that I have several types of flags for my reads presenting no quality score: . ```. 0. 16. 2048. 2064. 4. ```. All the above flags are also present in my reads having a quality score sequence, except for the flag `4` (= read unmapped), which is absent. Also, it seems that in this case flags should be written without the `0x` prefix, which converts them to hexadecimal when they are written in decimal in the sam file, as I understand. . `0x16` in https://broadinstitute.github.io/picard/explain-flags.html output a flag that cannot be set when read is not paired, and my read are not paired. However, it now seems clear that something went wrong with the alignment since I have all types of reads with no quality score sequence, not only `0x904` type reads (which are read unmapped `0x4`, not primary alignment `0x100`, and supplementary alignment `0x800`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:71,usability,tip,tips,71,"Hello @kishwarshafin, . Thank you for your response and for the useful tips! It appears that I have several types of flags for my reads presenting no quality score: . ```. 0. 16. 2048. 2064. 4. ```. All the above flags are also present in my reads having a quality score sequence, except for the flag `4` (= read unmapped), which is absent. Also, it seems that in this case flags should be written without the `0x` prefix, which converts them to hexadecimal when they are written in decimal in the sam file, as I understand. . `0x16` in https://broadinstitute.github.io/picard/explain-flags.html output a flag that cannot be set when read is not paired, and my read are not paired. However, it now seems clear that something went wrong with the alignment since I have all types of reads with no quality score sequence, not only `0x904` type reads (which are read unmapped `0x4`, not primary alignment `0x100`, and supplementary alignment `0x800`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:704,usability,clear,clear,704,"Hello @kishwarshafin, . Thank you for your response and for the useful tips! It appears that I have several types of flags for my reads presenting no quality score: . ```. 0. 16. 2048. 2064. 4. ```. All the above flags are also present in my reads having a quality score sequence, except for the flag `4` (= read unmapped), which is absent. Also, it seems that in this case flags should be written without the `0x` prefix, which converts them to hexadecimal when they are written in decimal in the sam file, as I understand. . `0x16` in https://broadinstitute.github.io/picard/explain-flags.html output a flag that cannot be set when read is not paired, and my read are not paired. However, it now seems clear that something went wrong with the alignment since I have all types of reads with no quality score sequence, not only `0x904` type reads (which are read unmapped `0x4`, not primary alignment `0x100`, and supplementary alignment `0x800`).",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:31,reliability,doe,does,31,"@ziphra ,. You are correct. It does seem like something went wrong with your mapping and you have reads without base-qualities. My suspicion was that the aligner was removing base-qualities from non-primary reads, but that's clearly not the case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/539:225,usability,clear,clearly,225,"@ziphra ,. You are correct. It does seem like something went wrong with your mapping and you have reads without base-qualities. My suspicion was that the aligner was removing base-qualities from non-primary reads, but that's clearly not the case.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/539
https://github.com/google/deepvariant/issues/541:336,deployability,releas,release,336,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:492,deployability,build,build,492,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:118,performance,time,time,118,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:139,safety,test,test,139,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:139,testability,test,test,139,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:297,testability,plan,plan,297,"Hi @ASLeonard ,. Thanks for reporting this issue. We actually made a deliberate decision to not include OpenVINO this time, because in our test setting we were not able to get faster runtime. We did talk to @dkurt about this and tried https://github.com/google/deepvariant/pull/523. We will still plan to try OpenVINO again in the next release. But given that we didn't see faster runtime, we decided to leave it out of the default. If you would like to use it, please use our Dockerfile and build with the option on. I'm curious - were you seeing a speedup by using OpenVINO in DeepVariant v1.3.0? If so, what is the type of machine you're using? Thank you!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:147,availability,slo,slower,147,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:310,deployability,build,build,310,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:637,energy efficiency,current,currently,637,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:123,reliability,doe,doesn,123,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:147,reliability,slo,slower,147,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:463,reliability,doe,doesn,463,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:649,security,legitim,legitimate,649,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:250,usability,help,helpful,250,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:293,usability,user,users,293,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:485,usability,support,support,485,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:534,usability,user,user,534,"I was using OpenVINO from v1.1 when it was still faster, and mainly haven't bothered to remove the flags since at worst it doesn't seem to make it slower. I didn't benchmark in v1.3 when not including the flag, so it may well be the case it isn't as helpful anymore. It would get tricky since users can easily build their own image with `DV_OPENVINO_BUILD=1`, so the flags to run with OpenVINO can't be easily removed. But if the default google/deepvariant image doesn't have OpenVINO support, it would be nice if there was more of a user warning+exit or a warning+ignore the flag and run as if `--use_openvino=False` anyway since it is currently a legitimate flag to use.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:202,deployability,build,build,202,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:372,deployability,releas,releases,372,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:432,deployability,build,building,432,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:395,interoperability,specif,specifically,395,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:37,safety,compl,completely,37,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:37,security,compl,completely,37,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:192,usability,user,users,192,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:298,usability,help,helpful,298,"Yeah, we could remove `use_openvino` completely from call_variants.py. But given that I do still want to try it again in the future, it would be nice to keep it as a flag. (And like you said, users who build their own binaries or own Docker images, they can still enable it). @ASLeonard Will it be helpful if we add a bullet point in https://github.com/google/deepvariant/releases/tag/v1.4.0 to specifically call out that we're not building OpenVINO into out default Docker image?",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:287,availability,sli,slightly,287,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:174,deployability,depend,dependency,174,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:622,deployability,releas,release,622,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:174,integrability,depend,dependency,174,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:174,modifiability,depend,dependency,174,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:316,performance,memor,memory,316,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:287,reliability,sli,slightly,287,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:174,safety,depend,dependency,174,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:174,testability,depend,dependency,174,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:466,testability,coverag,coverage,466,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:133,usability,tool,tools,133,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:316,usability,memor,memory,316,"Yeah I think that would be fine. This case was more unfortunate as the missing OpenVINO leads to the missing `from tensorflow.python.tools import optimize_for_inference_lib` dependency, and so I assumed I had really messed something up as I hadn't changed anything with tensorflow. On a slightly different note, the memory usage for call_variants (open_vino=False) in v1.4 is much better than v1.3 (open_vino=True) at ~ 7gb compared to ~20gb RAM for a lot of medium coverage samples. Also postprocessing seems to be about 70% faster (although the previous runs had IO issues so probably inflated). Great improvements this release!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:44,deployability,updat,updated,44,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:90,deployability,releas,releases,90,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:146,deployability,build,build,146,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:210,deployability,observ,observation,210,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:312,deployability,version,version,312,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:320,deployability,updat,updates,320,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:312,integrability,version,version,312,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:312,modifiability,version,version,312,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:131,performance,time,time,131,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:44,safety,updat,updated,44,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:320,safety,updat,updates,320,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:44,security,updat,updated,44,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:320,security,updat,updates,320,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/541:210,testability,observ,observation,210,"Thanks @ASLeonard , a few follow ups:. 1. I updated https://github.com/google/deepvariant/releases/tag/v1.4.0 to mention that this time we didn't build in OpenVINO by default. 2. Thanks for the `call_variants` observation. Now I wonder how much of the RAM difference is OpenVINO and how much of it is TensorFlow version updates... 3. Great to hear that you're also seeing good postprocess_variants improvements! Our 20%er @MosheWagner worked really hard on this, so I'm sure he'll be happy to hear that too!",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/541
https://github.com/google/deepvariant/issues/542:39,safety,input,input,39,"Could you please paste a line from the input BAM after the header? Also, a line from the reference showing the ID of the chromosome.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:39,usability,input,input,39,"Could you please paste a line from the input BAM after the header? Also, a line from the reference showing the ID of the chromosome.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:22,safety,input,input,22,"Lines after header in input bam: . ![Image 15-06-2022 at 09 41](https://user-images.githubusercontent.com/57212516/173783876-a335765c-035a-4020-b440-de485180d968.jpg). Chromosome ID in reference (it isn't all Ns, I checked): . <img width=""1712"" alt=""Screenshot 2022-06-15 at 09 49 45"" src=""https://user-images.githubusercontent.com/57212516/173785292-858b5500-7888-4bc7-b4f3-607abae6ba52.png"">.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:22,usability,input,input,22,"Lines after header in input bam: . ![Image 15-06-2022 at 09 41](https://user-images.githubusercontent.com/57212516/173783876-a335765c-035a-4020-b440-de485180d968.jpg). Chromosome ID in reference (it isn't all Ns, I checked): . <img width=""1712"" alt=""Screenshot 2022-06-15 at 09 49 45"" src=""https://user-images.githubusercontent.com/57212516/173785292-858b5500-7888-4bc7-b4f3-607abae6ba52.png"">.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:72,usability,user,user-images,72,"Lines after header in input bam: . ![Image 15-06-2022 at 09 41](https://user-images.githubusercontent.com/57212516/173783876-a335765c-035a-4020-b440-de485180d968.jpg). Chromosome ID in reference (it isn't all Ns, I checked): . <img width=""1712"" alt=""Screenshot 2022-06-15 at 09 49 45"" src=""https://user-images.githubusercontent.com/57212516/173785292-858b5500-7888-4bc7-b4f3-607abae6ba52.png"">.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:298,usability,user,user-images,298,"Lines after header in input bam: . ![Image 15-06-2022 at 09 41](https://user-images.githubusercontent.com/57212516/173783876-a335765c-035a-4020-b440-de485180d968.jpg). Chromosome ID in reference (it isn't all Ns, I checked): . <img width=""1712"" alt=""Screenshot 2022-06-15 at 09 49 45"" src=""https://user-images.githubusercontent.com/57212516/173785292-858b5500-7888-4bc7-b4f3-607abae6ba52.png"">.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/542:460,interoperability,share,share,460,"I think it may have been a problem with my bed file! . I did this to see if it was tab or spaces between the fields (even though my text editor said it was tabs): . tr -d "" "" < original.bed > checktabspaces.bed. The result was a file where all the columns combined so then I did this on the original file:. awk 'OFS="" "" {print $1""\t"", $2""\t"", $3}' orginial.bed | tr -d "" "" > tab.bed. And then reran, and it worked! . Not a deepvariant problem, but thought I'd share. Thanks! Amy.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/542
https://github.com/google/deepvariant/issues/543:29,availability,error,error,29,How did you solve this? Same error here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:29,performance,error,error,29,How did you solve this? Same error here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:29,safety,error,error,29,How did you solve this? Same error here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/543:29,usability,error,error,29,How did you solve this? Same error here.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/543
https://github.com/google/deepvariant/issues/544:97,energy efficiency,optim,optimized,97,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:396,modifiability,Pac,PacBio,396,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:471,modifiability,pac,pacbio-case-study,471,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:530,modifiability,scal,scalable,530,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:97,performance,optimiz,optimized,97,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:530,performance,scalab,scalable,530,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:616,performance,content,content,616,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:713,usability,support,supported,713,"Merging VCFs can be done using [GLnexus](https://github.com/dnanexus-rnd/GLnexus) which has been optimized for use with DeepVariant gVCFs. The process is described in the DeepTrio case studies ([DeepTrio whole genome sequencing case study](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-wgs-case-study.md) and [Using DeepTrio for small variant calling from the trio sequenced with PacBio HiFi](https://github.com/google/deepvariant/blob/r1.4/docs/deeptrio-pacbio-case-study.md)), and in the manuscript, [""Accurate, scalable cohort variant calls using DeepVariant and GLnexus""](https://www.biorxiv.org/content/10.1101/2020.02.10.942086v2). --output_gvcf_merged flag in run_deeptrio.py script is not supported.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:147,performance,time,time,147,"Thank you for the explanations. As this flag is proposed in the options of run_deeptrio.py, I thought it might be useful to get the merging at the time of calling. I used GLnexus but some calls/merging are problematic, like this ""denovo"" one:. X 7811586 X_7811586_C_T C T 99 . AF=0.166667;AQ=99;AB=0.285714;x_denovo=mysample1 GT:DP:AD:GQ:PL:RNC:VAF 0/1:35:25,10:67:99,0,67:..:0.285714 0/0:17:17,0:50:0,54,539:..:0 0/0:32:20,12:43:0,43,50:..:0.375",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:14,deployability,version,versions,14,In the future versions we may add the merging functionality to run_deeptrio.py.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:14,integrability,version,versions,14,In the future versions we may add the merging functionality to run_deeptrio.py.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/544:14,modifiability,version,versions,14,In the future versions we may add the merging functionality to run_deeptrio.py.,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/544
https://github.com/google/deepvariant/issues/546:48,usability,command,command,48,@davidecarlson can you try to run the following command and report back the result? ```. singularity run \. --nv -B /usr/lib/locale/:/usr/lib/locale/ \. nproc. ```,MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:87,availability,error,error,87,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:264,availability,ERROR,ERROR,264,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:679,availability,avail,available,679,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1167,availability,cluster,cluster,1167,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:104,deployability,fail,failed,104,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1138,deployability,configurat,configuration,1138,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1167,deployability,cluster,cluster,1167,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:445,energy efficiency,gpu,gpu,445,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:559,energy efficiency,schedul,scheduler,559,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:689,energy efficiency,CPU,CPUs,689,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:907,energy efficiency,gpu,gpu,907,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1138,integrability,configur,configuration,1138,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:314,interoperability,specif,specify,314,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1213,interoperability,specif,specifically,1213,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:1138,modifiability,configur,configuration,1138,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:87,performance,error,error,87,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:264,performance,ERROR,ERROR,264,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:445,performance,gpu,gpu,445,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:559,performance,schedul,scheduler,559,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
https://github.com/google/deepvariant/issues/546:689,performance,CPU,CPUs,689,"Hi Daniel,. Thanks for your response! If I run that exact command, I get the following error:. > FATAL: failed to retrieved path for /gpfs/scratch/decarlson/deepvariant_test/nproc: lstat /gpfs/scratch/decarlson/deepvariant_test/nproc: no such file or directory. > ERROR : Child exit with status 255. However, if I specify the image:. ```. singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ \. docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc. ```. The value returned is:. > 1. That said, I think this is some weird interaction with the Slurm HPC scheduler I'm using. I'm doing this in an interactive job, where I've set `--ntasks-per-node=28`. But I'm not seeing 28 available CPUs. But if I open up a new terminal and ssh directly to the node my interactive job is running on, and then do. `singularity run --nv -B /usr/lib/locale/:/usr/lib/locale/ docker://google/deepvariant:""${BIN_VERSION}""-gpu nproc`. The value returned is now:. > 28. Moreover, when I run the same command that I listed in my first post in this second terminal, make_examples is parallelized across all 28 shards as expected. I think this is probably a configuration issue with our cluster, not something related to DeepVariant specifically. If you agree, feel free to close the ticket. Thanks for your help! Dave.",MatchSource.ISSUE_COMMENT,google,deepvariant,v1.6.1,,https://github.com/google/deepvariant/issues/546
